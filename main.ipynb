{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>比赛链接：[飞桨学习赛：遥感影像地块分割](https://aistudio.baidu.com/aistudio/competition/detail/63/0/introduction)\n",
    "</font>\n",
    "\n",
    "\n",
    "## 0、赛题介绍\n",
    "* 本赛题由 2020 CCF BDCI 遥感影像地块分割 初赛赛题改编而来。遥感影像地块分割, 旨在对遥感影像进行像素级内容解析，对遥感影像中感兴趣的类别进行提取和分类，在城乡规划、防汛救灾等领域具有很高的实用价值，在工业界也受到了广泛关注。现有的遥感影像地块分割数据处理方法局限于特定的场景和特定的数据来源，且精度无法满足需求。因此在实际应用中，仍然大量依赖于人工处理，需要消耗大量的人力、物力、财力。本赛题旨在衡量遥感影像地块分割模型在多个类别（如建筑、道路、林地等）上的效果，利用人工智能技术，对多来源、多场景的异构遥感影像数据进行充分挖掘，打造高效、实用的算法，提高遥感影像的分析提取能力。 赛题任务 本赛题旨在对遥感影像进行像素级内容解析，并对遥感影像中感兴趣的类别进行提取和分类，以衡量遥感影像地块分割模型在多个类别（如建筑、道路、林地等）上的效果。\n",
    "\n",
    "* 本赛题提供了多个地区已脱敏的遥感影像数据，各参赛选手可以基于这些数据构建自己的地块分割模型。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/a829cd4f77cf4ad79a887e6b6151593f8aae2fb804364296a20ad62ace079fa7)\n",
    "\n",
    "\n",
    "\n",
    "### 数据集特性\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/26f2b1cc7b514c088e5f3bcf4718c1caedb482a89f65478cb3cdd76406b6ba73)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/36ca749a37bc477180e9be08cf5f14e8eff3792fc1704f0a9b10bf07f3405923)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1、环境配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-11-15T10:03:10.317503Z",
     "iopub.status.busy": "2022-11-15T10:03:10.316846Z",
     "iopub.status.idle": "2022-11-15T10:04:25.557885Z",
     "shell.execute_reply": "2022-11-15T10:04:25.556791Z",
     "shell.execute_reply.started": "2022-11-15T10:03:10.317456Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正克隆到 'PaddleSeg'...\r\n",
      "remote: Enumerating objects: 20171, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (5140/5140), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (2425/2425), done.\u001b[K\r\n",
      "remote: Total 20171 (delta 3243), reused 4335 (delta 2647), pack-reused 15031\u001b[K\r\n",
      "接收对象中: 100% (20171/20171), 345.54 MiB | 6.09 MiB/s, 完成.\r\n",
      "处理 delta 中: 100% (13103/13103), 完成.\r\n",
      "检查连接... 完成。\r\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r PaddleSeg/requirements.txt (line 1)) (5.1.2)\r\n",
      "Requirement already satisfied: visualdl>=2.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r PaddleSeg/requirements.txt (line 2)) (2.4.0)\r\n",
      "Requirement already satisfied: opencv-python in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r PaddleSeg/requirements.txt (line 3)) (4.6.0.66)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r PaddleSeg/requirements.txt (line 4)) (4.64.1)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r PaddleSeg/requirements.txt (line 5)) (3.0.12)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r PaddleSeg/requirements.txt (line 6)) (1.6.3)\r\n",
      "Requirement already satisfied: prettytable in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r PaddleSeg/requirements.txt (line 7)) (0.7.2)\r\n",
      "Requirement already satisfied: sklearn in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from -r PaddleSeg/requirements.txt (line 8)) (0.0)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.0->-r PaddleSeg/requirements.txt (line 2)) (2.2.3)\r\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.0->-r PaddleSeg/requirements.txt (line 2)) (1.16.0)\r\n",
      "Requirement already satisfied: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.0->-r PaddleSeg/requirements.txt (line 2)) (1.0.0)\r\n",
      "Requirement already satisfied: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.0->-r PaddleSeg/requirements.txt (line 2)) (0.8.53)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.0->-r PaddleSeg/requirements.txt (line 2)) (1.19.5)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.0->-r PaddleSeg/requirements.txt (line 2)) (1.1.5)\r\n",
      "Requirement already satisfied: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.0->-r PaddleSeg/requirements.txt (line 2)) (3.20.0)\r\n",
      "Requirement already satisfied: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.0->-r PaddleSeg/requirements.txt (line 2)) (1.1.1)\r\n",
      "Requirement already satisfied: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.0->-r PaddleSeg/requirements.txt (line 2)) (2.24.0)\r\n",
      "Requirement already satisfied: Pillow>=7.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.0->-r PaddleSeg/requirements.txt (line 2)) (8.2.0)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from sklearn->-r PaddleSeg/requirements.txt (line 8)) (0.24.2)\r\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.2.0->-r PaddleSeg/requirements.txt (line 2)) (3.0.0)\r\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.2.0->-r PaddleSeg/requirements.txt (line 2)) (1.1.0)\r\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.2.0->-r PaddleSeg/requirements.txt (line 2)) (0.16.0)\r\n",
      "Requirement already satisfied: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.2.0->-r PaddleSeg/requirements.txt (line 2)) (8.0.4)\r\n",
      "Requirement already satisfied: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.2.0->-r PaddleSeg/requirements.txt (line 2)) (2.8.0)\r\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.2.0->-r PaddleSeg/requirements.txt (line 2)) (2019.3)\r\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.2.0->-r PaddleSeg/requirements.txt (line 2)) (3.9.9)\r\n",
      "Requirement already satisfied: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.2.0->-r PaddleSeg/requirements.txt (line 2)) (0.18.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl>=2.2.0->-r PaddleSeg/requirements.txt (line 2)) (0.10.0)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl>=2.2.0->-r PaddleSeg/requirements.txt (line 2)) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl>=2.2.0->-r PaddleSeg/requirements.txt (line 2)) (2.8.2)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl>=2.2.0->-r PaddleSeg/requirements.txt (line 2)) (1.1.0)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.2.0->-r PaddleSeg/requirements.txt (line 2)) (2.8)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.2.0->-r PaddleSeg/requirements.txt (line 2)) (3.0.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.2.0->-r PaddleSeg/requirements.txt (line 2)) (2019.9.11)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.2.0->-r PaddleSeg/requirements.txt (line 2)) (1.25.6)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn->sklearn->-r PaddleSeg/requirements.txt (line 8)) (0.14.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn->sklearn->-r PaddleSeg/requirements.txt (line 8)) (2.1.0)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from click>=5.1->flask>=1.1.1->visualdl>=2.2.0->-r PaddleSeg/requirements.txt (line 2)) (4.2.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0.0rc2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask>=1.1.1->visualdl>=2.2.0->-r PaddleSeg/requirements.txt (line 2)) (2.0.1)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->visualdl>=2.2.0->-r PaddleSeg/requirements.txt (line 2)) (56.2.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata->click>=5.1->flask>=1.1.1->visualdl>=2.2.0->-r PaddleSeg/requirements.txt (line 2)) (4.3.0)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata->click>=5.1->flask>=1.1.1->visualdl>=2.2.0->-r PaddleSeg/requirements.txt (line 2)) (3.8.1)\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# 克隆paddleSeg的github仓库\n",
    "!git clone https://gitee.com/paddlepaddle/PaddleSeg.git\n",
    "!pip install -r PaddleSeg/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-11-15T10:04:35.052628Z",
     "iopub.status.busy": "2022-11-15T10:04:35.051948Z",
     "iopub.status.idle": "2022-11-15T10:05:17.074996Z",
     "shell.execute_reply": "2022-11-15T10:05:17.073794Z",
     "shell.execute_reply.started": "2022-11-15T10:04:35.052581Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 解压数据集\n",
    "!mkdir ~/PaddleSeg/datasets\n",
    "!unzip -q data/data77571/train_and_label.zip -d ~/PaddleSeg/datasets\n",
    "!unzip -q data/data77571/img_test.zip -d ~/PaddleSeg/datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3、数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （1）数据集划分模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-11-15T12:39:59.689562Z",
     "iopub.status.busy": "2022-11-15T12:39:59.688822Z",
     "iopub.status.idle": "2022-11-15T12:40:02.034213Z",
     "shell.execute_reply": "2022-11-15T12:40:02.033419Z",
     "shell.execute_reply.started": "2022-11-15T12:39:59.689530Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 67424\r\n",
      "img_train/T030431.jpg\r\n",
      "lab_train/T030431.png\r\n",
      "('img_train/T095861.jpg', 'lab_train/T095861.png')\r\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.chdir('/home/aistudio/PaddleSeg/datasets/')\n",
    "\n",
    "datas = []\n",
    "image_base = 'img_train'   # 训练集原图路径\n",
    "annos_base = 'lab_train'   # 训练集标签路径\n",
    "\n",
    "# 读取原图文件名\n",
    "ids_ = [v.split('.')[0] for v in os.listdir(image_base)]\n",
    "\n",
    "# 将训练集的图像集和标签路径写入datas中\n",
    "for id_ in ids_:\n",
    "    img_pt0 = os.path.join(image_base, '{}.jpg'.format(id_))\n",
    "    img_pt1 = os.path.join(annos_base, '{}.png'.format(id_))\n",
    "    datas.append((img_pt0.replace('/home/aistudio', ''), img_pt1.replace('/home/aistudio', '')))\n",
    "    if os.path.exists(img_pt0) and os.path.exists(img_pt1):\n",
    "        pass\n",
    "    else:\n",
    "        raise \"path invalid!\"\n",
    "\n",
    "# 打印datas的长度和具体存储例子\n",
    "print('total:', len(datas))\n",
    "print(datas[0][0])\n",
    "print(datas[0][1])\n",
    "print(datas[10][:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （2）划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-11-15T12:40:04.111543Z",
     "iopub.status.busy": "2022-11-15T12:40:04.110609Z",
     "iopub.status.idle": "2022-11-15T12:40:06.294865Z",
     "shell.execute_reply": "2022-11-15T12:40:06.293590Z",
     "shell.execute_reply.started": "2022-11-15T12:40:04.111509Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 64053\r\n",
      "valid: 3371\r\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "os.chdir('/home/aistudio/PaddleSeg/datasets/')\n",
    "# 四类标签，这里用处不大，比赛评测是以0、1、2、3类来对比评测的\n",
    "labels = ['建筑', '耕地', '林地', '其他']\n",
    "\n",
    "# 将labels写入标签文件\n",
    "with open('labels.txt', 'w') as f:\n",
    "    for v in labels:\n",
    "        f.write(v+'\\n')\n",
    "\n",
    "# 随机打乱datas\n",
    "np.random.seed(3407)\n",
    "np.random.shuffle(datas)\n",
    "\n",
    "# 验证集与训练集的划分，0.05表示5%为验证集，95%为训练集\n",
    "split_num = int(0.05*len(datas))\n",
    "\n",
    "# 划分训练集和验证集\n",
    "train_data = datas[:-split_num]\n",
    "valid_data = datas[-split_num:]\n",
    "\n",
    "# 写入训练集list\n",
    "with open('train_list.txt', 'w') as f:\n",
    "    for img, lbl in train_data:\n",
    "        f.write(img + ' ' + lbl + '\\n')\n",
    "\n",
    "# 写入验证集list\n",
    "with open('val_list.txt', 'w') as f:\n",
    "    for img, lbl in valid_data:\n",
    "        # 进行数据清洗，数据验证过程中，对于全为255的图像直接忽略\n",
    "        clean = cv2.imread(lbl)\n",
    "        if (clean == 255).all():\n",
    "            continue\n",
    "        f.write(img + ' ' + lbl + '\\n')\n",
    "\n",
    "# 打印训练集和测试集大小\n",
    "print('train:', len(train_data))\n",
    "print('valid:', len(valid_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （3）分析数据类别样本数量[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-11-15T12:40:07.476640Z",
     "iopub.status.busy": "2022-11-15T12:40:07.475882Z",
     "iopub.status.idle": "2022-11-15T12:40:47.617930Z",
     "shell.execute_reply": "2022-11-15T12:40:47.616985Z",
     "shell.execute_reply.started": "2022-11-15T12:40:07.476608Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前已读取0个样本，进度为 0.0%\r\n",
      "当前已读取5000个样本，进度为 7.8060600004995875%\r\n",
      "当前已读取10000个样本，进度为 15.612120000999175%\r\n",
      "当前已读取15000个样本，进度为 23.418180001498765%\r\n",
      "当前已读取20000个样本，进度为 31.22424000199835%\r\n",
      "当前已读取25000个样本，进度为 39.030300002497945%\r\n",
      "当前已读取30000个样本，进度为 46.83636000299753%\r\n",
      "当前已读取35000个样本，进度为 54.642420003497115%\r\n",
      "当前已读取40000个样本，进度为 62.4484800039967%\r\n",
      "当前已读取45000个样本，进度为 70.25454000449629%\r\n",
      "当前已读取50000个样本，进度为 78.06060000499589%\r\n",
      "当前已读取55000个样本，进度为 85.86666000549546%\r\n",
      "当前已读取60000个样本，进度为 93.67272000599506%\r\n",
      "{0: 0.05662774723285185, 1: 0.07080380284899565, 2: 0.03490974336102769, 3: 0.03852830397623599, 255: 0.7991304025808889}\r\n",
      "{0: {0: 45770, 1: 1325, 2: 16303, 3: 655}, 1: {0: 38196, 1: 1823, 2: 24034, 3: 0}, 2: {0: 44354, 1: 2050, 2: 17467, 3: 182}, 3: {0: 48485, 1: 1731, 2: 13621, 3: 216}}\r\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "area = {i : 0 for i in range(NUM_CLASSES)}\n",
    "area_proportion = {i : {0 : 0, 1 : 0, 2 : 0, 3 : 0} for i in range(NUM_CLASSES)}\n",
    "area[255] = 0\n",
    "image_num = 0\n",
    "\n",
    "def calc(image, num_classes=NUM_CLASSES):\n",
    "    label_image = np.array(image)\n",
    "    for cls in range(num_classes):\n",
    "        area[cls] += np.count_nonzero(label_image == cls)\n",
    "    area[255] += np.count_nonzero(label_image == 255)\n",
    "\n",
    "def area_calc(image, num_classes=NUM_CLASSES):\n",
    "    label_image = np.array(image)\n",
    "    image_area = label_image.shape[0] * label_image.shape[1]\n",
    "    for cls in range(num_classes):\n",
    "        proportion = np.count_nonzero(label_image == cls) / float(image_area)\n",
    "        if proportion < 0.01:\n",
    "            area_proportion[cls][0] += 1\n",
    "        elif proportion < 0.02:\n",
    "            area_proportion[cls][1] += 1\n",
    "        elif proportion < 0.8:\n",
    "            area_proportion[cls][2] += 1\n",
    "        else:\n",
    "            area_proportion[cls][3] += 1\n",
    "\n",
    "\n",
    "# 统计四种类型的面积占比\n",
    "train_file_dir = '/home/aistudio/PaddleSeg/datasets/train_list.txt'\n",
    "val_file_dir = '/home/aistudio/PaddleSeg/datasets/val_list.txt'\n",
    "with open(train_file_dir, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        if image_num % 5000 == 0:\n",
    "            print(\"当前已读取\"+str(image_num)+\"个样本，进度为 \"+str(100*image_num/len(os.listdir(\"img_train\"))/0.95)+\"%\")\n",
    "        label_dir = line.split()[1]\n",
    "        image_label = cv2.imread(label_dir, cv2.IMREAD_GRAYSCALE)\n",
    "        calc(image_label)\n",
    "        area_calc(image_label)\n",
    "        image_num += 1\n",
    "\n",
    "\n",
    "for cls in range(NUM_CLASSES):\n",
    "    area[cls] = area[cls] / (image_num * 256.0 * 256.0)\n",
    "area[255] = area[255] / (image_num * 256.0 * 256.0)\n",
    "print(area)\n",
    "print(area_proportion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （4）对已划分的数据集进行重采样\n",
    "**在训练过程中发现第三类mIoU明显低于其他类别，并且发现第一类和第三类非常相似，考虑对第三类进行重采样，并进行额外的数据增强。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-15T12:40:47.631013Z",
     "iopub.status.busy": "2022-11-15T12:40:47.630812Z",
     "iopub.status.idle": "2022-11-15T12:41:38.525736Z",
     "shell.execute_reply": "2022-11-15T12:41:38.524800Z",
     "shell.execute_reply.started": "2022-11-15T12:40:47.630994Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前已读取0个样本，进度为 0.0%\r\n",
      "当前已读取5000个样本，进度为 7.806035626746601%\r\n",
      "当前已读取10000个样本，进度为 15.612071253493202%\r\n",
      "当前已读取15000个样本，进度为 23.4181068802398%\r\n",
      "当前已读取20000个样本，进度为 31.224142506986404%\r\n",
      "当前已读取25000个样本，进度为 39.030178133733%\r\n",
      "当前已读取30000个样本，进度为 46.8362137604796%\r\n",
      "当前已读取35000个样本，进度为 54.6422493872262%\r\n",
      "当前已读取40000个样本，进度为 62.44828501397281%\r\n",
      "当前已读取45000个样本，进度为 70.2543206407194%\r\n",
      "当前已读取50000个样本，进度为 78.060356267466%\r\n",
      "当前已读取55000个样本，进度为 85.86639189421261%\r\n",
      "当前已读取60000个样本，进度为 93.6724275209592%\r\n",
      "对含有该类的图像数量为： 8160\r\n",
      "对含有该类的图像并进行重采样的数量为： 819\r\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "os.chdir('/home/aistudio/PaddleSeg/datasets/')\n",
    "\n",
    "PROB = 0.1  #重采样概率\n",
    "\n",
    "with open('train_list.txt', 'r') as f:  #把txt写入list中\n",
    "    lines = f.readlines()\n",
    "\n",
    "#如果发现类别3存在于img中，那么把该图像的位置在train_list里复制一次\n",
    "with open('train_list.txt', 'a+') as f:\n",
    "    index = 0\n",
    "    count = 0\n",
    "    samp_count = 0\n",
    "    for line in lines:\n",
    "        if index % 5000 == 0:\n",
    "            print(\"当前已读取\"+str(index)+\"个样本，进度为 \"+str(100*index/len(lines))+\"%\")\n",
    "        label_dir = line.split()[1]\n",
    "        train_dir = line.split()[0]\n",
    "        image_label = cv2.imread(label_dir, cv2.IMREAD_GRAYSCALE)\n",
    "        if 3 in image_label[0]:\n",
    "            img = cv2.imread(train_dir, cv2.IMREAD_COLOR)\n",
    "            count += 1\n",
    "            if np.random.random()<PROB:\n",
    "                f.write(\"img_train/T{}.jpg\".format(\"RE\"+str(index))+' '+\"lab_train/T{}.png\".format(\"RE\"+str(index))+\"\\n\")\n",
    "                rand_rotate = np.random.randint(0,3)\n",
    "                img_t = cv2.rotate(cv2.bilateralFilter(img, 9, 75, 75), rand_rotate) #随机旋转并且进行双边模糊\n",
    "                lab_t = cv2.rotate(image_label, rand_rotate)\n",
    "                cv2.imwrite(\"img_train/T{}.jpg\".format(\"RE\"+str(index)),img_t)\n",
    "                cv2.imwrite(\"lab_train/T{}.png\".format(\"RE\"+str(index)),lab_t)\n",
    "                samp_count += 1\n",
    "        index += 1\n",
    "\n",
    "print(\"对含有该类的图像数量为：\", count)\n",
    "print(\"对含有该类的图像并进行重采样的数量为：\", samp_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第二类和第三类的像素点数量都一样少，但第三类的mIoU更低\n",
    "猜想可能是数量最多第一类影响了第三类的mIoU**\n",
    "\n",
    "**若同时对第二类进行重采样，mIoU略微下降**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/29b2de03209e4d8e9efcf654d5f6e31535ee14220425445391199fe40ca378b3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5、模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/d3da1d6ef87945a287e71e8287134bcfe5542dee7139402cb5f602097ba5ad54)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-15T12:41:43.604410Z",
     "iopub.status.busy": "2022-11-15T12:41:43.603493Z",
     "iopub.status.idle": "2022-11-15T12:41:44.381007Z",
     "shell.execute_reply": "2022-11-15T12:41:44.379604Z",
     "shell.execute_reply.started": "2022-11-15T12:41:43.604376Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio\r\n"
     ]
    }
   ],
   "source": [
    "#将work中的配置文件复制到PaddleSeg中\n",
    "%cd ~\n",
    "!cp work/Configs/segformer_b2_cityscapes_1024x1024_160k.yml PaddleSeg/configs/segformer/segformer_b2_cityscapes_1024x1024_160k.yml\n",
    "!cp work/Configs/custom_256x256.yml PaddleSeg/configs/_base_/custom_256x256.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.status.idle": "2022-11-16T14:45:33.733590Z",
     "shell.execute_reply": "2022-11-16T14:45:33.731878Z",
     "shell.execute_reply.started": "2022-11-15T12:41:45.978152Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3094/3094 [==============================] - 156s 51ms/step - batch_cost: 0.0504 - reader cost: 9.2913e-05\r\n",
      "2022-11-16 17:41:02 [INFO]\t[EVAL] #Images: 3094 mIoU: 0.6218 Acc: 0.7837 Kappa: 0.7004 Dice: 0.7621\r\n",
      "2022-11-16 17:41:02 [INFO]\t[EVAL] Class IoU: \r\n",
      "[0.5991 0.7741 0.621  0.4929]\r\n",
      "2022-11-16 17:41:02 [INFO]\t[EVAL] Class Precision: \r\n",
      "[0.7796 0.8502 0.7416 0.6823]\r\n",
      "2022-11-16 17:41:02 [INFO]\t[EVAL] Class Recall: \r\n",
      "[0.7213 0.8963 0.7925 0.6398]\r\n",
      "2022-11-16 17:41:03 [INFO]\t[EVAL] The model with the best validation mIoU (0.6226) was saved at iter 202000.\r\n",
      "2022-11-16 17:41:17 [INFO]\t[TRAIN] epoch: 54, iter: 216050/640000, loss: 0.5425, lr: 0.000041, batch_cost: 0.2749, reader_cost: 0.00014, ips: 58.1933 samples/sec | ETA 32:22:43\r\n",
      "2022-11-16 17:41:31 [INFO]\t[TRAIN] epoch: 54, iter: 216100/640000, loss: 0.5745, lr: 0.000041, batch_cost: 0.2747, reader_cost: 0.00014, ips: 58.2364 samples/sec | ETA 32:21:03\r\n",
      "2022-11-16 17:41:44 [INFO]\t[TRAIN] epoch: 54, iter: 216150/640000, loss: 0.5054, lr: 0.000041, batch_cost: 0.2733, reader_cost: 0.00013, ips: 58.5527 samples/sec | ETA 32:10:20\r\n",
      "2022-11-16 17:41:58 [INFO]\t[TRAIN] epoch: 54, iter: 216200/640000, loss: 0.5384, lr: 0.000041, batch_cost: 0.2720, reader_cost: 0.00014, ips: 58.8341 samples/sec | ETA 32:00:52\r\n",
      "2022-11-16 17:42:11 [INFO]\t[TRAIN] epoch: 54, iter: 216250/640000, loss: 0.5288, lr: 0.000041, batch_cost: 0.2707, reader_cost: 0.00013, ips: 59.1110 samples/sec | ETA 31:51:39\r\n",
      "2022-11-16 17:42:25 [INFO]\t[TRAIN] epoch: 54, iter: 216300/640000, loss: 0.5152, lr: 0.000041, batch_cost: 0.2725, reader_cost: 0.00013, ips: 58.7099 samples/sec | ETA 32:04:29\r\n",
      "2022-11-16 17:42:39 [INFO]\t[TRAIN] epoch: 54, iter: 216350/640000, loss: 0.5521, lr: 0.000041, batch_cost: 0.2751, reader_cost: 0.00014, ips: 58.1672 samples/sec | ETA 32:22:13\r\n",
      "2022-11-16 17:42:53 [INFO]\t[TRAIN] epoch: 54, iter: 216400/640000, loss: 0.5217, lr: 0.000041, batch_cost: 0.2798, reader_cost: 0.00014, ips: 57.1778 samples/sec | ETA 32:55:35\r\n",
      "2022-11-16 17:43:07 [INFO]\t[TRAIN] epoch: 54, iter: 216450/640000, loss: 0.5339, lr: 0.000041, batch_cost: 0.2843, reader_cost: 0.00016, ips: 56.2845 samples/sec | ETA 33:26:42\r\n",
      "2022-11-16 17:43:21 [INFO]\t[TRAIN] epoch: 54, iter: 216500/640000, loss: 0.5404, lr: 0.000041, batch_cost: 0.2830, reader_cost: 0.00016, ips: 56.5374 samples/sec | ETA 33:17:29\r\n",
      "2022-11-16 17:43:35 [INFO]\t[TRAIN] epoch: 54, iter: 216550/640000, loss: 0.5918, lr: 0.000041, batch_cost: 0.2759, reader_cost: 0.00014, ips: 57.9964 samples/sec | ETA 32:27:00\r\n",
      "2022-11-16 17:43:49 [INFO]\t[TRAIN] epoch: 54, iter: 216600/640000, loss: 0.5406, lr: 0.000041, batch_cost: 0.2741, reader_cost: 0.00015, ips: 58.3825 samples/sec | ETA 32:13:54\r\n",
      "2022-11-16 17:44:02 [INFO]\t[TRAIN] epoch: 54, iter: 216650/640000, loss: 0.4858, lr: 0.000041, batch_cost: 0.2749, reader_cost: 0.00014, ips: 58.2001 samples/sec | ETA 32:19:44\r\n",
      "2022-11-16 17:44:16 [INFO]\t[TRAIN] epoch: 54, iter: 216700/640000, loss: 0.5469, lr: 0.000041, batch_cost: 0.2763, reader_cost: 0.00014, ips: 57.9167 samples/sec | ETA 32:29:00\r\n",
      "2022-11-16 17:44:30 [INFO]\t[TRAIN] epoch: 54, iter: 216750/640000, loss: 0.5036, lr: 0.000041, batch_cost: 0.2760, reader_cost: 0.00014, ips: 57.9700 samples/sec | ETA 32:26:59\r\n",
      "2022-11-16 17:44:44 [INFO]\t[TRAIN] epoch: 54, iter: 216800/640000, loss: 0.4946, lr: 0.000041, batch_cost: 0.2754, reader_cost: 0.00013, ips: 58.0979 samples/sec | ETA 32:22:28\r\n",
      "2022-11-16 17:44:58 [INFO]\t[TRAIN] epoch: 54, iter: 216850/640000, loss: 0.4920, lr: 0.000041, batch_cost: 0.2775, reader_cost: 0.00014, ips: 57.6547 samples/sec | ETA 32:37:10\r\n",
      "2022-11-16 17:45:11 [INFO]\t[TRAIN] epoch: 54, iter: 216900/640000, loss: 0.5370, lr: 0.000041, batch_cost: 0.2719, reader_cost: 0.00013, ips: 58.8503 samples/sec | ETA 31:57:10\r\n",
      "2022-11-16 17:45:25 [INFO]\t[TRAIN] epoch: 54, iter: 216950/640000, loss: 0.5800, lr: 0.000041, batch_cost: 0.2729, reader_cost: 0.00013, ips: 58.6382 samples/sec | ETA 32:03:53\r\n",
      "2022-11-16 17:45:38 [INFO]\t[TRAIN] epoch: 54, iter: 217000/640000, loss: 0.5235, lr: 0.000041, batch_cost: 0.2728, reader_cost: 0.00014, ips: 58.6610 samples/sec | ETA 32:02:54\r\n",
      "2022-11-16 17:45:52 [INFO]\t[TRAIN] epoch: 54, iter: 217050/640000, loss: 0.5745, lr: 0.000041, batch_cost: 0.2740, reader_cost: 0.00013, ips: 58.3947 samples/sec | ETA 32:11:27\r\n",
      "2022-11-16 17:46:06 [INFO]\t[TRAIN] epoch: 54, iter: 217100/640000, loss: 0.5705, lr: 0.000041, batch_cost: 0.2734, reader_cost: 0.00013, ips: 58.5277 samples/sec | ETA 32:06:50\r\n",
      "2022-11-16 17:46:19 [INFO]\t[TRAIN] epoch: 54, iter: 217150/640000, loss: 0.5744, lr: 0.000041, batch_cost: 0.2727, reader_cost: 0.00013, ips: 58.6646 samples/sec | ETA 32:02:06\r\n",
      "2022-11-16 17:46:33 [INFO]\t[TRAIN] epoch: 54, iter: 217200/640000, loss: 0.5618, lr: 0.000041, batch_cost: 0.2722, reader_cost: 0.00013, ips: 58.7702 samples/sec | ETA 31:58:25\r\n",
      "2022-11-16 17:46:47 [INFO]\t[TRAIN] epoch: 54, iter: 217250/640000, loss: 0.5119, lr: 0.000041, batch_cost: 0.2705, reader_cost: 0.00013, ips: 59.1533 samples/sec | ETA 31:45:46\r\n",
      "2022-11-16 17:47:00 [INFO]\t[TRAIN] epoch: 54, iter: 217300/640000, loss: 0.5623, lr: 0.000041, batch_cost: 0.2739, reader_cost: 0.00013, ips: 58.4156 samples/sec | ETA 32:09:37\r\n",
      "2022-11-16 17:47:14 [INFO]\t[TRAIN] epoch: 54, iter: 217350/640000, loss: 0.5076, lr: 0.000041, batch_cost: 0.2720, reader_cost: 0.00014, ips: 58.8199 samples/sec | ETA 31:56:07\r\n",
      "2022-11-16 17:47:27 [INFO]\t[TRAIN] epoch: 54, iter: 217400/640000, loss: 0.5481, lr: 0.000041, batch_cost: 0.2715, reader_cost: 0.00013, ips: 58.9362 samples/sec | ETA 31:52:07\r\n",
      "2022-11-16 17:47:41 [INFO]\t[TRAIN] epoch: 54, iter: 217450/640000, loss: 0.5581, lr: 0.000041, batch_cost: 0.2727, reader_cost: 0.00014, ips: 58.6763 samples/sec | ETA 32:00:21\r\n",
      "2022-11-16 17:47:55 [INFO]\t[TRAIN] epoch: 54, iter: 217500/640000, loss: 0.5248, lr: 0.000041, batch_cost: 0.2720, reader_cost: 0.00014, ips: 58.8170 samples/sec | ETA 31:55:32\r\n",
      "2022-11-16 17:48:08 [INFO]\t[TRAIN] epoch: 54, iter: 217550/640000, loss: 0.5588, lr: 0.000041, batch_cost: 0.2743, reader_cost: 0.00013, ips: 58.3322 samples/sec | ETA 32:11:14\r\n",
      "2022-11-16 17:48:22 [INFO]\t[TRAIN] epoch: 54, iter: 217600/640000, loss: 0.5601, lr: 0.000041, batch_cost: 0.2730, reader_cost: 0.00013, ips: 58.6093 samples/sec | ETA 32:01:52\r\n",
      "2022-11-16 17:48:36 [INFO]\t[TRAIN] epoch: 54, iter: 217650/640000, loss: 0.5685, lr: 0.000041, batch_cost: 0.2717, reader_cost: 0.00013, ips: 58.8956 samples/sec | ETA 31:52:18\r\n",
      "2022-11-16 17:48:49 [INFO]\t[TRAIN] epoch: 54, iter: 217700/640000, loss: 0.5284, lr: 0.000041, batch_cost: 0.2703, reader_cost: 0.00014, ips: 59.1974 samples/sec | ETA 31:42:20\r\n",
      "2022-11-16 17:49:03 [INFO]\t[TRAIN] epoch: 54, iter: 217750/640000, loss: 0.5562, lr: 0.000041, batch_cost: 0.2721, reader_cost: 0.00013, ips: 58.7944 samples/sec | ETA 31:55:08\r\n",
      "2022-11-16 17:49:17 [INFO]\t[TRAIN] epoch: 54, iter: 217800/640000, loss: 0.5482, lr: 0.000041, batch_cost: 0.2748, reader_cost: 0.00014, ips: 58.2243 samples/sec | ETA 32:13:40\r\n",
      "2022-11-16 17:49:30 [INFO]\t[TRAIN] epoch: 54, iter: 217850/640000, loss: 0.5224, lr: 0.000041, batch_cost: 0.2715, reader_cost: 0.00013, ips: 58.9243 samples/sec | ETA 31:50:28\r\n",
      "2022-11-16 17:49:44 [INFO]\t[TRAIN] epoch: 54, iter: 217900/640000, loss: 0.5547, lr: 0.000041, batch_cost: 0.2710, reader_cost: 0.00013, ips: 59.0433 samples/sec | ETA 31:46:23\r\n",
      "2022-11-16 17:49:57 [INFO]\t[TRAIN] epoch: 54, iter: 217950/640000, loss: 0.5651, lr: 0.000041, batch_cost: 0.2724, reader_cost: 0.00014, ips: 58.7340 samples/sec | ETA 31:56:12\r\n",
      "2022-11-16 17:50:11 [INFO]\t[TRAIN] epoch: 54, iter: 218000/640000, loss: 0.5367, lr: 0.000041, batch_cost: 0.2744, reader_cost: 0.00013, ips: 58.3103 samples/sec | ETA 32:09:54\r\n",
      "2022-11-16 17:50:11 [INFO]\tStart evaluating (total_samples: 3094, total_iters: 3094)...\r\n",
      "3094/3094 [==============================] - 153s 49ms/step - batch_cost: 0.0492 - reader cost: 8.5966e-05\r\n",
      "2022-11-16 17:52:44 [INFO]\t[EVAL] #Images: 3094 mIoU: 0.6216 Acc: 0.7845 Kappa: 0.7010 Dice: 0.7618\r\n",
      "2022-11-16 17:52:44 [INFO]\t[EVAL] Class IoU: \r\n",
      "[0.6034 0.7778 0.6158 0.4894]\r\n",
      "2022-11-16 17:52:44 [INFO]\t[EVAL] Class Precision: \r\n",
      "[0.7557 0.8551 0.7479 0.7028]\r\n",
      "2022-11-16 17:52:44 [INFO]\t[EVAL] Class Recall: \r\n",
      "[0.7496 0.8959 0.7771 0.6171]\r\n",
      "2022-11-16 17:52:44 [INFO]\t[EVAL] The model with the best validation mIoU (0.6226) was saved at iter 202000.\r\n",
      "2022-11-16 17:52:58 [INFO]\t[TRAIN] epoch: 54, iter: 218050/640000, loss: 0.5245, lr: 0.000041, batch_cost: 0.2719, reader_cost: 0.00013, ips: 58.8387 samples/sec | ETA 31:52:20\r\n",
      "2022-11-16 17:53:11 [INFO]\t[TRAIN] epoch: 54, iter: 218100/640000, loss: 0.5647, lr: 0.000041, batch_cost: 0.2729, reader_cost: 0.00014, ips: 58.6253 samples/sec | ETA 31:59:04\r\n",
      "2022-11-16 17:53:25 [INFO]\t[TRAIN] epoch: 54, iter: 218150/640000, loss: 0.5654, lr: 0.000041, batch_cost: 0.2716, reader_cost: 0.00013, ips: 58.9056 samples/sec | ETA 31:49:43\r\n",
      "2022-11-16 17:53:38 [INFO]\t[TRAIN] epoch: 54, iter: 218200/640000, loss: 0.5372, lr: 0.000041, batch_cost: 0.2720, reader_cost: 0.00013, ips: 58.8326 samples/sec | ETA 31:51:51\r\n",
      "2022-11-16 17:53:52 [INFO]\t[TRAIN] epoch: 54, iter: 218250/640000, loss: 0.5603, lr: 0.000041, batch_cost: 0.2750, reader_cost: 0.00014, ips: 58.1868 samples/sec | ETA 32:12:51\r\n",
      "2022-11-16 17:54:06 [INFO]\t[TRAIN] epoch: 54, iter: 218300/640000, loss: 0.5254, lr: 0.000041, batch_cost: 0.2842, reader_cost: 0.00015, ips: 56.2916 samples/sec | ETA 33:17:41\r\n",
      "2022-11-16 17:54:21 [INFO]\t[TRAIN] epoch: 54, iter: 218350/640000, loss: 0.5215, lr: 0.000041, batch_cost: 0.2836, reader_cost: 0.00016, ips: 56.4241 samples/sec | ETA 33:12:45\r\n",
      "2022-11-16 17:54:35 [INFO]\t[TRAIN] epoch: 54, iter: 218400/640000, loss: 0.5544, lr: 0.000041, batch_cost: 0.2821, reader_cost: 0.00016, ips: 56.7223 samples/sec | ETA 33:02:03\r\n",
      "2022-11-16 17:54:49 [INFO]\t[TRAIN] epoch: 54, iter: 218450/640000, loss: 0.4978, lr: 0.000041, batch_cost: 0.2799, reader_cost: 0.00014, ips: 57.1653 samples/sec | ETA 32:46:27\r\n",
      "2022-11-16 17:55:02 [INFO]\t[TRAIN] epoch: 54, iter: 218500/640000, loss: 0.5540, lr: 0.000041, batch_cost: 0.2721, reader_cost: 0.00013, ips: 58.8050 samples/sec | ETA 31:51:24\r\n",
      "2022-11-16 17:55:16 [INFO]\t[TRAIN] epoch: 54, iter: 218550/640000, loss: 0.5798, lr: 0.000041, batch_cost: 0.2721, reader_cost: 0.00013, ips: 58.8067 samples/sec | ETA 31:51:07\r\n",
      "2022-11-16 17:55:30 [INFO]\t[TRAIN] epoch: 54, iter: 218600/640000, loss: 0.5917, lr: 0.000041, batch_cost: 0.2732, reader_cost: 0.00013, ips: 58.5575 samples/sec | ETA 31:59:01\r\n",
      "2022-11-16 17:55:43 [INFO]\t[TRAIN] epoch: 54, iter: 218650/640000, loss: 0.5057, lr: 0.000041, batch_cost: 0.2746, reader_cost: 0.00014, ips: 58.2626 samples/sec | ETA 32:08:30\r\n",
      "2022-11-16 17:55:57 [INFO]\t[TRAIN] epoch: 54, iter: 218700/640000, loss: 0.5277, lr: 0.000041, batch_cost: 0.2735, reader_cost: 0.00014, ips: 58.5102 samples/sec | ETA 32:00:07\r\n",
      "2022-11-16 17:56:11 [INFO]\t[TRAIN] epoch: 54, iter: 218750/640000, loss: 0.5552, lr: 0.000041, batch_cost: 0.2727, reader_cost: 0.00014, ips: 58.6693 samples/sec | ETA 31:54:41\r\n",
      "2022-11-16 17:56:24 [INFO]\t[TRAIN] epoch: 54, iter: 218800/640000, loss: 0.5381, lr: 0.000041, batch_cost: 0.2724, reader_cost: 0.00013, ips: 58.7445 samples/sec | ETA 31:52:00\r\n",
      "2022-11-16 17:56:38 [INFO]\t[TRAIN] epoch: 54, iter: 218850/640000, loss: 0.5154, lr: 0.000041, batch_cost: 0.2728, reader_cost: 0.00013, ips: 58.6441 samples/sec | ETA 31:55:03\r\n",
      "2022-11-16 17:56:52 [INFO]\t[TRAIN] epoch: 54, iter: 218900/640000, loss: 0.5726, lr: 0.000041, batch_cost: 0.2743, reader_cost: 0.00014, ips: 58.3241 samples/sec | ETA 32:05:20\r\n",
      "2022-11-16 17:57:05 [INFO]\t[TRAIN] epoch: 55, iter: 218950/640000, loss: 0.5529, lr: 0.000041, batch_cost: 0.2757, reader_cost: 0.00335, ips: 58.0364 samples/sec | ETA 32:14:38\r\n",
      "2022-11-16 17:57:19 [INFO]\t[TRAIN] epoch: 55, iter: 219000/640000, loss: 0.5465, lr: 0.000041, batch_cost: 0.2746, reader_cost: 0.00014, ips: 58.2721 samples/sec | ETA 32:06:35\r\n",
      "2022-11-16 17:57:33 [INFO]\t[TRAIN] epoch: 55, iter: 219050/640000, loss: 0.5295, lr: 0.000041, batch_cost: 0.2732, reader_cost: 0.00014, ips: 58.5617 samples/sec | ETA 31:56:50\r\n",
      "2022-11-16 17:57:46 [INFO]\t[TRAIN] epoch: 55, iter: 219100/640000, loss: 0.5076, lr: 0.000041, batch_cost: 0.2728, reader_cost: 0.00013, ips: 58.6407 samples/sec | ETA 31:54:01\r\n",
      "2022-11-16 17:58:00 [INFO]\t[TRAIN] epoch: 55, iter: 219150/640000, loss: 0.5380, lr: 0.000041, batch_cost: 0.2746, reader_cost: 0.00013, ips: 58.2642 samples/sec | ETA 32:06:10\r\n",
      "2022-11-16 17:58:14 [INFO]\t[TRAIN] epoch: 55, iter: 219200/640000, loss: 0.5671, lr: 0.000041, batch_cost: 0.2723, reader_cost: 0.00013, ips: 58.7671 samples/sec | ETA 31:49:27\r\n",
      "2022-11-16 17:58:28 [INFO]\t[TRAIN] epoch: 55, iter: 219250/640000, loss: 0.5360, lr: 0.000041, batch_cost: 0.2756, reader_cost: 0.00013, ips: 58.0626 samples/sec | ETA 32:12:23\r\n",
      "2022-11-16 17:58:42 [INFO]\t[TRAIN] epoch: 55, iter: 219300/640000, loss: 0.5594, lr: 0.000041, batch_cost: 0.2825, reader_cost: 0.00014, ips: 56.6369 samples/sec | ETA 33:00:48\r\n",
      "2022-11-16 17:58:55 [INFO]\t[TRAIN] epoch: 55, iter: 219350/640000, loss: 0.5491, lr: 0.000041, batch_cost: 0.2728, reader_cost: 0.00013, ips: 58.6535 samples/sec | ETA 31:52:28\r\n",
      "2022-11-16 17:59:09 [INFO]\t[TRAIN] epoch: 55, iter: 219400/640000, loss: 0.5051, lr: 0.000041, batch_cost: 0.2717, reader_cost: 0.00013, ips: 58.8992 samples/sec | ETA 31:44:16\r\n",
      "2022-11-16 17:59:23 [INFO]\t[TRAIN] epoch: 55, iter: 219450/640000, loss: 0.5159, lr: 0.000041, batch_cost: 0.2730, reader_cost: 0.00013, ips: 58.6139 samples/sec | ETA 31:53:18\r\n",
      "2022-11-16 17:59:36 [INFO]\t[TRAIN] epoch: 55, iter: 219500/640000, loss: 0.5411, lr: 0.000041, batch_cost: 0.2718, reader_cost: 0.00013, ips: 58.8614 samples/sec | ETA 31:45:02\r\n",
      "2022-11-16 17:59:50 [INFO]\t[TRAIN] epoch: 55, iter: 219550/640000, loss: 0.5389, lr: 0.000041, batch_cost: 0.2710, reader_cost: 0.00013, ips: 59.0436 samples/sec | ETA 31:38:56\r\n",
      "2022-11-16 18:00:03 [INFO]\t[TRAIN] epoch: 55, iter: 219600/640000, loss: 0.5290, lr: 0.000041, batch_cost: 0.2716, reader_cost: 0.00013, ips: 58.9031 samples/sec | ETA 31:43:14\r\n",
      "2022-11-16 18:00:17 [INFO]\t[TRAIN] epoch: 55, iter: 219650/640000, loss: 0.5065, lr: 0.000041, batch_cost: 0.2719, reader_cost: 0.00013, ips: 58.8444 samples/sec | ETA 31:44:54\r\n",
      "2022-11-16 18:00:30 [INFO]\t[TRAIN] epoch: 55, iter: 219700/640000, loss: 0.5791, lr: 0.000041, batch_cost: 0.2725, reader_cost: 0.00013, ips: 58.7230 samples/sec | ETA 31:48:37\r\n",
      "2022-11-16 18:00:44 [INFO]\t[TRAIN] epoch: 55, iter: 219750/640000, loss: 0.5424, lr: 0.000041, batch_cost: 0.2718, reader_cost: 0.00013, ips: 58.8566 samples/sec | ETA 31:44:03\r\n",
      "2022-11-16 18:00:58 [INFO]\t[TRAIN] epoch: 55, iter: 219800/640000, loss: 0.5266, lr: 0.000041, batch_cost: 0.2738, reader_cost: 0.00014, ips: 58.4277 samples/sec | ETA 31:57:48\r\n",
      "2022-11-16 18:01:11 [INFO]\t[TRAIN] epoch: 55, iter: 219850/640000, loss: 0.5002, lr: 0.000041, batch_cost: 0.2713, reader_cost: 0.00013, ips: 58.9820 samples/sec | ETA 31:39:33\r\n",
      "2022-11-16 18:01:25 [INFO]\t[TRAIN] epoch: 55, iter: 219900/640000, loss: 0.5388, lr: 0.000041, batch_cost: 0.2706, reader_cost: 0.00013, ips: 59.1255 samples/sec | ETA 31:34:43\r\n",
      "2022-11-16 18:01:38 [INFO]\t[TRAIN] epoch: 55, iter: 219950/640000, loss: 0.5053, lr: 0.000041, batch_cost: 0.2718, reader_cost: 0.00013, ips: 58.8735 samples/sec | ETA 31:42:36\r\n",
      "2022-11-16 18:01:52 [INFO]\t[TRAIN] epoch: 55, iter: 220000/640000, loss: 0.5381, lr: 0.000041, batch_cost: 0.2728, reader_cost: 0.00013, ips: 58.6589 samples/sec | ETA 31:49:20\r\n",
      "2022-11-16 18:01:52 [INFO]\tStart evaluating (total_samples: 3094, total_iters: 3094)...\r\n",
      "3094/3094 [==============================] - 154s 50ms/step - batch_cost: 0.0495 - reader cost: 8.9198e-05\r\n",
      "2022-11-16 18:04:26 [INFO]\t[EVAL] #Images: 3094 mIoU: 0.6164 Acc: 0.7804 Kappa: 0.6950 Dice: 0.7576\r\n",
      "2022-11-16 18:04:26 [INFO]\t[EVAL] Class IoU: \r\n",
      "[0.6023 0.7722 0.612  0.4789]\r\n",
      "2022-11-16 18:04:26 [INFO]\t[EVAL] Class Precision: \r\n",
      "[0.737  0.8548 0.7745 0.6864]\r\n",
      "2022-11-16 18:04:26 [INFO]\t[EVAL] Class Recall: \r\n",
      "[0.7671 0.8888 0.7447 0.6131]\r\n",
      "2022-11-16 18:04:26 [INFO]\t[EVAL] The model with the best validation mIoU (0.6226) was saved at iter 202000.\r\n",
      "2022-11-16 18:04:40 [INFO]\t[TRAIN] epoch: 55, iter: 220050/640000, loss: 0.4841, lr: 0.000041, batch_cost: 0.2735, reader_cost: 0.00014, ips: 58.5069 samples/sec | ETA 31:54:04\r\n",
      "2022-11-16 18:04:54 [INFO]\t[TRAIN] epoch: 55, iter: 220100/640000, loss: 0.5580, lr: 0.000041, batch_cost: 0.2747, reader_cost: 0.00014, ips: 58.2429 samples/sec | ETA 32:02:31\r\n",
      "2022-11-16 18:05:07 [INFO]\t[TRAIN] epoch: 55, iter: 220150/640000, loss: 0.5839, lr: 0.000041, batch_cost: 0.2727, reader_cost: 0.00014, ips: 58.6648 samples/sec | ETA 31:48:28\r\n",
      "2022-11-16 18:05:21 [INFO]\t[TRAIN] epoch: 55, iter: 220200/640000, loss: 0.5115, lr: 0.000041, batch_cost: 0.2720, reader_cost: 0.00014, ips: 58.8309 samples/sec | ETA 31:42:51\r\n",
      "2022-11-16 18:05:35 [INFO]\t[TRAIN] epoch: 55, iter: 220250/640000, loss: 0.5451, lr: 0.000041, batch_cost: 0.2754, reader_cost: 0.00015, ips: 58.1007 samples/sec | ETA 32:06:32\r\n",
      "2022-11-16 18:05:49 [INFO]\t[TRAIN] epoch: 55, iter: 220300/640000, loss: 0.5182, lr: 0.000041, batch_cost: 0.2758, reader_cost: 0.00014, ips: 58.0080 samples/sec | ETA 32:09:23\r\n",
      "2022-11-16 18:06:02 [INFO]\t[TRAIN] epoch: 55, iter: 220350/640000, loss: 0.5330, lr: 0.000041, batch_cost: 0.2739, reader_cost: 0.00014, ips: 58.4164 samples/sec | ETA 31:55:40\r\n",
      "2022-11-16 18:06:16 [INFO]\t[TRAIN] epoch: 55, iter: 220400/640000, loss: 0.5063, lr: 0.000041, batch_cost: 0.2719, reader_cost: 0.00013, ips: 58.8503 samples/sec | ETA 31:41:19\r\n",
      "2022-11-16 18:06:30 [INFO]\t[TRAIN] epoch: 55, iter: 220450/640000, loss: 0.5510, lr: 0.000041, batch_cost: 0.2724, reader_cost: 0.00013, ips: 58.7300 samples/sec | ETA 31:44:59\r\n",
      "2022-11-16 18:06:43 [INFO]\t[TRAIN] epoch: 55, iter: 220500/640000, loss: 0.5279, lr: 0.000041, batch_cost: 0.2723, reader_cost: 0.00014, ips: 58.7680 samples/sec | ETA 31:43:31\r\n",
      "2022-11-16 18:06:57 [INFO]\t[TRAIN] epoch: 55, iter: 220550/640000, loss: 0.4901, lr: 0.000041, batch_cost: 0.2726, reader_cost: 0.00014, ips: 58.7021 samples/sec | ETA 31:45:26\r\n",
      "2022-11-16 18:07:11 [INFO]\t[TRAIN] epoch: 55, iter: 220600/640000, loss: 0.5208, lr: 0.000041, batch_cost: 0.2754, reader_cost: 0.00014, ips: 58.0878 samples/sec | ETA 32:05:21\r\n",
      "2022-11-16 18:07:24 [INFO]\t[TRAIN] epoch: 55, iter: 220650/640000, loss: 0.5577, lr: 0.000041, batch_cost: 0.2744, reader_cost: 0.00016, ips: 58.3050 samples/sec | ETA 31:57:57\r\n",
      "2022-11-16 18:07:38 [INFO]\t[TRAIN] epoch: 55, iter: 220700/640000, loss: 0.5636, lr: 0.000041, batch_cost: 0.2758, reader_cost: 0.00014, ips: 58.0035 samples/sec | ETA 32:07:41\r\n",
      "2022-11-16 18:07:52 [INFO]\t[TRAIN] epoch: 55, iter: 220750/640000, loss: 0.5218, lr: 0.000041, batch_cost: 0.2754, reader_cost: 0.00014, ips: 58.1034 samples/sec | ETA 32:04:09\r\n",
      "2022-11-16 18:08:06 [INFO]\t[TRAIN] epoch: 55, iter: 220800/640000, loss: 0.5719, lr: 0.000041, batch_cost: 0.2752, reader_cost: 0.00014, ips: 58.1417 samples/sec | ETA 32:02:39\r\n",
      "2022-11-16 18:08:20 [INFO]\t[TRAIN] epoch: 55, iter: 220850/640000, loss: 0.5555, lr: 0.000041, batch_cost: 0.2790, reader_cost: 0.00014, ips: 57.3483 samples/sec | ETA 32:29:01\r\n",
      "2022-11-16 18:08:34 [INFO]\t[TRAIN] epoch: 55, iter: 220900/640000, loss: 0.5602, lr: 0.000041, batch_cost: 0.2830, reader_cost: 0.00015, ips: 56.5431 samples/sec | ETA 32:56:32\r\n",
      "2022-11-16 18:08:48 [INFO]\t[TRAIN] epoch: 55, iter: 220950/640000, loss: 0.5823, lr: 0.000041, batch_cost: 0.2793, reader_cost: 0.00014, ips: 57.2878 samples/sec | ETA 32:30:37\r\n",
      "2022-11-16 18:09:01 [INFO]\t[TRAIN] epoch: 55, iter: 221000/640000, loss: 0.5652, lr: 0.000041, batch_cost: 0.2728, reader_cost: 0.00013, ips: 58.6597 samples/sec | ETA 31:44:46\r\n",
      "2022-11-16 18:09:15 [INFO]\t[TRAIN] epoch: 55, iter: 221050/640000, loss: 0.5166, lr: 0.000041, batch_cost: 0.2758, reader_cost: 0.00014, ips: 58.0068 samples/sec | ETA 32:05:58\r\n",
      "2022-11-16 18:09:29 [INFO]\t[TRAIN] epoch: 55, iter: 221100/640000, loss: 0.5572, lr: 0.000041, batch_cost: 0.2745, reader_cost: 0.00014, ips: 58.2829 samples/sec | ETA 31:56:37\r\n",
      "2022-11-16 18:09:43 [INFO]\t[TRAIN] epoch: 55, iter: 221150/640000, loss: 0.5296, lr: 0.000041, batch_cost: 0.2744, reader_cost: 0.00014, ips: 58.3002 samples/sec | ETA 31:55:49\r\n",
      "2022-11-16 18:09:56 [INFO]\t[TRAIN] epoch: 55, iter: 221200/640000, loss: 0.5252, lr: 0.000041, batch_cost: 0.2744, reader_cost: 0.00014, ips: 58.3066 samples/sec | ETA 31:55:23\r\n",
      "2022-11-16 18:10:10 [INFO]\t[TRAIN] epoch: 55, iter: 221250/640000, loss: 0.5514, lr: 0.000041, batch_cost: 0.2756, reader_cost: 0.00014, ips: 58.0650 samples/sec | ETA 32:03:07\r\n",
      "2022-11-16 18:10:24 [INFO]\t[TRAIN] epoch: 55, iter: 221300/640000, loss: 0.5729, lr: 0.000041, batch_cost: 0.2773, reader_cost: 0.00014, ips: 57.6924 samples/sec | ETA 32:15:19\r\n",
      "2022-11-16 18:10:38 [INFO]\t[TRAIN] epoch: 55, iter: 221350/640000, loss: 0.5314, lr: 0.000041, batch_cost: 0.2743, reader_cost: 0.00014, ips: 58.3352 samples/sec | ETA 31:53:45\r\n",
      "2022-11-16 18:10:51 [INFO]\t[TRAIN] epoch: 55, iter: 221400/640000, loss: 0.5410, lr: 0.000041, batch_cost: 0.2739, reader_cost: 0.00014, ips: 58.4258 samples/sec | ETA 31:50:34\r\n",
      "2022-11-16 18:11:05 [INFO]\t[TRAIN] epoch: 55, iter: 221450/640000, loss: 0.5157, lr: 0.000041, batch_cost: 0.2766, reader_cost: 0.00015, ips: 57.8411 samples/sec | ETA 32:09:39\r\n",
      "2022-11-16 18:11:19 [INFO]\t[TRAIN] epoch: 55, iter: 221500/640000, loss: 0.5585, lr: 0.000041, batch_cost: 0.2757, reader_cost: 0.00014, ips: 58.0389 samples/sec | ETA 32:02:50\r\n",
      "2022-11-16 18:11:33 [INFO]\t[TRAIN] epoch: 55, iter: 221550/640000, loss: 0.5904, lr: 0.000041, batch_cost: 0.2730, reader_cost: 0.00014, ips: 58.6018 samples/sec | ETA 31:44:08\r\n",
      "2022-11-16 18:11:46 [INFO]\t[TRAIN] epoch: 55, iter: 221600/640000, loss: 0.5447, lr: 0.000041, batch_cost: 0.2725, reader_cost: 0.00014, ips: 58.7228 samples/sec | ETA 31:39:59\r\n",
      "2022-11-16 18:12:00 [INFO]\t[TRAIN] epoch: 55, iter: 221650/640000, loss: 0.5467, lr: 0.000041, batch_cost: 0.2746, reader_cost: 0.00015, ips: 58.2734 samples/sec | ETA 31:54:25\r\n",
      "2022-11-16 18:12:14 [INFO]\t[TRAIN] epoch: 55, iter: 221700/640000, loss: 0.5012, lr: 0.000041, batch_cost: 0.2724, reader_cost: 0.00014, ips: 58.7414 samples/sec | ETA 31:38:56\r\n",
      "2022-11-16 18:12:27 [INFO]\t[TRAIN] epoch: 55, iter: 221750/640000, loss: 0.5260, lr: 0.000041, batch_cost: 0.2753, reader_cost: 0.00015, ips: 58.1176 samples/sec | ETA 31:59:05\r\n",
      "2022-11-16 18:12:41 [INFO]\t[TRAIN] epoch: 55, iter: 221800/640000, loss: 0.5794, lr: 0.000041, batch_cost: 0.2790, reader_cost: 0.00014, ips: 57.3551 samples/sec | ETA 32:24:22\r\n",
      "2022-11-16 18:12:55 [INFO]\t[TRAIN] epoch: 55, iter: 221850/640000, loss: 0.5399, lr: 0.000041, batch_cost: 0.2766, reader_cost: 0.00014, ips: 57.8554 samples/sec | ETA 32:07:19\r\n",
      "2022-11-16 18:13:09 [INFO]\t[TRAIN] epoch: 55, iter: 221900/640000, loss: 0.5483, lr: 0.000041, batch_cost: 0.2815, reader_cost: 0.00015, ips: 56.8455 samples/sec | ETA 32:41:20\r\n",
      "2022-11-16 18:13:23 [INFO]\t[TRAIN] epoch: 55, iter: 221950/640000, loss: 0.5427, lr: 0.000041, batch_cost: 0.2704, reader_cost: 0.00013, ips: 59.1726 samples/sec | ETA 31:23:58\r\n",
      "2022-11-16 18:13:36 [INFO]\t[TRAIN] epoch: 55, iter: 222000/640000, loss: 0.5641, lr: 0.000041, batch_cost: 0.2717, reader_cost: 0.00013, ips: 58.8794 samples/sec | ETA 31:33:08\r\n",
      "2022-11-16 18:13:36 [INFO]\tStart evaluating (total_samples: 3094, total_iters: 3094)...\r\n",
      "3094/3094 [==============================] - 156s 50ms/step - batch_cost: 0.0502 - reader cost: 9.4701e-05\r\n",
      "2022-11-16 18:16:12 [INFO]\t[EVAL] #Images: 3094 mIoU: 0.6212 Acc: 0.7824 Kappa: 0.6992 Dice: 0.7616\r\n",
      "2022-11-16 18:16:12 [INFO]\t[EVAL] Class IoU: \r\n",
      "[0.6041 0.774  0.6185 0.4882]\r\n",
      "2022-11-16 18:16:12 [INFO]\t[EVAL] Class Precision: \r\n",
      "[0.7534 0.8692 0.752  0.6722]\r\n",
      "2022-11-16 18:16:12 [INFO]\t[EVAL] Class Recall: \r\n",
      "[0.753  0.8761 0.777  0.6407]\r\n",
      "2022-11-16 18:16:13 [INFO]\t[EVAL] The model with the best validation mIoU (0.6226) was saved at iter 202000.\r\n",
      "2022-11-16 18:16:26 [INFO]\t[TRAIN] epoch: 55, iter: 222050/640000, loss: 0.5207, lr: 0.000041, batch_cost: 0.2737, reader_cost: 0.00015, ips: 58.4484 samples/sec | ETA 31:46:52\r\n",
      "2022-11-16 18:16:40 [INFO]\t[TRAIN] epoch: 55, iter: 222100/640000, loss: 0.5709, lr: 0.000041, batch_cost: 0.2729, reader_cost: 0.00014, ips: 58.6189 samples/sec | ETA 31:41:05\r\n",
      "2022-11-16 18:16:54 [INFO]\t[TRAIN] epoch: 55, iter: 222150/640000, loss: 0.5371, lr: 0.000041, batch_cost: 0.2738, reader_cost: 0.00016, ips: 58.4469 samples/sec | ETA 31:46:27\r\n",
      "2022-11-16 18:17:07 [INFO]\t[TRAIN] epoch: 55, iter: 222200/640000, loss: 0.5505, lr: 0.000041, batch_cost: 0.2723, reader_cost: 0.00013, ips: 58.7677 samples/sec | ETA 31:35:49\r\n",
      "2022-11-16 18:17:21 [INFO]\t[TRAIN] epoch: 55, iter: 222250/640000, loss: 0.5288, lr: 0.000041, batch_cost: 0.2719, reader_cost: 0.00013, ips: 58.8401 samples/sec | ETA 31:33:16\r\n",
      "2022-11-16 18:17:34 [INFO]\t[TRAIN] epoch: 55, iter: 222300/640000, loss: 0.5435, lr: 0.000041, batch_cost: 0.2726, reader_cost: 0.00013, ips: 58.6910 samples/sec | ETA 31:37:51\r\n",
      "2022-11-16 18:17:48 [INFO]\t[TRAIN] epoch: 55, iter: 222350/640000, loss: 0.5797, lr: 0.000041, batch_cost: 0.2735, reader_cost: 0.00014, ips: 58.5014 samples/sec | ETA 31:43:46\r\n",
      "2022-11-16 18:18:02 [INFO]\t[TRAIN] epoch: 55, iter: 222400/640000, loss: 0.5589, lr: 0.000041, batch_cost: 0.2700, reader_cost: 0.00013, ips: 59.2538 samples/sec | ETA 31:19:22\r\n",
      "2022-11-16 18:18:16 [INFO]\t[TRAIN] epoch: 55, iter: 222450/640000, loss: 0.4800, lr: 0.000041, batch_cost: 0.2795, reader_cost: 0.00016, ips: 57.2387 samples/sec | ETA 32:25:18\r\n",
      "2022-11-16 18:18:29 [INFO]\t[TRAIN] epoch: 55, iter: 222500/640000, loss: 0.5700, lr: 0.000041, batch_cost: 0.2748, reader_cost: 0.00013, ips: 58.2211 samples/sec | ETA 31:52:15\r\n",
      "2022-11-16 18:18:43 [INFO]\t[TRAIN] epoch: 55, iter: 222550/640000, loss: 0.5295, lr: 0.000041, batch_cost: 0.2778, reader_cost: 0.00014, ips: 57.6021 samples/sec | ETA 32:12:34\r\n",
      "2022-11-16 18:18:57 [INFO]\t[TRAIN] epoch: 55, iter: 222600/640000, loss: 0.4992, lr: 0.000041, batch_cost: 0.2787, reader_cost: 0.00015, ips: 57.4085 samples/sec | ETA 32:18:51\r\n",
      "2022-11-16 18:19:11 [INFO]\t[TRAIN] epoch: 55, iter: 222650/640000, loss: 0.5306, lr: 0.000041, batch_cost: 0.2755, reader_cost: 0.00015, ips: 58.0658 samples/sec | ETA 31:56:40\r\n",
      "2022-11-16 18:19:25 [INFO]\t[TRAIN] epoch: 55, iter: 222700/640000, loss: 0.5187, lr: 0.000041, batch_cost: 0.2751, reader_cost: 0.00015, ips: 58.1596 samples/sec | ETA 31:53:21\r\n",
      "2022-11-16 18:19:38 [INFO]\t[TRAIN] epoch: 55, iter: 222750/640000, loss: 0.5580, lr: 0.000041, batch_cost: 0.2741, reader_cost: 0.00015, ips: 58.3640 samples/sec | ETA 31:46:25\r\n",
      "2022-11-16 18:19:52 [INFO]\t[TRAIN] epoch: 55, iter: 222800/640000, loss: 0.5232, lr: 0.000041, batch_cost: 0.2752, reader_cost: 0.00014, ips: 58.1302 samples/sec | ETA 31:53:51\r\n",
      "2022-11-16 18:20:06 [INFO]\t[TRAIN] epoch: 55, iter: 222850/640000, loss: 0.5396, lr: 0.000041, batch_cost: 0.2737, reader_cost: 0.00013, ips: 58.4494 samples/sec | ETA 31:43:11\r\n",
      "2022-11-16 18:20:20 [INFO]\t[TRAIN] epoch: 55, iter: 222900/640000, loss: 0.5641, lr: 0.000041, batch_cost: 0.2747, reader_cost: 0.00014, ips: 58.2487 samples/sec | ETA 31:49:30\r\n",
      "2022-11-16 18:20:33 [INFO]\t[TRAIN] epoch: 55, iter: 222950/640000, loss: 0.5257, lr: 0.000041, batch_cost: 0.2733, reader_cost: 0.00013, ips: 58.5342 samples/sec | ETA 31:39:58\r\n",
      "2022-11-16 18:20:47 [INFO]\t[TRAIN] epoch: 56, iter: 223000/640000, loss: 0.5255, lr: 0.000041, batch_cost: 0.2757, reader_cost: 0.00387, ips: 58.0276 samples/sec | ETA 31:56:19\r\n",
      "2022-11-16 18:21:01 [INFO]\t[TRAIN] epoch: 56, iter: 223050/640000, loss: 0.5790, lr: 0.000041, batch_cost: 0.2770, reader_cost: 0.00014, ips: 57.7558 samples/sec | ETA 32:05:06\r\n",
      "2022-11-16 18:21:15 [INFO]\t[TRAIN] epoch: 56, iter: 223100/640000, loss: 0.5143, lr: 0.000041, batch_cost: 0.2831, reader_cost: 0.00016, ips: 56.5202 samples/sec | ETA 32:46:57\r\n",
      "2022-11-16 18:21:29 [INFO]\t[TRAIN] epoch: 56, iter: 223150/640000, loss: 0.5253, lr: 0.000041, batch_cost: 0.2766, reader_cost: 0.00014, ips: 57.8420 samples/sec | ETA 32:01:47\r\n",
      "2022-11-16 18:21:43 [INFO]\t[TRAIN] epoch: 56, iter: 223200/640000, loss: 0.5805, lr: 0.000041, batch_cost: 0.2726, reader_cost: 0.00013, ips: 58.6913 samples/sec | ETA 31:33:44\r\n",
      "2022-11-16 18:21:56 [INFO]\t[TRAIN] epoch: 56, iter: 223250/640000, loss: 0.5552, lr: 0.000041, batch_cost: 0.2734, reader_cost: 0.00013, ips: 58.5236 samples/sec | ETA 31:38:56\r\n",
      "2022-11-16 18:22:10 [INFO]\t[TRAIN] epoch: 56, iter: 223300/640000, loss: 0.5444, lr: 0.000041, batch_cost: 0.2748, reader_cost: 0.00015, ips: 58.2201 samples/sec | ETA 31:48:37\r\n",
      "2022-11-16 18:22:24 [INFO]\t[TRAIN] epoch: 56, iter: 223350/640000, loss: 0.5552, lr: 0.000041, batch_cost: 0.2766, reader_cost: 0.00014, ips: 57.8421 samples/sec | ETA 32:00:51\r\n",
      "2022-11-16 18:22:38 [INFO]\t[TRAIN] epoch: 56, iter: 223400/640000, loss: 0.5641, lr: 0.000041, batch_cost: 0.2794, reader_cost: 0.00015, ips: 57.2631 samples/sec | ETA 32:20:03\r\n",
      "2022-11-16 18:22:51 [INFO]\t[TRAIN] epoch: 56, iter: 223450/640000, loss: 0.5375, lr: 0.000041, batch_cost: 0.2727, reader_cost: 0.00013, ips: 58.6652 samples/sec | ETA 31:33:27\r\n",
      "2022-11-16 18:23:05 [INFO]\t[TRAIN] epoch: 56, iter: 223500/640000, loss: 0.5744, lr: 0.000041, batch_cost: 0.2734, reader_cost: 0.00014, ips: 58.5247 samples/sec | ETA 31:37:46\r\n",
      "2022-11-16 18:23:19 [INFO]\t[TRAIN] epoch: 56, iter: 223550/640000, loss: 0.5192, lr: 0.000041, batch_cost: 0.2734, reader_cost: 0.00013, ips: 58.5135 samples/sec | ETA 31:37:54\r\n",
      "2022-11-16 18:23:32 [INFO]\t[TRAIN] epoch: 56, iter: 223600/640000, loss: 0.5304, lr: 0.000041, batch_cost: 0.2717, reader_cost: 0.00013, ips: 58.8903 samples/sec | ETA 31:25:32\r\n",
      "2022-11-16 18:23:46 [INFO]\t[TRAIN] epoch: 56, iter: 223650/640000, loss: 0.5512, lr: 0.000041, batch_cost: 0.2718, reader_cost: 0.00013, ips: 58.8760 samples/sec | ETA 31:25:46\r\n",
      "2022-11-16 18:24:00 [INFO]\t[TRAIN] epoch: 56, iter: 223700/640000, loss: 0.5490, lr: 0.000041, batch_cost: 0.2721, reader_cost: 0.00012, ips: 58.7940 samples/sec | ETA 31:28:10\r\n",
      "2022-11-16 18:24:13 [INFO]\t[TRAIN] epoch: 56, iter: 223750/640000, loss: 0.5219, lr: 0.000041, batch_cost: 0.2736, reader_cost: 0.00014, ips: 58.4693 samples/sec | ETA 31:38:25\r\n",
      "2022-11-16 18:24:27 [INFO]\t[TRAIN] epoch: 56, iter: 223800/640000, loss: 0.5085, lr: 0.000041, batch_cost: 0.2740, reader_cost: 0.00015, ips: 58.3868 samples/sec | ETA 31:40:53\r\n",
      "2022-11-16 18:24:41 [INFO]\t[TRAIN] epoch: 56, iter: 223850/640000, loss: 0.5205, lr: 0.000041, batch_cost: 0.2796, reader_cost: 0.00015, ips: 57.2303 samples/sec | ETA 32:19:03\r\n",
      "2022-11-16 18:24:55 [INFO]\t[TRAIN] epoch: 56, iter: 223900/640000, loss: 0.5083, lr: 0.000041, batch_cost: 0.2723, reader_cost: 0.00013, ips: 58.7591 samples/sec | ETA 31:28:23\r\n",
      "2022-11-16 18:25:08 [INFO]\t[TRAIN] epoch: 56, iter: 223950/640000, loss: 0.5287, lr: 0.000041, batch_cost: 0.2724, reader_cost: 0.00014, ips: 58.7270 samples/sec | ETA 31:29:11\r\n",
      "2022-11-16 18:25:22 [INFO]\t[TRAIN] epoch: 56, iter: 224000/640000, loss: 0.5452, lr: 0.000041, batch_cost: 0.2728, reader_cost: 0.00014, ips: 58.6468 samples/sec | ETA 31:31:32\r\n",
      "2022-11-16 18:25:22 [INFO]\tStart evaluating (total_samples: 3094, total_iters: 3094)...\r\n",
      "3094/3094 [==============================] - 154s 50ms/step - batch_cost: 0.0497 - reader cost: 9.3060e-05\r\n",
      "2022-11-16 18:27:56 [INFO]\t[EVAL] #Images: 3094 mIoU: 0.6204 Acc: 0.7818 Kappa: 0.6976 Dice: 0.7610\r\n",
      "2022-11-16 18:27:56 [INFO]\t[EVAL] Class IoU: \r\n",
      "[0.6053 0.7699 0.6192 0.4872]\r\n",
      "2022-11-16 18:27:56 [INFO]\t[EVAL] Class Precision: \r\n",
      "[0.7373 0.8637 0.7808 0.6772]\r\n",
      "2022-11-16 18:27:56 [INFO]\t[EVAL] Class Recall: \r\n",
      "[0.7718 0.8764 0.7495 0.6345]\r\n",
      "2022-11-16 18:27:57 [INFO]\t[EVAL] The model with the best validation mIoU (0.6226) was saved at iter 202000.\r\n",
      "2022-11-16 18:28:10 [INFO]\t[TRAIN] epoch: 56, iter: 224050/640000, loss: 0.5486, lr: 0.000041, batch_cost: 0.2741, reader_cost: 0.00014, ips: 58.3830 samples/sec | ETA 31:39:52\r\n",
      "2022-11-16 18:28:24 [INFO]\t[TRAIN] epoch: 56, iter: 224100/640000, loss: 0.5502, lr: 0.000041, batch_cost: 0.2765, reader_cost: 0.00015, ips: 57.8744 samples/sec | ETA 31:56:20\r\n",
      "2022-11-16 18:28:38 [INFO]\t[TRAIN] epoch: 56, iter: 224150/640000, loss: 0.5015, lr: 0.000041, batch_cost: 0.2739, reader_cost: 0.00014, ips: 58.4067 samples/sec | ETA 31:38:38\r\n",
      "2022-11-16 18:28:52 [INFO]\t[TRAIN] epoch: 56, iter: 224200/640000, loss: 0.5208, lr: 0.000041, batch_cost: 0.2759, reader_cost: 0.00014, ips: 57.9821 samples/sec | ETA 31:52:18\r\n",
      "2022-11-16 18:29:05 [INFO]\t[TRAIN] epoch: 56, iter: 224250/640000, loss: 0.5499, lr: 0.000041, batch_cost: 0.2735, reader_cost: 0.00013, ips: 58.5112 samples/sec | ETA 31:34:47\r\n",
      "2022-11-16 18:29:19 [INFO]\t[TRAIN] epoch: 56, iter: 224300/640000, loss: 0.5857, lr: 0.000041, batch_cost: 0.2792, reader_cost: 0.00014, ips: 57.3163 samples/sec | ETA 32:14:03\r\n",
      "2022-11-16 18:29:33 [INFO]\t[TRAIN] epoch: 56, iter: 224350/640000, loss: 0.5165, lr: 0.000041, batch_cost: 0.2729, reader_cost: 0.00013, ips: 58.6343 samples/sec | ETA 31:30:21\r\n",
      "2022-11-16 18:29:46 [INFO]\t[TRAIN] epoch: 56, iter: 224400/640000, loss: 0.5452, lr: 0.000041, batch_cost: 0.2711, reader_cost: 0.00013, ips: 59.0208 samples/sec | ETA 31:17:45\r\n",
      "2022-11-16 18:30:00 [INFO]\t[TRAIN] epoch: 56, iter: 224450/640000, loss: 0.5069, lr: 0.000041, batch_cost: 0.2712, reader_cost: 0.00013, ips: 58.9863 samples/sec | ETA 31:18:37\r\n",
      "2022-11-16 18:30:14 [INFO]\t[TRAIN] epoch: 56, iter: 224500/640000, loss: 0.5523, lr: 0.000041, batch_cost: 0.2715, reader_cost: 0.00014, ips: 58.9363 samples/sec | ETA 31:19:59\r\n",
      "2022-11-16 18:30:27 [INFO]\t[TRAIN] epoch: 56, iter: 224550/640000, loss: 0.5792, lr: 0.000041, batch_cost: 0.2719, reader_cost: 0.00013, ips: 58.8414 samples/sec | ETA 31:22:48\r\n",
      "2022-11-16 18:30:41 [INFO]\t[TRAIN] epoch: 56, iter: 224600/640000, loss: 0.5701, lr: 0.000041, batch_cost: 0.2720, reader_cost: 0.00013, ips: 58.8229 samples/sec | ETA 31:23:09\r\n",
      "2022-11-16 18:30:54 [INFO]\t[TRAIN] epoch: 56, iter: 224650/640000, loss: 0.5364, lr: 0.000041, batch_cost: 0.2723, reader_cost: 0.00013, ips: 58.7668 samples/sec | ETA 31:24:44\r\n",
      "2022-11-16 18:31:08 [INFO]\t[TRAIN] epoch: 56, iter: 224700/640000, loss: 0.5465, lr: 0.000041, batch_cost: 0.2738, reader_cost: 0.00013, ips: 58.4377 samples/sec | ETA 31:35:07\r\n",
      "2022-11-16 18:31:22 [INFO]\t[TRAIN] epoch: 56, iter: 224750/640000, loss: 0.5360, lr: 0.000041, batch_cost: 0.2791, reader_cost: 0.00014, ips: 57.3297 samples/sec | ETA 32:11:31\r\n",
      "2022-11-16 18:31:36 [INFO]\t[TRAIN] epoch: 56, iter: 224800/640000, loss: 0.5575, lr: 0.000041, batch_cost: 0.2751, reader_cost: 0.00014, ips: 58.1698 samples/sec | ETA 31:43:23\r\n",
      "2022-11-16 18:31:49 [INFO]\t[TRAIN] epoch: 56, iter: 224850/640000, loss: 0.5359, lr: 0.000041, batch_cost: 0.2740, reader_cost: 0.00013, ips: 58.3958 samples/sec | ETA 31:35:47\r\n",
      "2022-11-16 18:32:03 [INFO]\t[TRAIN] epoch: 56, iter: 224900/640000, loss: 0.5095, lr: 0.000041, batch_cost: 0.2702, reader_cost: 0.00013, ips: 59.2116 samples/sec | ETA 31:09:27\r\n",
      "2022-11-16 18:32:17 [INFO]\t[TRAIN] epoch: 56, iter: 224950/640000, loss: 0.5300, lr: 0.000041, batch_cost: 0.2715, reader_cost: 0.00013, ips: 58.9269 samples/sec | ETA 31:18:15\r\n",
      "2022-11-16 18:32:30 [INFO]\t[TRAIN] epoch: 56, iter: 225000/640000, loss: 0.5291, lr: 0.000041, batch_cost: 0.2741, reader_cost: 0.00013, ips: 58.3634 samples/sec | ETA 31:36:09\r\n",
      "2022-11-16 18:32:44 [INFO]\t[TRAIN] epoch: 56, iter: 225050/640000, loss: 0.5271, lr: 0.000041, batch_cost: 0.2793, reader_cost: 0.00015, ips: 57.2857 samples/sec | ETA 32:11:36\r\n",
      "2022-11-16 18:32:58 [INFO]\t[TRAIN] epoch: 56, iter: 225100/640000, loss: 0.5227, lr: 0.000041, batch_cost: 0.2718, reader_cost: 0.00013, ips: 58.8613 samples/sec | ETA 31:19:40\r\n",
      "2022-11-16 18:33:12 [INFO]\t[TRAIN] epoch: 56, iter: 225150/640000, loss: 0.5381, lr: 0.000041, batch_cost: 0.2743, reader_cost: 0.00013, ips: 58.3250 samples/sec | ETA 31:36:43\r\n",
      "2022-11-16 18:33:25 [INFO]\t[TRAIN] epoch: 56, iter: 225200/640000, loss: 0.5704, lr: 0.000041, batch_cost: 0.2741, reader_cost: 0.00014, ips: 58.3695 samples/sec | ETA 31:35:03\r\n",
      "2022-11-16 18:33:39 [INFO]\t[TRAIN] epoch: 56, iter: 225250/640000, loss: 0.5547, lr: 0.000041, batch_cost: 0.2752, reader_cost: 0.00013, ips: 58.1387 samples/sec | ETA 31:42:20\r\n",
      "2022-11-16 18:33:53 [INFO]\t[TRAIN] epoch: 56, iter: 225300/640000, loss: 0.5292, lr: 0.000041, batch_cost: 0.2741, reader_cost: 0.00013, ips: 58.3638 samples/sec | ETA 31:34:46\r\n",
      "2022-11-16 18:34:06 [INFO]\t[TRAIN] epoch: 56, iter: 225350/640000, loss: 0.5335, lr: 0.000041, batch_cost: 0.2716, reader_cost: 0.00014, ips: 58.9188 samples/sec | ETA 31:16:42\r\n",
      "2022-11-16 18:34:20 [INFO]\t[TRAIN] epoch: 56, iter: 225400/640000, loss: 0.5065, lr: 0.000041, batch_cost: 0.2731, reader_cost: 0.00014, ips: 58.5804 samples/sec | ETA 31:27:19\r\n",
      "2022-11-16 18:34:34 [INFO]\t[TRAIN] epoch: 56, iter: 225450/640000, loss: 0.5853, lr: 0.000041, batch_cost: 0.2739, reader_cost: 0.00013, ips: 58.4173 samples/sec | ETA 31:32:21\r\n",
      "2022-11-16 18:34:47 [INFO]\t[TRAIN] epoch: 56, iter: 225500/640000, loss: 0.4932, lr: 0.000041, batch_cost: 0.2737, reader_cost: 0.00014, ips: 58.4577 samples/sec | ETA 31:30:49\r\n",
      "2022-11-16 18:35:01 [INFO]\t[TRAIN] epoch: 56, iter: 225550/640000, loss: 0.4915, lr: 0.000041, batch_cost: 0.2802, reader_cost: 0.00014, ips: 57.1041 samples/sec | ETA 32:15:24\r\n",
      "2022-11-16 18:35:15 [INFO]\t[TRAIN] epoch: 56, iter: 225600/640000, loss: 0.5707, lr: 0.000041, batch_cost: 0.2744, reader_cost: 0.00013, ips: 58.3100 samples/sec | ETA 31:35:09\r\n",
      "2022-11-16 18:35:29 [INFO]\t[TRAIN] epoch: 56, iter: 225650/640000, loss: 0.5274, lr: 0.000041, batch_cost: 0.2716, reader_cost: 0.00013, ips: 58.9113 samples/sec | ETA 31:15:35\r\n",
      "2022-11-16 18:35:42 [INFO]\t[TRAIN] epoch: 56, iter: 225700/640000, loss: 0.5694, lr: 0.000041, batch_cost: 0.2722, reader_cost: 0.00013, ips: 58.7902 samples/sec | ETA 31:19:13\r\n",
      "2022-11-16 18:35:56 [INFO]\t[TRAIN] epoch: 56, iter: 225750/640000, loss: 0.5630, lr: 0.000041, batch_cost: 0.2741, reader_cost: 0.00013, ips: 58.3701 samples/sec | ETA 31:32:31\r\n",
      "2022-11-16 18:36:10 [INFO]\t[TRAIN] epoch: 56, iter: 225800/640000, loss: 0.5434, lr: 0.000041, batch_cost: 0.2749, reader_cost: 0.00013, ips: 58.2087 samples/sec | ETA 31:37:32\r\n",
      "2022-11-16 18:36:23 [INFO]\t[TRAIN] epoch: 56, iter: 225850/640000, loss: 0.5335, lr: 0.000041, batch_cost: 0.2744, reader_cost: 0.00014, ips: 58.3162 samples/sec | ETA 31:33:48\r\n",
      "2022-11-16 18:36:37 [INFO]\t[TRAIN] epoch: 56, iter: 225900/640000, loss: 0.5159, lr: 0.000041, batch_cost: 0.2731, reader_cost: 0.00014, ips: 58.5839 samples/sec | ETA 31:24:56\r\n",
      "2022-11-16 18:36:51 [INFO]\t[TRAIN] epoch: 56, iter: 225950/640000, loss: 0.5462, lr: 0.000041, batch_cost: 0.2761, reader_cost: 0.00015, ips: 57.9541 samples/sec | ETA 31:45:11\r\n",
      "2022-11-16 18:37:05 [INFO]\t[TRAIN] epoch: 56, iter: 226000/640000, loss: 0.5637, lr: 0.000041, batch_cost: 0.2722, reader_cost: 0.00013, ips: 58.7787 samples/sec | ETA 31:18:13\r\n",
      "2022-11-16 18:37:05 [INFO]\tStart evaluating (total_samples: 3094, total_iters: 3094)...\r\n",
      "3094/3094 [==============================] - 159s 51ms/step - batch_cost: 0.0511 - reader cost: 9.1072e-05\r\n",
      "2022-11-16 18:39:43 [INFO]\t[EVAL] #Images: 3094 mIoU: 0.6256 Acc: 0.7852 Kappa: 0.7032 Dice: 0.7651\r\n",
      "2022-11-16 18:39:43 [INFO]\t[EVAL] Class IoU: \r\n",
      "[0.6103 0.7731 0.6255 0.4934]\r\n",
      "2022-11-16 18:39:43 [INFO]\t[EVAL] Class Precision: \r\n",
      "[0.7683 0.8661 0.7559 0.6686]\r\n",
      "2022-11-16 18:39:43 [INFO]\t[EVAL] Class Recall: \r\n",
      "[0.748  0.8781 0.7839 0.6531]\r\n",
      "2022-11-16 18:39:48 [INFO]\t[EVAL] The model with the best validation mIoU (0.6256) was saved at iter 226000.\r\n",
      "2022-11-16 18:40:02 [INFO]\t[TRAIN] epoch: 56, iter: 226050/640000, loss: 0.5198, lr: 0.000041, batch_cost: 0.2764, reader_cost: 0.00014, ips: 57.8781 samples/sec | ETA 31:47:13\r\n",
      "2022-11-16 18:40:16 [INFO]\t[TRAIN] epoch: 56, iter: 226100/640000, loss: 0.5627, lr: 0.000041, batch_cost: 0.2749, reader_cost: 0.00014, ips: 58.2046 samples/sec | ETA 31:36:17\r\n",
      "2022-11-16 18:40:29 [INFO]\t[TRAIN] epoch: 56, iter: 226150/640000, loss: 0.5384, lr: 0.000041, batch_cost: 0.2773, reader_cost: 0.00015, ips: 57.6982 samples/sec | ETA 31:52:42\r\n",
      "2022-11-16 18:40:43 [INFO]\t[TRAIN] epoch: 56, iter: 226200/640000, loss: 0.5740, lr: 0.000041, batch_cost: 0.2742, reader_cost: 0.00014, ips: 58.3516 samples/sec | ETA 31:31:03\r\n",
      "2022-11-16 18:40:57 [INFO]\t[TRAIN] epoch: 56, iter: 226250/640000, loss: 0.5261, lr: 0.000041, batch_cost: 0.2769, reader_cost: 0.00014, ips: 57.7835 samples/sec | ETA 31:49:25\r\n",
      "2022-11-16 18:41:11 [INFO]\t[TRAIN] epoch: 56, iter: 226300/640000, loss: 0.4970, lr: 0.000041, batch_cost: 0.2811, reader_cost: 0.00015, ips: 56.9123 samples/sec | ETA 32:18:25\r\n",
      "2022-11-16 18:41:25 [INFO]\t[TRAIN] epoch: 56, iter: 226350/640000, loss: 0.4772, lr: 0.000041, batch_cost: 0.2803, reader_cost: 0.00015, ips: 57.0844 samples/sec | ETA 32:12:20\r\n",
      "2022-11-16 18:41:39 [INFO]\t[TRAIN] epoch: 56, iter: 226400/640000, loss: 0.5108, lr: 0.000041, batch_cost: 0.2775, reader_cost: 0.00014, ips: 57.6474 samples/sec | ETA 31:53:14\r\n",
      "2022-11-16 18:41:53 [INFO]\t[TRAIN] epoch: 56, iter: 226450/640000, loss: 0.5350, lr: 0.000041, batch_cost: 0.2738, reader_cost: 0.00013, ips: 58.4437 samples/sec | ETA 31:26:56\r\n",
      "2022-11-16 18:42:06 [INFO]\t[TRAIN] epoch: 56, iter: 226500/640000, loss: 0.5055, lr: 0.000040, batch_cost: 0.2754, reader_cost: 0.00015, ips: 58.0946 samples/sec | ETA 31:38:03\r\n",
      "2022-11-16 18:42:20 [INFO]\t[TRAIN] epoch: 56, iter: 226550/640000, loss: 0.5737, lr: 0.000040, batch_cost: 0.2763, reader_cost: 0.00014, ips: 57.9080 samples/sec | ETA 31:43:56\r\n",
      "2022-11-16 18:42:34 [INFO]\t[TRAIN] epoch: 56, iter: 226600/640000, loss: 0.5565, lr: 0.000040, batch_cost: 0.2731, reader_cost: 0.00014, ips: 58.5856 samples/sec | ETA 31:21:41\r\n",
      "2022-11-16 18:42:48 [INFO]\t[TRAIN] epoch: 56, iter: 226650/640000, loss: 0.5515, lr: 0.000040, batch_cost: 0.2739, reader_cost: 0.00014, ips: 58.4084 samples/sec | ETA 31:27:10\r\n",
      "2022-11-16 18:43:01 [INFO]\t[TRAIN] epoch: 56, iter: 226700/640000, loss: 0.5909, lr: 0.000040, batch_cost: 0.2748, reader_cost: 0.00014, ips: 58.2227 samples/sec | ETA 31:32:57\r\n",
      "2022-11-16 18:43:15 [INFO]\t[TRAIN] epoch: 56, iter: 226750/640000, loss: 0.5611, lr: 0.000040, batch_cost: 0.2720, reader_cost: 0.00013, ips: 58.8286 samples/sec | ETA 31:13:14\r\n",
      "2022-11-16 18:43:28 [INFO]\t[TRAIN] epoch: 56, iter: 226800/640000, loss: 0.5833, lr: 0.000040, batch_cost: 0.2717, reader_cost: 0.00013, ips: 58.8977 samples/sec | ETA 31:10:48\r\n",
      "2022-11-16 18:43:42 [INFO]\t[TRAIN] epoch: 56, iter: 226850/640000, loss: 0.5388, lr: 0.000040, batch_cost: 0.2706, reader_cost: 0.00013, ips: 59.1238 samples/sec | ETA 31:03:26\r\n",
      "2022-11-16 18:43:56 [INFO]\t[TRAIN] epoch: 56, iter: 226900/640000, loss: 0.5249, lr: 0.000040, batch_cost: 0.2723, reader_cost: 0.00013, ips: 58.7658 samples/sec | ETA 31:14:33\r\n",
      "2022-11-16 18:44:09 [INFO]\t[TRAIN] epoch: 56, iter: 226950/640000, loss: 0.5264, lr: 0.000040, batch_cost: 0.2751, reader_cost: 0.00014, ips: 58.1547 samples/sec | ETA 31:34:01\r\n",
      "2022-11-16 18:44:23 [INFO]\t[TRAIN] epoch: 56, iter: 227000/640000, loss: 0.5642, lr: 0.000040, batch_cost: 0.2710, reader_cost: 0.00013, ips: 59.0498 samples/sec | ETA 31:05:05\r\n",
      "2022-11-16 18:44:37 [INFO]\t[TRAIN] epoch: 57, iter: 227050/640000, loss: 0.5585, lr: 0.000040, batch_cost: 0.2738, reader_cost: 0.00314, ips: 58.4455 samples/sec | ETA 31:24:08\r\n",
      "2022-11-16 18:44:50 [INFO]\t[TRAIN] epoch: 57, iter: 227100/640000, loss: 0.5487, lr: 0.000040, batch_cost: 0.2764, reader_cost: 0.00015, ips: 57.8963 samples/sec | ETA 31:41:47\r\n",
      "2022-11-16 18:45:04 [INFO]\t[TRAIN] epoch: 57, iter: 227150/640000, loss: 0.5550, lr: 0.000040, batch_cost: 0.2771, reader_cost: 0.00014, ips: 57.7386 samples/sec | ETA 31:46:45\r\n",
      "2022-11-16 18:45:18 [INFO]\t[TRAIN] epoch: 57, iter: 227200/640000, loss: 0.5136, lr: 0.000040, batch_cost: 0.2748, reader_cost: 0.00014, ips: 58.2207 samples/sec | ETA 31:30:44\r\n",
      "2022-11-16 18:45:32 [INFO]\t[TRAIN] epoch: 57, iter: 227250/640000, loss: 0.5558, lr: 0.000040, batch_cost: 0.2753, reader_cost: 0.00014, ips: 58.1119 samples/sec | ETA 31:34:02\r\n",
      "2022-11-16 18:45:46 [INFO]\t[TRAIN] epoch: 57, iter: 227300/640000, loss: 0.5112, lr: 0.000040, batch_cost: 0.2774, reader_cost: 0.00014, ips: 57.6821 samples/sec | ETA 31:47:55\r\n",
      "2022-11-16 18:45:59 [INFO]\t[TRAIN] epoch: 57, iter: 227350/640000, loss: 0.5853, lr: 0.000040, batch_cost: 0.2732, reader_cost: 0.00014, ips: 58.5643 samples/sec | ETA 31:18:57\r\n",
      "2022-11-16 18:46:13 [INFO]\t[TRAIN] epoch: 57, iter: 227400/640000, loss: 0.5059, lr: 0.000040, batch_cost: 0.2745, reader_cost: 0.00014, ips: 58.2958 samples/sec | ETA 31:27:23\r\n",
      "2022-11-16 18:46:27 [INFO]\t[TRAIN] epoch: 57, iter: 227450/640000, loss: 0.5606, lr: 0.000040, batch_cost: 0.2760, reader_cost: 0.00015, ips: 57.9725 samples/sec | ETA 31:37:40\r\n",
      "2022-11-16 18:46:41 [INFO]\t[TRAIN] epoch: 57, iter: 227500/640000, loss: 0.5175, lr: 0.000040, batch_cost: 0.2749, reader_cost: 0.00014, ips: 58.1946 samples/sec | ETA 31:30:12\r\n",
      "2022-11-16 18:46:54 [INFO]\t[TRAIN] epoch: 57, iter: 227550/640000, loss: 0.5321, lr: 0.000040, batch_cost: 0.2731, reader_cost: 0.00014, ips: 58.5778 samples/sec | ETA 31:17:37\r\n",
      "2022-11-16 18:47:08 [INFO]\t[TRAIN] epoch: 57, iter: 227600/640000, loss: 0.5492, lr: 0.000040, batch_cost: 0.2739, reader_cost: 0.00014, ips: 58.4173 samples/sec | ETA 31:22:32\r\n",
      "2022-11-16 18:47:22 [INFO]\t[TRAIN] epoch: 57, iter: 227650/640000, loss: 0.5577, lr: 0.000040, batch_cost: 0.2729, reader_cost: 0.00014, ips: 58.6306 samples/sec | ETA 31:15:28\r\n",
      "2022-11-16 18:47:35 [INFO]\t[TRAIN] epoch: 57, iter: 227700/640000, loss: 0.5356, lr: 0.000040, batch_cost: 0.2734, reader_cost: 0.00013, ips: 58.5200 samples/sec | ETA 31:18:47\r\n",
      "2022-11-16 18:47:49 [INFO]\t[TRAIN] epoch: 57, iter: 227750/640000, loss: 0.5653, lr: 0.000040, batch_cost: 0.2733, reader_cost: 0.00013, ips: 58.5374 samples/sec | ETA 31:18:00\r\n",
      "2022-11-16 18:48:03 [INFO]\t[TRAIN] epoch: 57, iter: 227800/640000, loss: 0.5324, lr: 0.000040, batch_cost: 0.2726, reader_cost: 0.00013, ips: 58.6908 samples/sec | ETA 31:12:51\r\n",
      "2022-11-16 18:48:16 [INFO]\t[TRAIN] epoch: 57, iter: 227850/640000, loss: 0.5376, lr: 0.000040, batch_cost: 0.2737, reader_cost: 0.00013, ips: 58.4620 samples/sec | ETA 31:19:57\r\n",
      "2022-11-16 18:48:30 [INFO]\t[TRAIN] epoch: 57, iter: 227900/640000, loss: 0.5238, lr: 0.000040, batch_cost: 0.2743, reader_cost: 0.00013, ips: 58.3401 samples/sec | ETA 31:23:39\r\n",
      "2022-11-16 18:48:44 [INFO]\t[TRAIN] epoch: 57, iter: 227950/640000, loss: 0.5716, lr: 0.000040, batch_cost: 0.2722, reader_cost: 0.00013, ips: 58.7751 samples/sec | ETA 31:09:30\r\n",
      "2022-11-16 18:48:57 [INFO]\t[TRAIN] epoch: 57, iter: 228000/640000, loss: 0.5372, lr: 0.000040, batch_cost: 0.2738, reader_cost: 0.00015, ips: 58.4463 samples/sec | ETA 31:19:47\r\n",
      "2022-11-16 18:48:57 [INFO]\tStart evaluating (total_samples: 3094, total_iters: 3094)...\r\n",
      "3094/3094 [==============================] - 153s 49ms/step - batch_cost: 0.0493 - reader cost: 8.6082e-05\r\n",
      "2022-11-16 18:51:30 [INFO]\t[EVAL] #Images: 3094 mIoU: 0.6223 Acc: 0.7831 Kappa: 0.6999 Dice: 0.7626\r\n",
      "2022-11-16 18:51:30 [INFO]\t[EVAL] Class IoU: \r\n",
      "[0.6015 0.7726 0.6217 0.4935]\r\n",
      "2022-11-16 18:51:30 [INFO]\t[EVAL] Class Precision: \r\n",
      "[0.7296 0.874  0.751  0.7069]\r\n",
      "2022-11-16 18:51:30 [INFO]\t[EVAL] Class Recall: \r\n",
      "[0.7741 0.8694 0.783  0.6205]\r\n",
      "2022-11-16 18:51:31 [INFO]\t[EVAL] The model with the best validation mIoU (0.6256) was saved at iter 226000.\r\n",
      "2022-11-16 18:51:44 [INFO]\t[TRAIN] epoch: 57, iter: 228050/640000, loss: 0.5047, lr: 0.000040, batch_cost: 0.2716, reader_cost: 0.00013, ips: 58.9032 samples/sec | ETA 31:04:58\r\n",
      "2022-11-16 18:51:58 [INFO]\t[TRAIN] epoch: 57, iter: 228100/640000, loss: 0.5295, lr: 0.000040, batch_cost: 0.2712, reader_cost: 0.00014, ips: 59.0012 samples/sec | ETA 31:01:39\r\n",
      "2022-11-16 18:52:12 [INFO]\t[TRAIN] epoch: 57, iter: 228150/640000, loss: 0.5990, lr: 0.000040, batch_cost: 0.2786, reader_cost: 0.00014, ips: 57.4314 samples/sec | ETA 31:52:18\r\n",
      "2022-11-16 18:52:26 [INFO]\t[TRAIN] epoch: 57, iter: 228200/640000, loss: 0.5710, lr: 0.000040, batch_cost: 0.2776, reader_cost: 0.00014, ips: 57.6373 samples/sec | ETA 31:45:14\r\n",
      "2022-11-16 18:52:39 [INFO]\t[TRAIN] epoch: 57, iter: 228250/640000, loss: 0.5325, lr: 0.000040, batch_cost: 0.2707, reader_cost: 0.00013, ips: 59.1087 samples/sec | ETA 30:57:35\r\n",
      "2022-11-16 18:52:53 [INFO]\t[TRAIN] epoch: 57, iter: 228300/640000, loss: 0.5611, lr: 0.000040, batch_cost: 0.2707, reader_cost: 0.00014, ips: 59.0982 samples/sec | ETA 30:57:41\r\n",
      "2022-11-16 18:53:07 [INFO]\t[TRAIN] epoch: 57, iter: 228350/640000, loss: 0.5201, lr: 0.000040, batch_cost: 0.2767, reader_cost: 0.00014, ips: 57.8293 samples/sec | ETA 31:38:13\r\n",
      "2022-11-16 18:53:20 [INFO]\t[TRAIN] epoch: 57, iter: 228400/640000, loss: 0.4817, lr: 0.000040, batch_cost: 0.2719, reader_cost: 0.00014, ips: 58.8457 samples/sec | ETA 31:05:13\r\n",
      "2022-11-16 18:53:34 [INFO]\t[TRAIN] epoch: 57, iter: 228450/640000, loss: 0.5513, lr: 0.000040, batch_cost: 0.2758, reader_cost: 0.00013, ips: 58.0069 samples/sec | ETA 31:31:57\r\n",
      "2022-11-16 18:53:48 [INFO]\t[TRAIN] epoch: 57, iter: 228500/640000, loss: 0.5809, lr: 0.000040, batch_cost: 0.2737, reader_cost: 0.00013, ips: 58.4586 samples/sec | ETA 31:17:06\r\n",
      "2022-11-16 18:54:01 [INFO]\t[TRAIN] epoch: 57, iter: 228550/640000, loss: 0.5206, lr: 0.000040, batch_cost: 0.2725, reader_cost: 0.00013, ips: 58.7185 samples/sec | ETA 31:08:34\r\n",
      "2022-11-16 18:54:15 [INFO]\t[TRAIN] epoch: 57, iter: 228600/640000, loss: 0.4879, lr: 0.000040, batch_cost: 0.2735, reader_cost: 0.00013, ips: 58.5066 samples/sec | ETA 31:15:06\r\n",
      "2022-11-16 18:54:29 [INFO]\t[TRAIN] epoch: 57, iter: 228650/640000, loss: 0.5079, lr: 0.000040, batch_cost: 0.2748, reader_cost: 0.00013, ips: 58.2289 samples/sec | ETA 31:23:49\r\n",
      "2022-11-16 18:54:42 [INFO]\t[TRAIN] epoch: 57, iter: 228700/640000, loss: 0.5214, lr: 0.000040, batch_cost: 0.2737, reader_cost: 0.00013, ips: 58.4521 samples/sec | ETA 31:16:24\r\n",
      "2022-11-16 18:54:56 [INFO]\t[TRAIN] epoch: 57, iter: 228750/640000, loss: 0.5481, lr: 0.000040, batch_cost: 0.2710, reader_cost: 0.00013, ips: 59.0362 samples/sec | ETA 30:57:36\r\n",
      "2022-11-16 18:55:10 [INFO]\t[TRAIN] epoch: 57, iter: 228800/640000, loss: 0.4978, lr: 0.000040, batch_cost: 0.2719, reader_cost: 0.00014, ips: 58.8362 samples/sec | ETA 31:03:42\r\n",
      "2022-11-16 18:55:23 [INFO]\t[TRAIN] epoch: 57, iter: 228850/640000, loss: 0.5227, lr: 0.000040, batch_cost: 0.2716, reader_cost: 0.00013, ips: 58.9176 samples/sec | ETA 31:00:54\r\n",
      "2022-11-16 18:55:37 [INFO]\t[TRAIN] epoch: 57, iter: 228900/640000, loss: 0.5573, lr: 0.000040, batch_cost: 0.2812, reader_cost: 0.00014, ips: 56.8963 samples/sec | ETA 32:06:46\r\n",
      "2022-11-16 18:55:51 [INFO]\t[TRAIN] epoch: 57, iter: 228950/640000, loss: 0.5480, lr: 0.000040, batch_cost: 0.2707, reader_cost: 0.00013, ips: 59.1019 samples/sec | ETA 30:54:38\r\n",
      "2022-11-16 18:56:04 [INFO]\t[TRAIN] epoch: 57, iter: 229000/640000, loss: 0.5380, lr: 0.000040, batch_cost: 0.2714, reader_cost: 0.00013, ips: 58.9507 samples/sec | ETA 30:59:10\r\n",
      "2022-11-16 18:56:18 [INFO]\t[TRAIN] epoch: 57, iter: 229050/640000, loss: 0.5746, lr: 0.000040, batch_cost: 0.2737, reader_cost: 0.00013, ips: 58.4515 samples/sec | ETA 31:14:49\r\n",
      "2022-11-16 18:56:32 [INFO]\t[TRAIN] epoch: 57, iter: 229100/640000, loss: 0.5310, lr: 0.000040, batch_cost: 0.2731, reader_cost: 0.00013, ips: 58.5967 samples/sec | ETA 31:09:57\r\n",
      "2022-11-16 18:56:45 [INFO]\t[TRAIN] epoch: 57, iter: 229150/640000, loss: 0.5384, lr: 0.000040, batch_cost: 0.2729, reader_cost: 0.00013, ips: 58.6400 samples/sec | ETA 31:08:20\r\n",
      "2022-11-16 18:56:59 [INFO]\t[TRAIN] epoch: 57, iter: 229200/640000, loss: 0.5158, lr: 0.000040, batch_cost: 0.2737, reader_cost: 0.00013, ips: 58.4657 samples/sec | ETA 31:13:41\r\n",
      "2022-11-16 18:57:13 [INFO]\t[TRAIN] epoch: 57, iter: 229250/640000, loss: 0.5677, lr: 0.000040, batch_cost: 0.2736, reader_cost: 0.00014, ips: 58.4792 samples/sec | ETA 31:13:01\r\n",
      "2022-11-16 18:57:26 [INFO]\t[TRAIN] epoch: 57, iter: 229300/640000, loss: 0.5742, lr: 0.000040, batch_cost: 0.2744, reader_cost: 0.00013, ips: 58.3145 samples/sec | ETA 31:18:05\r\n",
      "2022-11-16 18:57:40 [INFO]\t[TRAIN] epoch: 57, iter: 229350/640000, loss: 0.5210, lr: 0.000040, batch_cost: 0.2736, reader_cost: 0.00014, ips: 58.4825 samples/sec | ETA 31:12:28\r\n",
      "2022-11-16 18:57:54 [INFO]\t[TRAIN] epoch: 57, iter: 229400/640000, loss: 0.5078, lr: 0.000040, batch_cost: 0.2749, reader_cost: 0.00013, ips: 58.1931 samples/sec | ETA 31:21:33\r\n",
      "2022-11-16 18:58:07 [INFO]\t[TRAIN] epoch: 57, iter: 229450/640000, loss: 0.5215, lr: 0.000040, batch_cost: 0.2724, reader_cost: 0.00014, ips: 58.7327 samples/sec | ETA 31:04:02\r\n",
      "2022-11-16 18:58:21 [INFO]\t[TRAIN] epoch: 57, iter: 229500/640000, loss: 0.5380, lr: 0.000040, batch_cost: 0.2720, reader_cost: 0.00013, ips: 58.8186 samples/sec | ETA 31:01:05\r\n",
      "2022-11-16 18:58:35 [INFO]\t[TRAIN] epoch: 57, iter: 229550/640000, loss: 0.5710, lr: 0.000040, batch_cost: 0.2726, reader_cost: 0.00014, ips: 58.6955 samples/sec | ETA 31:04:45\r\n",
      "2022-11-16 18:58:48 [INFO]\t[TRAIN] epoch: 57, iter: 229600/640000, loss: 0.5144, lr: 0.000040, batch_cost: 0.2741, reader_cost: 0.00013, ips: 58.3734 samples/sec | ETA 31:14:49\r\n",
      "2022-11-16 18:59:02 [INFO]\t[TRAIN] epoch: 57, iter: 229650/640000, loss: 0.5404, lr: 0.000040, batch_cost: 0.2727, reader_cost: 0.00013, ips: 58.6831 samples/sec | ETA 31:04:42\r\n",
      "2022-11-16 18:59:16 [INFO]\t[TRAIN] epoch: 57, iter: 229700/640000, loss: 0.5198, lr: 0.000040, batch_cost: 0.2727, reader_cost: 0.00013, ips: 58.6805 samples/sec | ETA 31:04:33\r\n",
      "2022-11-16 18:59:29 [INFO]\t[TRAIN] epoch: 57, iter: 229750/640000, loss: 0.5141, lr: 0.000040, batch_cost: 0.2716, reader_cost: 0.00013, ips: 58.9059 samples/sec | ETA 30:57:11\r\n",
      "2022-11-16 18:59:43 [INFO]\t[TRAIN] epoch: 57, iter: 229800/640000, loss: 0.4844, lr: 0.000040, batch_cost: 0.2733, reader_cost: 0.00013, ips: 58.5403 samples/sec | ETA 31:08:34\r\n",
      "2022-11-16 18:59:56 [INFO]\t[TRAIN] epoch: 57, iter: 229850/640000, loss: 0.5506, lr: 0.000040, batch_cost: 0.2702, reader_cost: 0.00013, ips: 59.2093 samples/sec | ETA 30:47:13\r\n",
      "2022-11-16 19:00:10 [INFO]\t[TRAIN] epoch: 57, iter: 229900/640000, loss: 0.5138, lr: 0.000040, batch_cost: 0.2723, reader_cost: 0.00013, ips: 58.7610 samples/sec | ETA 31:01:05\r\n",
      "2022-11-16 19:00:24 [INFO]\t[TRAIN] epoch: 57, iter: 229950/640000, loss: 0.5399, lr: 0.000040, batch_cost: 0.2722, reader_cost: 0.00013, ips: 58.7825 samples/sec | ETA 31:00:11\r\n",
      "2022-11-16 19:00:37 [INFO]\t[TRAIN] epoch: 57, iter: 230000/640000, loss: 0.5467, lr: 0.000040, batch_cost: 0.2720, reader_cost: 0.00013, ips: 58.8162 samples/sec | ETA 30:58:53\r\n",
      "2022-11-16 19:00:37 [INFO]\tStart evaluating (total_samples: 3094, total_iters: 3094)...\r\n",
      "3094/3094 [==============================] - 153s 49ms/step - batch_cost: 0.0492 - reader cost: 8.8549e-05\r\n",
      "2022-11-16 19:03:10 [INFO]\t[EVAL] #Images: 3094 mIoU: 0.6213 Acc: 0.7830 Kappa: 0.6995 Dice: 0.7616\r\n",
      "2022-11-16 19:03:10 [INFO]\t[EVAL] Class IoU: \r\n",
      "[0.6039 0.7742 0.6216 0.4857]\r\n",
      "2022-11-16 19:03:10 [INFO]\t[EVAL] Class Precision: \r\n",
      "[0.7453 0.8652 0.7581 0.6858]\r\n",
      "2022-11-16 19:03:10 [INFO]\t[EVAL] Class Recall: \r\n",
      "[0.7609 0.8804 0.7754 0.6247]\r\n",
      "2022-11-16 19:03:10 [INFO]\t[EVAL] The model with the best validation mIoU (0.6256) was saved at iter 226000.\r\n",
      "2022-11-16 19:03:24 [INFO]\t[TRAIN] epoch: 57, iter: 230050/640000, loss: 0.5433, lr: 0.000040, batch_cost: 0.2742, reader_cost: 0.00013, ips: 58.3608 samples/sec | ETA 31:13:10\r\n",
      "2022-11-16 19:03:38 [INFO]\t[TRAIN] epoch: 57, iter: 230100/640000, loss: 0.5043, lr: 0.000040, batch_cost: 0.2728, reader_cost: 0.00013, ips: 58.6568 samples/sec | ETA 31:03:29\r\n",
      "2022-11-16 19:03:51 [INFO]\t[TRAIN] epoch: 57, iter: 230150/640000, loss: 0.4835, lr: 0.000040, batch_cost: 0.2760, reader_cost: 0.00015, ips: 57.9711 samples/sec | ETA 31:25:18\r\n",
      "2022-11-16 19:04:05 [INFO]\t[TRAIN] epoch: 57, iter: 230200/640000, loss: 0.5510, lr: 0.000040, batch_cost: 0.2717, reader_cost: 0.00014, ips: 58.8780 samples/sec | ETA 30:56:02\r\n",
      "2022-11-16 19:04:19 [INFO]\t[TRAIN] epoch: 57, iter: 230250/640000, loss: 0.5501, lr: 0.000040, batch_cost: 0.2722, reader_cost: 0.00013, ips: 58.7902 samples/sec | ETA 30:58:35\r\n",
      "2022-11-16 19:04:32 [INFO]\t[TRAIN] epoch: 57, iter: 230300/640000, loss: 0.5665, lr: 0.000040, batch_cost: 0.2742, reader_cost: 0.00014, ips: 58.3473 samples/sec | ETA 31:12:27\r\n",
      "2022-11-16 19:04:46 [INFO]\t[TRAIN] epoch: 57, iter: 230350/640000, loss: 0.5349, lr: 0.000040, batch_cost: 0.2752, reader_cost: 0.00014, ips: 58.1339 samples/sec | ETA 31:19:06\r\n",
      "2022-11-16 19:05:00 [INFO]\t[TRAIN] epoch: 57, iter: 230400/640000, loss: 0.5293, lr: 0.000040, batch_cost: 0.2723, reader_cost: 0.00015, ips: 58.7646 samples/sec | ETA 30:58:42\r\n",
      "2022-11-16 19:05:13 [INFO]\t[TRAIN] epoch: 57, iter: 230450/640000, loss: 0.5474, lr: 0.000040, batch_cost: 0.2714, reader_cost: 0.00013, ips: 58.9580 samples/sec | ETA 30:52:23\r\n",
      "2022-11-16 19:05:27 [INFO]\t[TRAIN] epoch: 57, iter: 230500/640000, loss: 0.5198, lr: 0.000040, batch_cost: 0.2725, reader_cost: 0.00013, ips: 58.7110 samples/sec | ETA 30:59:57\r\n",
      "2022-11-16 19:05:41 [INFO]\t[TRAIN] epoch: 57, iter: 230550/640000, loss: 0.5122, lr: 0.000040, batch_cost: 0.2753, reader_cost: 0.00014, ips: 58.1142 samples/sec | ETA 31:18:49\r\n",
      "2022-11-16 19:05:54 [INFO]\t[TRAIN] epoch: 57, iter: 230600/640000, loss: 0.5651, lr: 0.000040, batch_cost: 0.2732, reader_cost: 0.00014, ips: 58.5635 samples/sec | ETA 31:04:11\r\n",
      "2022-11-16 19:06:08 [INFO]\t[TRAIN] epoch: 57, iter: 230650/640000, loss: 0.5359, lr: 0.000040, batch_cost: 0.2749, reader_cost: 0.00014, ips: 58.2126 samples/sec | ETA 31:15:11\r\n",
      "2022-11-16 19:06:22 [INFO]\t[TRAIN] epoch: 57, iter: 230700/640000, loss: 0.5147, lr: 0.000040, batch_cost: 0.2743, reader_cost: 0.00013, ips: 58.3239 samples/sec | ETA 31:11:23\r\n",
      "2022-11-16 19:06:35 [INFO]\t[TRAIN] epoch: 57, iter: 230750/640000, loss: 0.4931, lr: 0.000040, batch_cost: 0.2722, reader_cost: 0.00013, ips: 58.7833 samples/sec | ETA 30:56:32\r\n",
      "2022-11-16 19:06:49 [INFO]\t[TRAIN] epoch: 57, iter: 230800/640000, loss: 0.5972, lr: 0.000040, batch_cost: 0.2732, reader_cost: 0.00014, ips: 58.5717 samples/sec | ETA 31:03:00\r\n",
      "2022-11-16 19:07:03 [INFO]\t[TRAIN] epoch: 57, iter: 230850/640000, loss: 0.5407, lr: 0.000040, batch_cost: 0.2731, reader_cost: 0.00014, ips: 58.5889 samples/sec | ETA 31:02:14\r\n",
      "2022-11-16 19:07:16 [INFO]\t[TRAIN] epoch: 57, iter: 230900/640000, loss: 0.5126, lr: 0.000040, batch_cost: 0.2741, reader_cost: 0.00014, ips: 58.3661 samples/sec | ETA 31:09:07\r\n",
      "2022-11-16 19:07:30 [INFO]\t[TRAIN] epoch: 57, iter: 230950/640000, loss: 0.5441, lr: 0.000040, batch_cost: 0.2739, reader_cost: 0.00014, ips: 58.4057 samples/sec | ETA 31:07:37\r\n",
      "2022-11-16 19:07:44 [INFO]\t[TRAIN] epoch: 57, iter: 231000/640000, loss: 0.5534, lr: 0.000040, batch_cost: 0.2729, reader_cost: 0.00013, ips: 58.6315 samples/sec | ETA 31:00:12\r\n",
      "2022-11-16 19:07:57 [INFO]\t[TRAIN] epoch: 57, iter: 231050/640000, loss: 0.5571, lr: 0.000040, batch_cost: 0.2729, reader_cost: 0.00014, ips: 58.6203 samples/sec | ETA 31:00:20\r\n",
      "2022-11-16 19:08:11 [INFO]\t[TRAIN] epoch: 58, iter: 231100/640000, loss: 0.5180, lr: 0.000040, batch_cost: 0.2756, reader_cost: 0.00336, ips: 58.0652 samples/sec | ETA 31:17:53\r\n",
      "2022-11-16 19:08:25 [INFO]\t[TRAIN] epoch: 58, iter: 231150/640000, loss: 0.5732, lr: 0.000040, batch_cost: 0.2731, reader_cost: 0.00014, ips: 58.5897 samples/sec | ETA 31:00:51\r\n",
      "2022-11-16 19:08:39 [INFO]\t[TRAIN] epoch: 58, iter: 231200/640000, loss: 0.5476, lr: 0.000040, batch_cost: 0.2794, reader_cost: 0.00015, ips: 57.2600 samples/sec | ETA 31:43:49\r\n",
      "2022-11-16 19:08:53 [INFO]\t[TRAIN] epoch: 58, iter: 231250/640000, loss: 0.5181, lr: 0.000040, batch_cost: 0.2740, reader_cost: 0.00013, ips: 58.3843 samples/sec | ETA 31:06:56\r\n",
      "2022-11-16 19:09:06 [INFO]\t[TRAIN] epoch: 58, iter: 231300/640000, loss: 0.5399, lr: 0.000040, batch_cost: 0.2745, reader_cost: 0.00013, ips: 58.2826 samples/sec | ETA 31:09:58\r\n",
      "2022-11-16 19:09:20 [INFO]\t[TRAIN] epoch: 58, iter: 231350/640000, loss: 0.5677, lr: 0.000040, batch_cost: 0.2752, reader_cost: 0.00014, ips: 58.1309 samples/sec | ETA 31:14:37\r\n",
      "2022-11-16 19:09:34 [INFO]\t[TRAIN] epoch: 58, iter: 231400/640000, loss: 0.5468, lr: 0.000040, batch_cost: 0.2735, reader_cost: 0.00013, ips: 58.5076 samples/sec | ETA 31:02:19\r\n",
      "2022-11-16 19:09:47 [INFO]\t[TRAIN] epoch: 58, iter: 231450/640000, loss: 0.5613, lr: 0.000040, batch_cost: 0.2727, reader_cost: 0.00013, ips: 58.6803 samples/sec | ETA 30:56:36\r\n",
      "2022-11-16 19:10:01 [INFO]\t[TRAIN] epoch: 58, iter: 231500/640000, loss: 0.5356, lr: 0.000040, batch_cost: 0.2732, reader_cost: 0.00013, ips: 58.5558 samples/sec | ETA 31:00:20\r\n",
      "2022-11-16 19:10:15 [INFO]\t[TRAIN] epoch: 58, iter: 231550/640000, loss: 0.5246, lr: 0.000040, batch_cost: 0.2717, reader_cost: 0.00014, ips: 58.8912 samples/sec | ETA 30:49:30\r\n",
      "2022-11-16 19:10:28 [INFO]\t[TRAIN] epoch: 58, iter: 231600/640000, loss: 0.5447, lr: 0.000040, batch_cost: 0.2732, reader_cost: 0.00013, ips: 58.5727 samples/sec | ETA 30:59:20\r\n",
      "2022-11-16 19:10:42 [INFO]\t[TRAIN] epoch: 58, iter: 231650/640000, loss: 0.5406, lr: 0.000040, batch_cost: 0.2740, reader_cost: 0.00014, ips: 58.3881 samples/sec | ETA 31:04:59\r\n",
      "2022-11-16 19:10:56 [INFO]\t[TRAIN] epoch: 58, iter: 231700/640000, loss: 0.5315, lr: 0.000040, batch_cost: 0.2734, reader_cost: 0.00013, ips: 58.5297 samples/sec | ETA 31:00:15\r\n",
      "2022-11-16 19:11:09 [INFO]\t[TRAIN] epoch: 58, iter: 231750/640000, loss: 0.5376, lr: 0.000040, batch_cost: 0.2747, reader_cost: 0.00014, ips: 58.2527 samples/sec | ETA 31:08:52\r\n",
      "2022-11-16 19:11:23 [INFO]\t[TRAIN] epoch: 58, iter: 231800/640000, loss: 0.5257, lr: 0.000040, batch_cost: 0.2727, reader_cost: 0.00013, ips: 58.6760 samples/sec | ETA 30:55:09\r\n",
      "2022-11-16 19:11:37 [INFO]\t[TRAIN] epoch: 58, iter: 231850/640000, loss: 0.5000, lr: 0.000040, batch_cost: 0.2726, reader_cost: 0.00013, ips: 58.7024 samples/sec | ETA 30:54:05\r\n",
      "2022-11-16 19:11:50 [INFO]\t[TRAIN] epoch: 58, iter: 231900/640000, loss: 0.5777, lr: 0.000040, batch_cost: 0.2766, reader_cost: 0.00015, ips: 57.8471 samples/sec | ETA 31:21:16\r\n",
      "2022-11-16 19:12:04 [INFO]\t[TRAIN] epoch: 58, iter: 231950/640000, loss: 0.5210, lr: 0.000040, batch_cost: 0.2764, reader_cost: 0.00015, ips: 57.8881 samples/sec | ETA 31:19:43\r\n",
      "2022-11-16 19:12:18 [INFO]\t[TRAIN] epoch: 58, iter: 232000/640000, loss: 0.5218, lr: 0.000040, batch_cost: 0.2770, reader_cost: 0.00014, ips: 57.7688 samples/sec | ETA 31:23:22\r\n",
      "2022-11-16 19:12:18 [INFO]\tStart evaluating (total_samples: 3094, total_iters: 3094)...\r\n",
      "3094/3094 [==============================] - 156s 50ms/step - batch_cost: 0.0503 - reader cost: 1.0214e-04\r\n",
      "2022-11-16 19:14:54 [INFO]\t[EVAL] #Images: 3094 mIoU: 0.6236 Acc: 0.7840 Kappa: 0.7010 Dice: 0.7634\r\n",
      "2022-11-16 19:14:54 [INFO]\t[EVAL] Class IoU: \r\n",
      "[0.6065 0.774  0.6241 0.4897]\r\n",
      "2022-11-16 19:14:54 [INFO]\t[EVAL] Class Precision: \r\n",
      "[0.7686 0.8596 0.7706 0.6591]\r\n",
      "2022-11-16 19:14:54 [INFO]\t[EVAL] Class Recall: \r\n",
      "[0.7419 0.8859 0.7665 0.6558]\r\n",
      "2022-11-16 19:14:55 [INFO]\t[EVAL] The model with the best validation mIoU (0.6256) was saved at iter 226000.\r\n",
      "2022-11-16 19:15:09 [INFO]\t[TRAIN] epoch: 58, iter: 232050/640000, loss: 0.5351, lr: 0.000040, batch_cost: 0.2754, reader_cost: 0.00015, ips: 58.0906 samples/sec | ETA 31:12:42\r\n",
      "2022-11-16 19:15:22 [INFO]\t[TRAIN] epoch: 58, iter: 232100/640000, loss: 0.5528, lr: 0.000040, batch_cost: 0.2737, reader_cost: 0.00015, ips: 58.4588 samples/sec | ETA 31:00:41\r\n",
      "2022-11-16 19:15:36 [INFO]\t[TRAIN] epoch: 58, iter: 232150/640000, loss: 0.5562, lr: 0.000040, batch_cost: 0.2752, reader_cost: 0.00015, ips: 58.1294 samples/sec | ETA 31:10:59\r\n",
      "2022-11-16 19:15:50 [INFO]\t[TRAIN] epoch: 58, iter: 232200/640000, loss: 0.4990, lr: 0.000040, batch_cost: 0.2754, reader_cost: 0.00015, ips: 58.0950 samples/sec | ETA 31:11:52\r\n",
      "2022-11-16 19:16:03 [INFO]\t[TRAIN] epoch: 58, iter: 232250/640000, loss: 0.5361, lr: 0.000040, batch_cost: 0.2725, reader_cost: 0.00015, ips: 58.7191 samples/sec | ETA 30:51:45\r\n",
      "2022-11-16 19:16:17 [INFO]\t[TRAIN] epoch: 58, iter: 232300/640000, loss: 0.4883, lr: 0.000040, batch_cost: 0.2763, reader_cost: 0.00015, ips: 57.9073 samples/sec | ETA 31:17:28\r\n",
      "2022-11-16 19:16:31 [INFO]\t[TRAIN] epoch: 58, iter: 232350/640000, loss: 0.5522, lr: 0.000040, batch_cost: 0.2802, reader_cost: 0.00016, ips: 57.1018 samples/sec | ETA 31:43:43\r\n",
      "2022-11-16 19:16:45 [INFO]\t[TRAIN] epoch: 58, iter: 232400/640000, loss: 0.5019, lr: 0.000040, batch_cost: 0.2832, reader_cost: 0.00016, ips: 56.5053 samples/sec | ETA 32:03:35\r\n",
      "2022-11-16 19:16:59 [INFO]\t[TRAIN] epoch: 58, iter: 232450/640000, loss: 0.5691, lr: 0.000040, batch_cost: 0.2776, reader_cost: 0.00015, ips: 57.6291 samples/sec | ETA 31:25:51\r\n",
      "2022-11-16 19:17:13 [INFO]\t[TRAIN] epoch: 58, iter: 232500/640000, loss: 0.5096, lr: 0.000040, batch_cost: 0.2724, reader_cost: 0.00013, ips: 58.7303 samples/sec | ETA 30:50:16\r\n",
      "2022-11-16 19:17:26 [INFO]\t[TRAIN] epoch: 58, iter: 232550/640000, loss: 0.5415, lr: 0.000040, batch_cost: 0.2721, reader_cost: 0.00013, ips: 58.7992 samples/sec | ETA 30:47:52\r\n",
      "2022-11-16 19:17:40 [INFO]\t[TRAIN] epoch: 58, iter: 232600/640000, loss: 0.5296, lr: 0.000040, batch_cost: 0.2744, reader_cost: 0.00014, ips: 58.3040 samples/sec | ETA 31:03:20\r\n",
      "2022-11-16 19:17:54 [INFO]\t[TRAIN] epoch: 58, iter: 232650/640000, loss: 0.4868, lr: 0.000040, batch_cost: 0.2719, reader_cost: 0.00013, ips: 58.8553 samples/sec | ETA 30:45:39\r\n",
      "2022-11-16 19:18:07 [INFO]\t[TRAIN] epoch: 58, iter: 232700/640000, loss: 0.5694, lr: 0.000040, batch_cost: 0.2693, reader_cost: 0.00012, ips: 59.4057 samples/sec | ETA 30:28:19\r\n",
      "2022-11-16 19:18:21 [INFO]\t[TRAIN] epoch: 58, iter: 232750/640000, loss: 0.5438, lr: 0.000040, batch_cost: 0.2763, reader_cost: 0.00013, ips: 57.8982 samples/sec | ETA 31:15:42\r\n",
      "2022-11-16 19:18:35 [INFO]\t[TRAIN] epoch: 58, iter: 232800/640000, loss: 0.5116, lr: 0.000040, batch_cost: 0.2721, reader_cost: 0.00013, ips: 58.8055 samples/sec | ETA 30:46:32\r\n",
      "2022-11-16 19:18:48 [INFO]\t[TRAIN] epoch: 58, iter: 232850/640000, loss: 0.5544, lr: 0.000040, batch_cost: 0.2731, reader_cost: 0.00013, ips: 58.5914 samples/sec | ETA 30:53:03\r\n",
      "2022-11-16 19:19:02 [INFO]\t[TRAIN] epoch: 58, iter: 232900/640000, loss: 0.5295, lr: 0.000040, batch_cost: 0.2762, reader_cost: 0.00014, ips: 57.9216 samples/sec | ETA 31:14:15\r\n",
      "2022-11-16 19:19:16 [INFO]\t[TRAIN] epoch: 58, iter: 232950/640000, loss: 0.4980, lr: 0.000040, batch_cost: 0.2816, reader_cost: 0.00014, ips: 56.8140 samples/sec | ETA 31:50:33\r\n",
      "2022-11-16 19:19:30 [INFO]\t[TRAIN] epoch: 58, iter: 233000/640000, loss: 0.5314, lr: 0.000040, batch_cost: 0.2745, reader_cost: 0.00013, ips: 58.2789 samples/sec | ETA 31:02:18\r\n",
      "2022-11-16 19:19:44 [INFO]\t[TRAIN] epoch: 58, iter: 233050/640000, loss: 0.5017, lr: 0.000040, batch_cost: 0.2725, reader_cost: 0.00013, ips: 58.7184 samples/sec | ETA 30:48:08\r\n",
      "2022-11-16 19:19:57 [INFO]\t[TRAIN] epoch: 58, iter: 233100/640000, loss: 0.5298, lr: 0.000040, batch_cost: 0.2721, reader_cost: 0.00013, ips: 58.7951 samples/sec | ETA 30:45:30\r\n",
      "2022-11-16 19:20:11 [INFO]\t[TRAIN] epoch: 58, iter: 233150/640000, loss: 0.5462, lr: 0.000040, batch_cost: 0.2761, reader_cost: 0.00014, ips: 57.9462 samples/sec | ETA 31:12:18\r\n",
      "2022-11-16 19:20:25 [INFO]\t[TRAIN] epoch: 58, iter: 233200/640000, loss: 0.5608, lr: 0.000040, batch_cost: 0.2760, reader_cost: 0.00014, ips: 57.9614 samples/sec | ETA 31:11:35\r\n",
      "2022-11-16 19:20:39 [INFO]\t[TRAIN] epoch: 58, iter: 233250/640000, loss: 0.5668, lr: 0.000040, batch_cost: 0.2743, reader_cost: 0.00014, ips: 58.3392 samples/sec | ETA 30:59:14\r\n",
      "2022-11-16 19:20:52 [INFO]\t[TRAIN] epoch: 58, iter: 233300/640000, loss: 0.5516, lr: 0.000040, batch_cost: 0.2751, reader_cost: 0.00013, ips: 58.1693 samples/sec | ETA 31:04:26\r\n",
      "2022-11-16 19:21:06 [INFO]\t[TRAIN] epoch: 58, iter: 233350/640000, loss: 0.5474, lr: 0.000040, batch_cost: 0.2767, reader_cost: 0.00014, ips: 57.8294 samples/sec | ETA 31:15:10\r\n",
      "2022-11-16 19:21:20 [INFO]\t[TRAIN] epoch: 58, iter: 233400/640000, loss: 0.5061, lr: 0.000040, batch_cost: 0.2752, reader_cost: 0.00015, ips: 58.1322 samples/sec | ETA 31:05:10\r\n",
      "2022-11-16 19:21:33 [INFO]\t[TRAIN] epoch: 58, iter: 233450/640000, loss: 0.5436, lr: 0.000040, batch_cost: 0.2710, reader_cost: 0.00013, ips: 59.0410 samples/sec | ETA 30:36:14\r\n",
      "2022-11-16 19:21:47 [INFO]\t[TRAIN] epoch: 58, iter: 233500/640000, loss: 0.5515, lr: 0.000040, batch_cost: 0.2716, reader_cost: 0.00013, ips: 58.9158 samples/sec | ETA 30:39:54\r\n",
      "2022-11-16 19:22:01 [INFO]\t[TRAIN] epoch: 58, iter: 233550/640000, loss: 0.5642, lr: 0.000040, batch_cost: 0.2714, reader_cost: 0.00013, ips: 58.9521 samples/sec | ETA 30:38:33\r\n",
      "2022-11-16 19:22:14 [INFO]\t[TRAIN] epoch: 58, iter: 233600/640000, loss: 0.5391, lr: 0.000040, batch_cost: 0.2727, reader_cost: 0.00014, ips: 58.6684 samples/sec | ETA 30:47:13\r\n",
      "2022-11-16 19:22:28 [INFO]\t[TRAIN] epoch: 58, iter: 233650/640000, loss: 0.4783, lr: 0.000040, batch_cost: 0.2740, reader_cost: 0.00016, ips: 58.4030 samples/sec | ETA 30:55:23\r\n",
      "2022-11-16 19:22:42 [INFO]\t[TRAIN] epoch: 58, iter: 233700/640000, loss: 0.5599, lr: 0.000040, batch_cost: 0.2735, reader_cost: 0.00014, ips: 58.4968 samples/sec | ETA 30:52:10\r\n",
      "2022-11-16 19:22:55 [INFO]\t[TRAIN] epoch: 58, iter: 233750/640000, loss: 0.5227, lr: 0.000040, batch_cost: 0.2711, reader_cost: 0.00014, ips: 59.0212 samples/sec | ETA 30:35:29\r\n",
      "2022-11-16 19:23:09 [INFO]\t[TRAIN] epoch: 58, iter: 233800/640000, loss: 0.5987, lr: 0.000040, batch_cost: 0.2715, reader_cost: 0.00014, ips: 58.9394 samples/sec | ETA 30:37:49\r\n",
      "2022-11-16 19:23:22 [INFO]\t[TRAIN] epoch: 58, iter: 233850/640000, loss: 0.5176, lr: 0.000040, batch_cost: 0.2716, reader_cost: 0.00013, ips: 58.9021 samples/sec | ETA 30:38:45\r\n",
      "2022-11-16 19:23:36 [INFO]\t[TRAIN] epoch: 58, iter: 233900/640000, loss: 0.5295, lr: 0.000040, batch_cost: 0.2729, reader_cost: 0.00014, ips: 58.6388 samples/sec | ETA 30:46:47\r\n",
      "2022-11-16 19:23:49 [INFO]\t[TRAIN] epoch: 58, iter: 233950/640000, loss: 0.5778, lr: 0.000040, batch_cost: 0.2708, reader_cost: 0.00014, ips: 59.0777 samples/sec | ETA 30:32:50\r\n",
      "2022-11-16 19:24:03 [INFO]\t[TRAIN] epoch: 58, iter: 234000/640000, loss: 0.5230, lr: 0.000040, batch_cost: 0.2720, reader_cost: 0.00014, ips: 58.8246 samples/sec | ETA 30:40:30\r\n",
      "2022-11-16 19:24:03 [INFO]\tStart evaluating (total_samples: 3094, total_iters: 3094)...\r\n",
      "3094/3094 [==============================] - 155s 50ms/step - batch_cost: 0.0499 - reader cost: 9.2347e-05\r\n",
      "2022-11-16 19:26:38 [INFO]\t[EVAL] #Images: 3094 mIoU: 0.6239 Acc: 0.7846 Kappa: 0.7019 Dice: 0.7637\r\n",
      "2022-11-16 19:26:38 [INFO]\t[EVAL] Class IoU: \r\n",
      "[0.6056 0.7748 0.6223 0.4928]\r\n",
      "2022-11-16 19:26:38 [INFO]\t[EVAL] Class Precision: \r\n",
      "[0.7653 0.8598 0.758  0.6757]\r\n",
      "2022-11-16 19:26:38 [INFO]\t[EVAL] Class Recall: \r\n",
      "[0.7437 0.8868 0.7767 0.6455]\r\n",
      "2022-11-16 19:26:38 [INFO]\t[EVAL] The model with the best validation mIoU (0.6256) was saved at iter 226000.\r\n",
      "2022-11-16 19:26:52 [INFO]\t[TRAIN] epoch: 58, iter: 234050/640000, loss: 0.5356, lr: 0.000040, batch_cost: 0.2721, reader_cost: 0.00013, ips: 58.7996 samples/sec | ETA 30:41:03\r\n",
      "2022-11-16 19:27:05 [INFO]\t[TRAIN] epoch: 58, iter: 234100/640000, loss: 0.5321, lr: 0.000040, batch_cost: 0.2709, reader_cost: 0.00013, ips: 59.0613 samples/sec | ETA 30:32:40\r\n",
      "2022-11-16 19:27:19 [INFO]\t[TRAIN] epoch: 58, iter: 234150/640000, loss: 0.5561, lr: 0.000040, batch_cost: 0.2696, reader_cost: 0.00013, ips: 59.3372 samples/sec | ETA 30:23:55\r\n",
      "2022-11-16 19:27:33 [INFO]\t[TRAIN] epoch: 58, iter: 234200/640000, loss: 0.5654, lr: 0.000040, batch_cost: 0.2736, reader_cost: 0.00014, ips: 58.4867 samples/sec | ETA 30:50:13\r\n",
      "2022-11-16 19:27:46 [INFO]\t[TRAIN] epoch: 58, iter: 234250/640000, loss: 0.5509, lr: 0.000040, batch_cost: 0.2712, reader_cost: 0.00014, ips: 58.9990 samples/sec | ETA 30:33:55\r\n",
      "2022-11-16 19:28:00 [INFO]\t[TRAIN] epoch: 58, iter: 234300/640000, loss: 0.5762, lr: 0.000040, batch_cost: 0.2700, reader_cost: 0.00013, ips: 59.2549 samples/sec | ETA 30:25:47\r\n",
      "2022-11-16 19:28:13 [INFO]\t[TRAIN] epoch: 58, iter: 234350/640000, loss: 0.5739, lr: 0.000040, batch_cost: 0.2722, reader_cost: 0.00013, ips: 58.7905 samples/sec | ETA 30:39:58\r\n",
      "2022-11-16 19:28:27 [INFO]\t[TRAIN] epoch: 58, iter: 234400/640000, loss: 0.5412, lr: 0.000040, batch_cost: 0.2741, reader_cost: 0.00016, ips: 58.3748 samples/sec | ETA 30:52:51\r\n",
      "2022-11-16 19:28:41 [INFO]\t[TRAIN] epoch: 58, iter: 234450/640000, loss: 0.5246, lr: 0.000040, batch_cost: 0.2728, reader_cost: 0.00014, ips: 58.6556 samples/sec | ETA 30:43:45\r\n",
      "2022-11-16 19:28:54 [INFO]\t[TRAIN] epoch: 58, iter: 234500/640000, loss: 0.5375, lr: 0.000040, batch_cost: 0.2723, reader_cost: 0.00013, ips: 58.7604 samples/sec | ETA 30:40:14\r\n",
      "2022-11-16 19:29:08 [INFO]\t[TRAIN] epoch: 58, iter: 234550/640000, loss: 0.5553, lr: 0.000040, batch_cost: 0.2711, reader_cost: 0.00014, ips: 59.0244 samples/sec | ETA 30:31:47\r\n",
      "2022-11-16 19:29:21 [INFO]\t[TRAIN] epoch: 58, iter: 234600/640000, loss: 0.5332, lr: 0.000040, batch_cost: 0.2749, reader_cost: 0.00015, ips: 58.2120 samples/sec | ETA 30:57:07\r\n",
      "2022-11-16 19:29:35 [INFO]\t[TRAIN] epoch: 58, iter: 234650/640000, loss: 0.4885, lr: 0.000040, batch_cost: 0.2762, reader_cost: 0.00014, ips: 57.9374 samples/sec | ETA 31:05:41\r\n",
      "2022-11-16 19:29:49 [INFO]\t[TRAIN] epoch: 58, iter: 234700/640000, loss: 0.5184, lr: 0.000040, batch_cost: 0.2738, reader_cost: 0.00014, ips: 58.4279 samples/sec | ETA 30:49:48\r\n",
      "2022-11-16 19:30:03 [INFO]\t[TRAIN] epoch: 58, iter: 234750/640000, loss: 0.5143, lr: 0.000040, batch_cost: 0.2719, reader_cost: 0.00013, ips: 58.8557 samples/sec | ETA 30:36:07\r\n",
      "2022-11-16 19:30:16 [INFO]\t[TRAIN] epoch: 58, iter: 234800/640000, loss: 0.5299, lr: 0.000040, batch_cost: 0.2770, reader_cost: 0.00014, ips: 57.7541 samples/sec | ETA 31:10:55\r\n",
      "2022-11-16 19:30:30 [INFO]\t[TRAIN] epoch: 58, iter: 234850/640000, loss: 0.5699, lr: 0.000040, batch_cost: 0.2710, reader_cost: 0.00014, ips: 59.0298 samples/sec | ETA 30:30:15\r\n",
      "2022-11-16 19:30:44 [INFO]\t[TRAIN] epoch: 58, iter: 234900/640000, loss: 0.5548, lr: 0.000040, batch_cost: 0.2723, reader_cost: 0.00014, ips: 58.7486 samples/sec | ETA 30:38:47\r\n",
      "2022-11-16 19:30:57 [INFO]\t[TRAIN] epoch: 58, iter: 234950/640000, loss: 0.4830, lr: 0.000040, batch_cost: 0.2733, reader_cost: 0.00014, ips: 58.5510 samples/sec | ETA 30:44:46\r\n",
      "2022-11-16 19:31:11 [INFO]\t[TRAIN] epoch: 58, iter: 235000/640000, loss: 0.5235, lr: 0.000040, batch_cost: 0.2723, reader_cost: 0.00013, ips: 58.7616 samples/sec | ETA 30:37:56\r\n",
      "2022-11-16 19:31:25 [INFO]\t[TRAIN] epoch: 58, iter: 235050/640000, loss: 0.5279, lr: 0.000040, batch_cost: 0.2755, reader_cost: 0.00015, ips: 58.0670 samples/sec | ETA 30:59:41\r\n",
      "2022-11-16 19:31:38 [INFO]\t[TRAIN] epoch: 58, iter: 235100/640000, loss: 0.5163, lr: 0.000040, batch_cost: 0.2722, reader_cost: 0.00014, ips: 58.7878 samples/sec | ETA 30:36:39\r\n",
      "2022-11-16 19:31:52 [INFO]\t[TRAIN] epoch: 59, iter: 235150/640000, loss: 0.5592, lr: 0.000040, batch_cost: 0.2735, reader_cost: 0.00346, ips: 58.4914 samples/sec | ETA 30:45:44\r\n",
      "2022-11-16 19:32:05 [INFO]\t[TRAIN] epoch: 59, iter: 235200/640000, loss: 0.5693, lr: 0.000040, batch_cost: 0.2700, reader_cost: 0.00013, ips: 59.2664 samples/sec | ETA 30:21:22\r\n",
      "2022-11-16 19:32:19 [INFO]\t[TRAIN] epoch: 59, iter: 235250/640000, loss: 0.5120, lr: 0.000040, batch_cost: 0.2741, reader_cost: 0.00014, ips: 58.3724 samples/sec | ETA 30:49:02\r\n",
      "2022-11-16 19:32:33 [INFO]\t[TRAIN] epoch: 59, iter: 235300/640000, loss: 0.5195, lr: 0.000040, batch_cost: 0.2719, reader_cost: 0.00014, ips: 58.8551 samples/sec | ETA 30:33:39\r\n",
      "2022-11-16 19:32:46 [INFO]\t[TRAIN] epoch: 59, iter: 235350/640000, loss: 0.5605, lr: 0.000040, batch_cost: 0.2711, reader_cost: 0.00014, ips: 59.0276 samples/sec | ETA 30:28:04\r\n",
      "2022-11-16 19:33:00 [INFO]\t[TRAIN] epoch: 59, iter: 235400/640000, loss: 0.5178, lr: 0.000040, batch_cost: 0.2749, reader_cost: 0.00014, ips: 58.2054 samples/sec | ETA 30:53:39\r\n",
      "2022-11-16 19:33:14 [INFO]\t[TRAIN] epoch: 59, iter: 235450/640000, loss: 0.5398, lr: 0.000040, batch_cost: 0.2751, reader_cost: 0.00014, ips: 58.1643 samples/sec | ETA 30:54:44\r\n",
      "2022-11-16 19:33:28 [INFO]\t[TRAIN] epoch: 59, iter: 235500/640000, loss: 0.5255, lr: 0.000040, batch_cost: 0.2780, reader_cost: 0.00015, ips: 57.5584 samples/sec | ETA 31:14:02\r\n",
      "2022-11-16 19:33:41 [INFO]\t[TRAIN] epoch: 59, iter: 235550/640000, loss: 0.5643, lr: 0.000040, batch_cost: 0.2718, reader_cost: 0.00014, ips: 58.8770 samples/sec | ETA 30:31:50\r\n",
      "2022-11-16 19:33:55 [INFO]\t[TRAIN] epoch: 59, iter: 235600/640000, loss: 0.5059, lr: 0.000040, batch_cost: 0.2713, reader_cost: 0.00014, ips: 58.9794 samples/sec | ETA 30:28:26\r\n",
      "2022-11-16 19:34:08 [INFO]\t[TRAIN] epoch: 59, iter: 235650/640000, loss: 0.5080, lr: 0.000040, batch_cost: 0.2727, reader_cost: 0.00014, ips: 58.6679 samples/sec | ETA 30:37:55\r\n",
      "2022-11-16 19:34:22 [INFO]\t[TRAIN] epoch: 59, iter: 235700/640000, loss: 0.5948, lr: 0.000040, batch_cost: 0.2718, reader_cost: 0.00014, ips: 58.8697 samples/sec | ETA 30:31:23\r\n",
      "2022-11-16 19:34:36 [INFO]\t[TRAIN] epoch: 59, iter: 235750/640000, loss: 0.5202, lr: 0.000040, batch_cost: 0.2764, reader_cost: 0.00014, ips: 57.8898 samples/sec | ETA 31:02:09\r\n",
      "2022-11-16 19:34:50 [INFO]\t[TRAIN] epoch: 59, iter: 235800/640000, loss: 0.4842, lr: 0.000040, batch_cost: 0.2735, reader_cost: 0.00013, ips: 58.4950 samples/sec | ETA 30:42:39\r\n",
      "2022-11-16 19:35:03 [INFO]\t[TRAIN] epoch: 59, iter: 235850/640000, loss: 0.5488, lr: 0.000040, batch_cost: 0.2723, reader_cost: 0.00013, ips: 58.7512 samples/sec | ETA 30:34:24\r\n",
      "2022-11-16 19:35:17 [INFO]\t[TRAIN] epoch: 59, iter: 235900/640000, loss: 0.5048, lr: 0.000040, batch_cost: 0.2713, reader_cost: 0.00013, ips: 58.9843 samples/sec | ETA 30:26:55\r\n",
      "2022-11-16 19:35:30 [INFO]\t[TRAIN] epoch: 59, iter: 235950/640000, loss: 0.5634, lr: 0.000040, batch_cost: 0.2734, reader_cost: 0.00014, ips: 58.5117 samples/sec | ETA 30:41:27\r\n",
      "2022-11-16 19:35:44 [INFO]\t[TRAIN] epoch: 59, iter: 236000/640000, loss: 0.5331, lr: 0.000040, batch_cost: 0.2771, reader_cost: 0.00014, ips: 57.7490 samples/sec | ETA 31:05:32\r\n",
      "2022-11-16 19:35:44 [INFO]\tStart evaluating (total_samples: 3094, total_iters: 3094)...\r\n",
      "3094/3094 [==============================] - 154s 50ms/step - batch_cost: 0.0496 - reader cost: 8.9409e-05\r\n",
      "2022-11-16 19:38:18 [INFO]\t[EVAL] #Images: 3094 mIoU: 0.6210 Acc: 0.7826 Kappa: 0.6991 Dice: 0.7614\r\n",
      "2022-11-16 19:38:18 [INFO]\t[EVAL] Class IoU: \r\n",
      "[0.6015 0.7734 0.62   0.489 ]\r\n",
      "2022-11-16 19:38:18 [INFO]\t[EVAL] Class Precision: \r\n",
      "[0.7592 0.8606 0.7524 0.6769]\r\n",
      "2022-11-16 19:38:18 [INFO]\t[EVAL] Class Recall: \r\n",
      "[0.7434 0.8842 0.7789 0.6379]\r\n",
      "2022-11-16 19:38:19 [INFO]\t[EVAL] The model with the best validation mIoU (0.6256) was saved at iter 226000.\r\n",
      "2022-11-16 19:38:32 [INFO]\t[TRAIN] epoch: 59, iter: 236050/640000, loss: 0.5218, lr: 0.000040, batch_cost: 0.2712, reader_cost: 0.00014, ips: 59.0014 samples/sec | ETA 30:25:43\r\n",
      "2022-11-16 19:38:46 [INFO]\t[TRAIN] epoch: 59, iter: 236100/640000, loss: 0.5057, lr: 0.000040, batch_cost: 0.2743, reader_cost: 0.00014, ips: 58.3214 samples/sec | ETA 30:46:46\r\n",
      "2022-11-16 19:39:00 [INFO]\t[TRAIN] epoch: 59, iter: 236150/640000, loss: 0.5402, lr: 0.000040, batch_cost: 0.2766, reader_cost: 0.00014, ips: 57.8412 samples/sec | ETA 31:01:52\r\n",
      "2022-11-16 19:39:14 [INFO]\t[TRAIN] epoch: 59, iter: 236200/640000, loss: 0.5230, lr: 0.000040, batch_cost: 0.2727, reader_cost: 0.00014, ips: 58.6726 samples/sec | ETA 30:35:16\r\n",
      "2022-11-16 19:39:27 [INFO]\t[TRAIN] epoch: 59, iter: 236250/640000, loss: 0.4978, lr: 0.000040, batch_cost: 0.2716, reader_cost: 0.00014, ips: 58.9126 samples/sec | ETA 30:27:34\r\n",
      "2022-11-16 19:39:41 [INFO]\t[TRAIN] epoch: 59, iter: 236300/640000, loss: 0.5277, lr: 0.000040, batch_cost: 0.2766, reader_cost: 0.00016, ips: 57.8534 samples/sec | ETA 31:00:47\r\n",
      "2022-11-16 19:39:55 [INFO]\t[TRAIN] epoch: 59, iter: 236350/640000, loss: 0.5714, lr: 0.000040, batch_cost: 0.2727, reader_cost: 0.00015, ips: 58.6674 samples/sec | ETA 30:34:44\r\n",
      "2022-11-16 19:40:08 [INFO]\t[TRAIN] epoch: 59, iter: 236400/640000, loss: 0.5210, lr: 0.000040, batch_cost: 0.2740, reader_cost: 0.00015, ips: 58.3981 samples/sec | ETA 30:42:58\r\n",
      "2022-11-16 19:40:22 [INFO]\t[TRAIN] epoch: 59, iter: 236450/640000, loss: 0.5077, lr: 0.000040, batch_cost: 0.2737, reader_cost: 0.00015, ips: 58.4506 samples/sec | ETA 30:41:05\r\n",
      "2022-11-16 19:40:36 [INFO]\t[TRAIN] epoch: 59, iter: 236500/640000, loss: 0.5088, lr: 0.000040, batch_cost: 0.2734, reader_cost: 0.00015, ips: 58.5192 samples/sec | ETA 30:38:42\r\n",
      "2022-11-16 19:40:49 [INFO]\t[TRAIN] epoch: 59, iter: 236550/640000, loss: 0.5947, lr: 0.000040, batch_cost: 0.2761, reader_cost: 0.00015, ips: 57.9564 samples/sec | ETA 30:56:20\r\n",
      "2022-11-16 19:41:03 [INFO]\t[TRAIN] epoch: 59, iter: 236600/640000, loss: 0.5472, lr: 0.000040, batch_cost: 0.2729, reader_cost: 0.00015, ips: 58.6255 samples/sec | ETA 30:34:55\r\n",
      "2022-11-16 19:41:17 [INFO]\t[TRAIN] epoch: 59, iter: 236650/640000, loss: 0.5679, lr: 0.000040, batch_cost: 0.2731, reader_cost: 0.00016, ips: 58.5838 samples/sec | ETA 30:36:00\r\n",
      "2022-11-16 19:41:30 [INFO]\t[TRAIN] epoch: 59, iter: 236700/640000, loss: 0.5466, lr: 0.000040, batch_cost: 0.2740, reader_cost: 0.00015, ips: 58.3860 samples/sec | ETA 30:41:59\r\n",
      "2022-11-16 19:41:44 [INFO]\t[TRAIN] epoch: 59, iter: 236750/640000, loss: 0.5461, lr: 0.000040, batch_cost: 0.2735, reader_cost: 0.00015, ips: 58.4998 samples/sec | ETA 30:38:10\r\n",
      "2022-11-16 19:41:58 [INFO]\t[TRAIN] epoch: 59, iter: 236800/640000, loss: 0.5256, lr: 0.000040, batch_cost: 0.2714, reader_cost: 0.00015, ips: 58.9553 samples/sec | ETA 30:23:45\r\n",
      "2022-11-16 19:42:11 [INFO]\t[TRAIN] epoch: 59, iter: 236850/640000, loss: 0.4986, lr: 0.000040, batch_cost: 0.2734, reader_cost: 0.00015, ips: 58.5328 samples/sec | ETA 30:36:41\r\n",
      "2022-11-16 19:42:25 [INFO]\t[TRAIN] epoch: 59, iter: 236900/640000, loss: 0.5298, lr: 0.000040, batch_cost: 0.2739, reader_cost: 0.00015, ips: 58.4108 samples/sec | ETA 30:40:17\r\n",
      "2022-11-16 19:42:39 [INFO]\t[TRAIN] epoch: 59, iter: 236950/640000, loss: 0.5650, lr: 0.000040, batch_cost: 0.2724, reader_cost: 0.00015, ips: 58.7466 samples/sec | ETA 30:29:33\r\n",
      "2022-11-16 19:42:52 [INFO]\t[TRAIN] epoch: 59, iter: 237000/640000, loss: 0.5657, lr: 0.000040, batch_cost: 0.2740, reader_cost: 0.00016, ips: 58.3940 samples/sec | ETA 30:40:22\r\n",
      "2022-11-16 19:43:06 [INFO]\t[TRAIN] epoch: 59, iter: 237050/640000, loss: 0.5522, lr: 0.000040, batch_cost: 0.2742, reader_cost: 0.00015, ips: 58.3494 samples/sec | ETA 30:41:32\r\n",
      "2022-11-16 19:43:20 [INFO]\t[TRAIN] epoch: 59, iter: 237100/640000, loss: 0.5392, lr: 0.000040, batch_cost: 0.2779, reader_cost: 0.00015, ips: 57.5655 samples/sec | ETA 31:06:23\r\n",
      "2022-11-16 19:43:34 [INFO]\t[TRAIN] epoch: 59, iter: 237150/640000, loss: 0.5273, lr: 0.000040, batch_cost: 0.2723, reader_cost: 0.00013, ips: 58.7534 samples/sec | ETA 30:28:26\r\n",
      "2022-11-16 19:43:47 [INFO]\t[TRAIN] epoch: 59, iter: 237200/640000, loss: 0.5447, lr: 0.000040, batch_cost: 0.2755, reader_cost: 0.00014, ips: 58.0709 samples/sec | ETA 30:49:41\r\n",
      "2022-11-16 19:44:01 [INFO]\t[TRAIN] epoch: 59, iter: 237250/640000, loss: 0.5246, lr: 0.000040, batch_cost: 0.2712, reader_cost: 0.00013, ips: 58.9917 samples/sec | ETA 30:20:35\r\n",
      "2022-11-16 19:44:15 [INFO]\t[TRAIN] epoch: 59, iter: 237300/640000, loss: 0.5583, lr: 0.000040, batch_cost: 0.2711, reader_cost: 0.00013, ips: 59.0145 samples/sec | ETA 30:19:40\r\n",
      "2022-11-16 19:44:28 [INFO]\t[TRAIN] epoch: 59, iter: 237350/640000, loss: 0.5751, lr: 0.000040, batch_cost: 0.2699, reader_cost: 0.00013, ips: 59.2877 samples/sec | ETA 30:11:03\r\n",
      "2022-11-16 19:44:42 [INFO]\t[TRAIN] epoch: 59, iter: 237400/640000, loss: 0.5320, lr: 0.000040, batch_cost: 0.2715, reader_cost: 0.00013, ips: 58.9370 samples/sec | ETA 30:21:36\r\n",
      "2022-11-16 19:44:55 [INFO]\t[TRAIN] epoch: 59, iter: 237450/640000, loss: 0.5431, lr: 0.000040, batch_cost: 0.2724, reader_cost: 0.00013, ips: 58.7271 samples/sec | ETA 30:27:53\r\n",
      "2022-11-16 19:45:09 [INFO]\t[TRAIN] epoch: 59, iter: 237500/640000, loss: 0.5400, lr: 0.000040, batch_cost: 0.2706, reader_cost: 0.00013, ips: 59.1267 samples/sec | ETA 30:15:18\r\n",
      "2022-11-16 19:45:22 [INFO]\t[TRAIN] epoch: 59, iter: 237550/640000, loss: 0.5270, lr: 0.000040, batch_cost: 0.2726, reader_cost: 0.00013, ips: 58.6900 samples/sec | ETA 30:28:35\r\n",
      "2022-11-16 19:45:36 [INFO]\t[TRAIN] epoch: 59, iter: 237600/640000, loss: 0.5206, lr: 0.000040, batch_cost: 0.2780, reader_cost: 0.00014, ips: 57.5628 samples/sec | ETA 31:04:09\r\n",
      "2022-11-16 19:45:50 [INFO]\t[TRAIN] epoch: 59, iter: 237650/640000, loss: 0.5522, lr: 0.000040, batch_cost: 0.2732, reader_cost: 0.00014, ips: 58.5548 samples/sec | ETA 30:32:21\r\n",
      "2022-11-16 19:46:04 [INFO]\t[TRAIN] epoch: 59, iter: 237700/640000, loss: 0.5250, lr: 0.000040, batch_cost: 0.2721, reader_cost: 0.00014, ips: 58.7980 samples/sec | ETA 30:24:33\r\n",
      "2022-11-16 19:46:17 [INFO]\t[TRAIN] epoch: 59, iter: 237750/640000, loss: 0.5651, lr: 0.000040, batch_cost: 0.2723, reader_cost: 0.00013, ips: 58.7520 samples/sec | ETA 30:25:45\r\n",
      "2022-11-16 19:46:31 [INFO]\t[TRAIN] epoch: 59, iter: 237800/640000, loss: 0.5804, lr: 0.000039, batch_cost: 0.2722, reader_cost: 0.00014, ips: 58.7723 samples/sec | ETA 30:24:53\r\n",
      "2022-11-16 19:46:44 [INFO]\t[TRAIN] epoch: 59, iter: 237850/640000, loss: 0.5309, lr: 0.000039, batch_cost: 0.2723, reader_cost: 0.00013, ips: 58.7531 samples/sec | ETA 30:25:15\r\n",
      "2022-11-16 19:46:58 [INFO]\t[TRAIN] epoch: 59, iter: 237900/640000, loss: 0.5598, lr: 0.000039, batch_cost: 0.2756, reader_cost: 0.00014, ips: 58.0494 samples/sec | ETA 30:47:09\r\n",
      "2022-11-16 19:47:12 [INFO]\t[TRAIN] epoch: 59, iter: 237950/640000, loss: 0.5270, lr: 0.000039, batch_cost: 0.2727, reader_cost: 0.00013, ips: 58.6661 samples/sec | ETA 30:27:30\r\n",
      "2022-11-16 19:47:25 [INFO]\t[TRAIN] epoch: 59, iter: 238000/640000, loss: 0.5188, lr: 0.000039, batch_cost: 0.2700, reader_cost: 0.00013, ips: 59.2638 samples/sec | ETA 30:08:51\r\n",
      "2022-11-16 19:47:25 [INFO]\tStart evaluating (total_samples: 3094, total_iters: 3094)...\r\n",
      "3094/3094 [==============================] - 154s 50ms/step - batch_cost: 0.0497 - reader cost: 8.8706e-05\r\n",
      "2022-11-16 19:49:59 [INFO]\t[EVAL] #Images: 3094 mIoU: 0.6223 Acc: 0.7846 Kappa: 0.7010 Dice: 0.7623\r\n",
      "2022-11-16 19:49:59 [INFO]\t[EVAL] Class IoU: \r\n",
      "[0.607  0.776  0.6198 0.4864]\r\n",
      "2022-11-16 19:49:59 [INFO]\t[EVAL] Class Precision: \r\n",
      "[0.7432 0.8578 0.7716 0.6962]\r\n",
      "2022-11-16 19:49:59 [INFO]\t[EVAL] Class Recall: \r\n",
      "[0.7681 0.8905 0.759  0.6174]\r\n",
      "2022-11-16 19:50:00 [INFO]\t[EVAL] The model with the best validation mIoU (0.6256) was saved at iter 226000.\r\n",
      "2022-11-16 19:50:14 [INFO]\t[TRAIN] epoch: 59, iter: 238050/640000, loss: 0.5449, lr: 0.000039, batch_cost: 0.2775, reader_cost: 0.00015, ips: 57.6532 samples/sec | ETA 30:59:09\r\n",
      "2022-11-16 19:50:28 [INFO]\t[TRAIN] epoch: 59, iter: 238100/640000, loss: 0.5168, lr: 0.000039, batch_cost: 0.2807, reader_cost: 0.00014, ips: 57.0004 samples/sec | ETA 31:20:13\r\n",
      "2022-11-16 19:50:42 [INFO]\t[TRAIN] epoch: 59, iter: 238150/640000, loss: 0.5239, lr: 0.000039, batch_cost: 0.2818, reader_cost: 0.00015, ips: 56.7772 samples/sec | ETA 31:27:22\r\n",
      "2022-11-16 19:50:56 [INFO]\t[TRAIN] epoch: 59, iter: 238200/640000, loss: 0.5263, lr: 0.000039, batch_cost: 0.2736, reader_cost: 0.00014, ips: 58.4879 samples/sec | ETA 30:31:56\r\n",
      "2022-11-16 19:51:09 [INFO]\t[TRAIN] epoch: 59, iter: 238250/640000, loss: 0.5682, lr: 0.000039, batch_cost: 0.2723, reader_cost: 0.00014, ips: 58.7684 samples/sec | ETA 30:22:58\r\n",
      "2022-11-16 19:51:23 [INFO]\t[TRAIN] epoch: 59, iter: 238300/640000, loss: 0.5109, lr: 0.000039, batch_cost: 0.2703, reader_cost: 0.00013, ips: 59.1938 samples/sec | ETA 30:09:38\r\n",
      "2022-11-16 19:51:36 [INFO]\t[TRAIN] epoch: 59, iter: 238350/640000, loss: 0.5062, lr: 0.000039, batch_cost: 0.2701, reader_cost: 0.00014, ips: 59.2341 samples/sec | ETA 30:08:11\r\n",
      "2022-11-16 19:51:50 [INFO]\t[TRAIN] epoch: 59, iter: 238400/640000, loss: 0.5423, lr: 0.000039, batch_cost: 0.2707, reader_cost: 0.00014, ips: 59.0960 samples/sec | ETA 30:12:11\r\n",
      "2022-11-16 19:52:03 [INFO]\t[TRAIN] epoch: 59, iter: 238450/640000, loss: 0.5417, lr: 0.000039, batch_cost: 0.2691, reader_cost: 0.00013, ips: 59.4522 samples/sec | ETA 30:01:06\r\n",
      "2022-11-16 19:52:17 [INFO]\t[TRAIN] epoch: 59, iter: 238500/640000, loss: 0.5136, lr: 0.000039, batch_cost: 0.2698, reader_cost: 0.00013, ips: 59.3028 samples/sec | ETA 30:05:25\r\n",
      "2022-11-16 19:52:30 [INFO]\t[TRAIN] epoch: 59, iter: 238550/640000, loss: 0.5383, lr: 0.000039, batch_cost: 0.2685, reader_cost: 0.00012, ips: 59.5833 samples/sec | ETA 29:56:42\r\n",
      "2022-11-16 19:52:44 [INFO]\t[TRAIN] epoch: 59, iter: 238600/640000, loss: 0.5026, lr: 0.000039, batch_cost: 0.2708, reader_cost: 0.00013, ips: 59.0939 samples/sec | ETA 30:11:21\r\n",
      "2022-11-16 19:52:57 [INFO]\t[TRAIN] epoch: 59, iter: 238650/640000, loss: 0.4954, lr: 0.000039, batch_cost: 0.2706, reader_cost: 0.00013, ips: 59.1283 samples/sec | ETA 30:10:04\r\n",
      "2022-11-16 19:53:11 [INFO]\t[TRAIN] epoch: 59, iter: 238700/640000, loss: 0.5156, lr: 0.000039, batch_cost: 0.2716, reader_cost: 0.00013, ips: 58.9001 samples/sec | ETA 30:16:51\r\n",
      "2022-11-16 19:53:24 [INFO]\t[TRAIN] epoch: 59, iter: 238750/640000, loss: 0.5061, lr: 0.000039, batch_cost: 0.2706, reader_cost: 0.00012, ips: 59.1371 samples/sec | ETA 30:09:21\r\n",
      "2022-11-16 19:53:38 [INFO]\t[TRAIN] epoch: 59, iter: 238800/640000, loss: 0.5407, lr: 0.000039, batch_cost: 0.2699, reader_cost: 0.00013, ips: 59.2710 samples/sec | ETA 30:05:02\r\n",
      "2022-11-16 19:53:51 [INFO]\t[TRAIN] epoch: 59, iter: 238850/640000, loss: 0.5476, lr: 0.000039, batch_cost: 0.2709, reader_cost: 0.00014, ips: 59.0698 samples/sec | ETA 30:10:57\r\n",
      "2022-11-16 19:54:05 [INFO]\t[TRAIN] epoch: 59, iter: 238900/640000, loss: 0.5733, lr: 0.000039, batch_cost: 0.2755, reader_cost: 0.00015, ips: 58.0666 samples/sec | ETA 30:42:01\r\n",
      "2022-11-16 19:54:19 [INFO]\t[TRAIN] epoch: 59, iter: 238950/640000, loss: 0.5487, lr: 0.000039, batch_cost: 0.2738, reader_cost: 0.00013, ips: 58.4331 samples/sec | ETA 30:30:14\r\n",
      "2022-11-16 19:54:32 [INFO]\t[TRAIN] epoch: 59, iter: 239000/640000, loss: 0.5447, lr: 0.000039, batch_cost: 0.2702, reader_cost: 0.00013, ips: 59.2130 samples/sec | ETA 30:05:54\r\n",
      "2022-11-16 19:54:46 [INFO]\t[TRAIN] epoch: 59, iter: 239050/640000, loss: 0.5240, lr: 0.000039, batch_cost: 0.2720, reader_cost: 0.00013, ips: 58.8316 samples/sec | ETA 30:17:23\r\n",
      "2022-11-16 19:54:59 [INFO]\t[TRAIN] epoch: 59, iter: 239100/640000, loss: 0.5437, lr: 0.000039, batch_cost: 0.2687, reader_cost: 0.00012, ips: 59.5414 samples/sec | ETA 29:55:30\r\n",
      "2022-11-16 19:55:13 [INFO]\t[TRAIN] epoch: 59, iter: 239150/640000, loss: 0.5317, lr: 0.000039, batch_cost: 0.2698, reader_cost: 0.00013, ips: 59.3004 samples/sec | ETA 30:02:34\r\n",
      "2022-11-16 19:55:27 [INFO]\t[TRAIN] epoch: 60, iter: 239200/640000, loss: 0.4994, lr: 0.000039, batch_cost: 0.2761, reader_cost: 0.00330, ips: 57.9407 samples/sec | ETA 30:44:38\r\n",
      "2022-11-16 19:55:40 [INFO]\t[TRAIN] epoch: 60, iter: 239250/640000, loss: 0.5060, lr: 0.000039, batch_cost: 0.2702, reader_cost: 0.00015, ips: 59.2175 samples/sec | ETA 30:04:38\r\n",
      "2022-11-16 19:55:54 [INFO]\t[TRAIN] epoch: 60, iter: 239300/640000, loss: 0.5553, lr: 0.000039, batch_cost: 0.2725, reader_cost: 0.00013, ips: 58.7259 samples/sec | ETA 30:19:31\r\n",
      "2022-11-16 19:56:07 [INFO]\t[TRAIN] epoch: 60, iter: 239350/640000, loss: 0.5225, lr: 0.000039, batch_cost: 0.2717, reader_cost: 0.00014, ips: 58.8815 samples/sec | ETA 30:14:29\r\n",
      "2022-11-16 19:56:21 [INFO]\t[TRAIN] epoch: 60, iter: 239400/640000, loss: 0.5627, lr: 0.000039, batch_cost: 0.2729, reader_cost: 0.00014, ips: 58.6191 samples/sec | ETA 30:22:23\r\n",
      "2022-11-16 19:56:35 [INFO]\t[TRAIN] epoch: 60, iter: 239450/640000, loss: 0.5140, lr: 0.000039, batch_cost: 0.2717, reader_cost: 0.00013, ips: 58.8911 samples/sec | ETA 30:13:44\r\n",
      "2022-11-16 19:56:48 [INFO]\t[TRAIN] epoch: 60, iter: 239500/640000, loss: 0.5527, lr: 0.000039, batch_cost: 0.2717, reader_cost: 0.00013, ips: 58.8872 samples/sec | ETA 30:13:38\r\n",
      "2022-11-16 19:57:02 [INFO]\t[TRAIN] epoch: 60, iter: 239550/640000, loss: 0.5665, lr: 0.000039, batch_cost: 0.2723, reader_cost: 0.00014, ips: 58.7553 samples/sec | ETA 30:17:28\r\n",
      "2022-11-16 19:57:15 [INFO]\t[TRAIN] epoch: 60, iter: 239600/640000, loss: 0.4859, lr: 0.000039, batch_cost: 0.2735, reader_cost: 0.00013, ips: 58.5112 samples/sec | ETA 30:24:50\r\n",
      "2022-11-16 19:57:29 [INFO]\t[TRAIN] epoch: 60, iter: 239650/640000, loss: 0.4663, lr: 0.000039, batch_cost: 0.2714, reader_cost: 0.00013, ips: 58.9597 samples/sec | ETA 30:10:43\r\n",
      "2022-11-16 19:57:43 [INFO]\t[TRAIN] epoch: 60, iter: 239700/640000, loss: 0.5789, lr: 0.000039, batch_cost: 0.2697, reader_cost: 0.00015, ips: 59.3236 samples/sec | ETA 29:59:23\r\n",
      "2022-11-16 19:57:56 [INFO]\t[TRAIN] epoch: 60, iter: 239750/640000, loss: 0.5011, lr: 0.000039, batch_cost: 0.2683, reader_cost: 0.00012, ips: 59.6447 samples/sec | ETA 29:49:29\r\n",
      "2022-11-16 19:58:10 [INFO]\t[TRAIN] epoch: 60, iter: 239800/640000, loss: 0.5559, lr: 0.000039, batch_cost: 0.2749, reader_cost: 0.00013, ips: 58.2121 samples/sec | ETA 30:33:17\r\n",
      "2022-11-16 19:58:23 [INFO]\t[TRAIN] epoch: 60, iter: 239850/640000, loss: 0.5312, lr: 0.000039, batch_cost: 0.2753, reader_cost: 0.00014, ips: 58.1178 samples/sec | ETA 30:36:02\r\n",
      "2022-11-16 19:58:37 [INFO]\t[TRAIN] epoch: 60, iter: 239900/640000, loss: 0.5557, lr: 0.000039, batch_cost: 0.2713, reader_cost: 0.00014, ips: 58.9822 samples/sec | ETA 30:08:54\r\n",
      "2022-11-16 19:58:51 [INFO]\t[TRAIN] epoch: 60, iter: 239950/640000, loss: 0.5695, lr: 0.000039, batch_cost: 0.2711, reader_cost: 0.00013, ips: 59.0269 samples/sec | ETA 30:07:18\r\n",
      "2022-11-16 19:59:04 [INFO]\t[TRAIN] epoch: 60, iter: 240000/640000, loss: 0.5518, lr: 0.000039, batch_cost: 0.2699, reader_cost: 0.00013, ips: 59.2777 samples/sec | ETA 29:59:26\r\n",
      "2022-11-16 19:59:04 [INFO]\tStart evaluating (total_samples: 3094, total_iters: 3094)...\r\n",
      "3094/3094 [==============================] - 160s 52ms/step - batch_cost: 0.0516 - reader cost: 8.8628e-05\r\n",
      "2022-11-16 20:01:44 [INFO]\t[EVAL] #Images: 3094 mIoU: 0.6232 Acc: 0.7842 Kappa: 0.7014 Dice: 0.7630\r\n",
      "2022-11-16 20:01:44 [INFO]\t[EVAL] Class IoU: \r\n",
      "[0.6073 0.7766 0.621  0.4879]\r\n",
      "2022-11-16 20:01:44 [INFO]\t[EVAL] Class Precision: \r\n",
      "[0.7589 0.8666 0.7576 0.6713]\r\n",
      "2022-11-16 20:01:44 [INFO]\t[EVAL] Class Recall: \r\n",
      "[0.7525 0.882  0.775  0.6411]\r\n",
      "2022-11-16 20:01:45 [INFO]\t[EVAL] The model with the best validation mIoU (0.6256) was saved at iter 226000.\r\n",
      "2022-11-16 20:01:58 [INFO]\t[TRAIN] epoch: 60, iter: 240050/640000, loss: 0.5392, lr: 0.000039, batch_cost: 0.2712, reader_cost: 0.00013, ips: 58.9909 samples/sec | ETA 30:07:57\r\n",
      "2022-11-16 20:02:12 [INFO]\t[TRAIN] epoch: 60, iter: 240100/640000, loss: 0.5302, lr: 0.000039, batch_cost: 0.2720, reader_cost: 0.00014, ips: 58.8167 samples/sec | ETA 30:13:05\r\n",
      "2022-11-16 20:02:26 [INFO]\t[TRAIN] epoch: 60, iter: 240150/640000, loss: 0.5149, lr: 0.000039, batch_cost: 0.2731, reader_cost: 0.00014, ips: 58.5919 samples/sec | ETA 30:19:49\r\n",
      "2022-11-16 20:02:39 [INFO]\t[TRAIN] epoch: 60, iter: 240200/640000, loss: 0.5091, lr: 0.000039, batch_cost: 0.2695, reader_cost: 0.00013, ips: 59.3773 samples/sec | ETA 29:55:31\r\n",
      "2022-11-16 20:02:52 [INFO]\t[TRAIN] epoch: 60, iter: 240250/640000, loss: 0.4940, lr: 0.000039, batch_cost: 0.2695, reader_cost: 0.00013, ips: 59.3728 samples/sec | ETA 29:55:26\r\n",
      "2022-11-16 20:03:06 [INFO]\t[TRAIN] epoch: 60, iter: 240300/640000, loss: 0.5644, lr: 0.000039, batch_cost: 0.2698, reader_cost: 0.00013, ips: 59.3093 samples/sec | ETA 29:57:07\r\n",
      "2022-11-16 20:03:19 [INFO]\t[TRAIN] epoch: 60, iter: 240350/640000, loss: 0.5416, lr: 0.000039, batch_cost: 0.2698, reader_cost: 0.00012, ips: 59.3129 samples/sec | ETA 29:56:47\r\n",
      "2022-11-16 20:03:33 [INFO]\t[TRAIN] epoch: 60, iter: 240400/640000, loss: 0.5182, lr: 0.000039, batch_cost: 0.2693, reader_cost: 0.00012, ips: 59.4212 samples/sec | ETA 29:53:18\r\n",
      "2022-11-16 20:03:47 [INFO]\t[TRAIN] epoch: 60, iter: 240450/640000, loss: 0.5245, lr: 0.000039, batch_cost: 0.2721, reader_cost: 0.00014, ips: 58.8108 samples/sec | ETA 30:11:41\r\n",
      "2022-11-16 20:04:00 [INFO]\t[TRAIN] epoch: 60, iter: 240500/640000, loss: 0.5160, lr: 0.000039, batch_cost: 0.2723, reader_cost: 0.00014, ips: 58.7590 samples/sec | ETA 30:13:03\r\n",
      "2022-11-16 20:04:14 [INFO]\t[TRAIN] epoch: 60, iter: 240550/640000, loss: 0.5616, lr: 0.000039, batch_cost: 0.2715, reader_cost: 0.00013, ips: 58.9243 samples/sec | ETA 30:07:44\r\n",
      "2022-11-16 20:04:27 [INFO]\t[TRAIN] epoch: 60, iter: 240600/640000, loss: 0.5672, lr: 0.000039, batch_cost: 0.2736, reader_cost: 0.00014, ips: 58.4848 samples/sec | ETA 30:21:05\r\n",
      "2022-11-16 20:04:41 [INFO]\t[TRAIN] epoch: 60, iter: 240650/640000, loss: 0.5397, lr: 0.000039, batch_cost: 0.2734, reader_cost: 0.00014, ips: 58.5256 samples/sec | ETA 30:19:36\r\n",
      "2022-11-16 20:04:55 [INFO]\t[TRAIN] epoch: 60, iter: 240700/640000, loss: 0.5380, lr: 0.000039, batch_cost: 0.2715, reader_cost: 0.00013, ips: 58.9260 samples/sec | ETA 30:07:00\r\n",
      "2022-11-16 20:05:08 [INFO]\t[TRAIN] epoch: 60, iter: 240750/640000, loss: 0.5258, lr: 0.000039, batch_cost: 0.2718, reader_cost: 0.00013, ips: 58.8568 samples/sec | ETA 30:08:54\r\n",
      "2022-11-16 20:05:22 [INFO]\t[TRAIN] epoch: 60, iter: 240800/640000, loss: 0.4502, lr: 0.000039, batch_cost: 0.2731, reader_cost: 0.00013, ips: 58.5819 samples/sec | ETA 30:17:10\r\n",
      "2022-11-16 20:05:35 [INFO]\t[TRAIN] epoch: 60, iter: 240850/640000, loss: 0.5477, lr: 0.000039, batch_cost: 0.2698, reader_cost: 0.00013, ips: 59.3006 samples/sec | ETA 29:54:55\r\n",
      "2022-11-16 20:05:49 [INFO]\t[TRAIN] epoch: 60, iter: 240900/640000, loss: 0.5145, lr: 0.000039, batch_cost: 0.2692, reader_cost: 0.00013, ips: 59.4318 samples/sec | ETA 29:50:44\r\n",
      "2022-11-16 20:06:02 [INFO]\t[TRAIN] epoch: 60, iter: 240950/640000, loss: 0.5417, lr: 0.000039, batch_cost: 0.2723, reader_cost: 0.00013, ips: 58.7621 samples/sec | ETA 30:10:54\r\n",
      "2022-11-16 20:06:16 [INFO]\t[TRAIN] epoch: 60, iter: 241000/640000, loss: 0.5126, lr: 0.000039, batch_cost: 0.2726, reader_cost: 0.00014, ips: 58.7035 samples/sec | ETA 30:12:29\r\n",
      "2022-11-16 20:06:30 [INFO]\t[TRAIN] epoch: 60, iter: 241050/640000, loss: 0.5179, lr: 0.000039, batch_cost: 0.2708, reader_cost: 0.00013, ips: 59.0890 samples/sec | ETA 30:00:26\r\n",
      "2022-11-16 20:06:43 [INFO]\t[TRAIN] epoch: 60, iter: 241100/640000, loss: 0.5339, lr: 0.000039, batch_cost: 0.2706, reader_cost: 0.00013, ips: 59.1297 samples/sec | ETA 29:58:58\r\n",
      "2022-11-16 20:06:57 [INFO]\t[TRAIN] epoch: 60, iter: 241150/640000, loss: 0.5182, lr: 0.000039, batch_cost: 0.2704, reader_cost: 0.00013, ips: 59.1679 samples/sec | ETA 29:57:35\r\n",
      "2022-11-16 20:07:10 [INFO]\t[TRAIN] epoch: 60, iter: 241200/640000, loss: 0.5313, lr: 0.000039, batch_cost: 0.2691, reader_cost: 0.00013, ips: 59.4667 samples/sec | ETA 29:48:20\r\n",
      "2022-11-16 20:07:24 [INFO]\t[TRAIN] epoch: 60, iter: 241250/640000, loss: 0.5180, lr: 0.000039, batch_cost: 0.2703, reader_cost: 0.00013, ips: 59.1876 samples/sec | ETA 29:56:32\r\n",
      "2022-11-16 20:07:37 [INFO]\t[TRAIN] epoch: 60, iter: 241300/640000, loss: 0.5123, lr: 0.000039, batch_cost: 0.2703, reader_cost: 0.00013, ips: 59.1841 samples/sec | ETA 29:56:25\r\n",
      "2022-11-16 20:07:51 [INFO]\t[TRAIN] epoch: 60, iter: 241350/640000, loss: 0.5148, lr: 0.000039, batch_cost: 0.2702, reader_cost: 0.00013, ips: 59.2052 samples/sec | ETA 29:55:33\r\n",
      "2022-11-16 20:08:04 [INFO]\t[TRAIN] epoch: 60, iter: 241400/640000, loss: 0.5517, lr: 0.000039, batch_cost: 0.2689, reader_cost: 0.00013, ips: 59.5026 samples/sec | ETA 29:46:21\r\n",
      "2022-11-16 20:08:18 [INFO]\t[TRAIN] epoch: 60, iter: 241450/640000, loss: 0.5365, lr: 0.000039, batch_cost: 0.2683, reader_cost: 0.00013, ips: 59.6283 samples/sec | ETA 29:42:22\r\n",
      "2022-11-16 20:08:31 [INFO]\t[TRAIN] epoch: 60, iter: 241500/640000, loss: 0.5291, lr: 0.000039, batch_cost: 0.2702, reader_cost: 0.00013, ips: 59.2256 samples/sec | ETA 29:54:16\r\n",
      "2022-11-16 20:08:45 [INFO]\t[TRAIN] epoch: 60, iter: 241550/640000, loss: 0.5272, lr: 0.000039, batch_cost: 0.2721, reader_cost: 0.00014, ips: 58.8079 samples/sec | ETA 30:06:47\r\n",
      "2022-11-16 20:08:58 [INFO]\t[TRAIN] epoch: 60, iter: 241600/640000, loss: 0.5203, lr: 0.000039, batch_cost: 0.2719, reader_cost: 0.00014, ips: 58.8468 samples/sec | ETA 30:05:21\r\n",
      "2022-11-16 20:09:12 [INFO]\t[TRAIN] epoch: 60, iter: 241650/640000, loss: 0.5428, lr: 0.000039, batch_cost: 0.2702, reader_cost: 0.00013, ips: 59.2063 samples/sec | ETA 29:54:10\r\n",
      "2022-11-16 20:09:25 [INFO]\t[TRAIN] epoch: 60, iter: 241700/640000, loss: 0.5719, lr: 0.000039, batch_cost: 0.2701, reader_cost: 0.00013, ips: 59.2306 samples/sec | ETA 29:53:13\r\n",
      "2022-11-16 20:09:39 [INFO]\t[TRAIN] epoch: 60, iter: 241750/640000, loss: 0.5104, lr: 0.000039, batch_cost: 0.2719, reader_cost: 0.00014, ips: 58.8470 samples/sec | ETA 30:04:40\r\n",
      "2022-11-16 20:09:52 [INFO]\t[TRAIN] epoch: 60, iter: 241800/640000, loss: 0.5253, lr: 0.000039, batch_cost: 0.2711, reader_cost: 0.00013, ips: 59.0152 samples/sec | ETA 29:59:18\r\n",
      "2022-11-16 20:10:06 [INFO]\t[TRAIN] epoch: 60, iter: 241850/640000, loss: 0.5419, lr: 0.000039, batch_cost: 0.2719, reader_cost: 0.00013, ips: 58.8402 samples/sec | ETA 30:04:26\r\n",
      "2022-11-16 20:10:20 [INFO]\t[TRAIN] epoch: 60, iter: 241900/640000, loss: 0.5544, lr: 0.000039, batch_cost: 0.2704, reader_cost: 0.00012, ips: 59.1793 samples/sec | ETA 29:53:52\r\n",
      "2022-11-16 20:10:33 [INFO]\t[TRAIN] epoch: 60, iter: 241950/640000, loss: 0.5276, lr: 0.000039, batch_cost: 0.2705, reader_cost: 0.00013, ips: 59.1606 samples/sec | ETA 29:54:12\r\n",
      "2022-11-16 20:10:47 [INFO]\t[TRAIN] epoch: 60, iter: 242000/640000, loss: 0.5183, lr: 0.000039, batch_cost: 0.2699, reader_cost: 0.00014, ips: 59.2740 samples/sec | ETA 29:50:33\r\n",
      "2022-11-16 20:10:47 [INFO]\tStart evaluating (total_samples: 3094, total_iters: 3094)...\r\n",
      "3094/3094 [==============================] - 156s 51ms/step - batch_cost: 0.0504 - reader cost: 8.5265e-05\r\n",
      "2022-11-16 20:13:23 [INFO]\t[EVAL] #Images: 3094 mIoU: 0.6279 Acc: 0.7875 Kappa: 0.7058 Dice: 0.7669\r\n",
      "2022-11-16 20:13:23 [INFO]\t[EVAL] Class IoU: \r\n",
      "[0.6138 0.7771 0.6217 0.499 ]\r\n",
      "2022-11-16 20:13:23 [INFO]\t[EVAL] Class Precision: \r\n",
      "[0.7632 0.865  0.7698 0.6754]\r\n",
      "2022-11-16 20:13:23 [INFO]\t[EVAL] Class Recall: \r\n",
      "[0.7581 0.8844 0.7637 0.6565]\r\n",
      "2022-11-16 20:13:24 [INFO]\t[EVAL] The model with the best validation mIoU (0.6279) was saved at iter 242000.\r\n",
      "2022-11-16 20:13:38 [INFO]\t[TRAIN] epoch: 60, iter: 242050/640000, loss: 0.4964, lr: 0.000039, batch_cost: 0.2704, reader_cost: 0.00014, ips: 59.1821 samples/sec | ETA 29:53:06\r\n",
      "2022-11-16 20:13:51 [INFO]\t[TRAIN] epoch: 60, iter: 242100/640000, loss: 0.5351, lr: 0.000039, batch_cost: 0.2705, reader_cost: 0.00013, ips: 59.1431 samples/sec | ETA 29:54:03\r\n",
      "2022-11-16 20:14:05 [INFO]\t[TRAIN] epoch: 60, iter: 242150/640000, loss: 0.5495, lr: 0.000039, batch_cost: 0.2684, reader_cost: 0.00013, ips: 59.6022 samples/sec | ETA 29:40:01\r\n",
      "2022-11-16 20:14:18 [INFO]\t[TRAIN] epoch: 60, iter: 242200/640000, loss: 0.5140, lr: 0.000039, batch_cost: 0.2704, reader_cost: 0.00013, ips: 59.1639 samples/sec | ETA 29:52:59\r\n",
      "2022-11-16 20:14:32 [INFO]\t[TRAIN] epoch: 60, iter: 242250/640000, loss: 0.6444, lr: 0.000039, batch_cost: 0.2704, reader_cost: 0.00013, ips: 59.1731 samples/sec | ETA 29:52:28\r\n",
      "2022-11-16 20:14:45 [INFO]\t[TRAIN] epoch: 60, iter: 242300/640000, loss: 0.5686, lr: 0.000039, batch_cost: 0.2688, reader_cost: 0.00013, ips: 59.5332 samples/sec | ETA 29:41:24\r\n",
      "2022-11-16 20:14:59 [INFO]\t[TRAIN] epoch: 60, iter: 242350/640000, loss: 0.5298, lr: 0.000039, batch_cost: 0.2710, reader_cost: 0.00013, ips: 59.0477 samples/sec | ETA 29:55:50\r\n",
      "2022-11-16 20:15:12 [INFO]\t[TRAIN] epoch: 60, iter: 242400/640000, loss: 0.5298, lr: 0.000039, batch_cost: 0.2697, reader_cost: 0.00014, ips: 59.3201 samples/sec | ETA 29:47:21\r\n",
      "2022-11-16 20:15:26 [INFO]\t[TRAIN] epoch: 60, iter: 242450/640000, loss: 0.5006, lr: 0.000039, batch_cost: 0.2698, reader_cost: 0.00013, ips: 59.2988 samples/sec | ETA 29:47:46\r\n",
      "2022-11-16 20:15:39 [INFO]\t[TRAIN] epoch: 60, iter: 242500/640000, loss: 0.5437, lr: 0.000039, batch_cost: 0.2705, reader_cost: 0.00014, ips: 59.1583 samples/sec | ETA 29:51:48\r\n",
      "2022-11-16 20:15:53 [INFO]\t[TRAIN] epoch: 60, iter: 242550/640000, loss: 0.5037, lr: 0.000039, batch_cost: 0.2704, reader_cost: 0.00013, ips: 59.1800 samples/sec | ETA 29:50:55\r\n",
      "2022-11-16 20:16:06 [INFO]\t[TRAIN] epoch: 60, iter: 242600/640000, loss: 0.5383, lr: 0.000039, batch_cost: 0.2694, reader_cost: 0.00013, ips: 59.3885 samples/sec | ETA 29:44:24\r\n",
      "2022-11-16 20:16:20 [INFO]\t[TRAIN] epoch: 60, iter: 242650/640000, loss: 0.5509, lr: 0.000039, batch_cost: 0.2698, reader_cost: 0.00013, ips: 59.3134 samples/sec | ETA 29:46:26\r\n",
      "2022-11-16 20:16:33 [INFO]\t[TRAIN] epoch: 60, iter: 242700/640000, loss: 0.5160, lr: 0.000039, batch_cost: 0.2713, reader_cost: 0.00013, ips: 58.9747 samples/sec | ETA 29:56:28\r\n",
      "2022-11-16 20:16:47 [INFO]\t[TRAIN] epoch: 60, iter: 242750/640000, loss: 0.4867, lr: 0.000039, batch_cost: 0.2695, reader_cost: 0.00013, ips: 59.3584 samples/sec | ETA 29:44:38\r\n",
      "2022-11-16 20:17:00 [INFO]\t[TRAIN] epoch: 60, iter: 242800/640000, loss: 0.5175, lr: 0.000039, batch_cost: 0.2718, reader_cost: 0.00014, ips: 58.8654 samples/sec | ETA 29:59:21\r\n",
      "2022-11-16 20:17:14 [INFO]\t[TRAIN] epoch: 60, iter: 242850/640000, loss: 0.5333, lr: 0.000039, batch_cost: 0.2706, reader_cost: 0.00014, ips: 59.1323 samples/sec | ETA 29:51:00\r\n",
      "2022-11-16 20:17:27 [INFO]\t[TRAIN] epoch: 60, iter: 242900/640000, loss: 0.5079, lr: 0.000039, batch_cost: 0.2716, reader_cost: 0.00013, ips: 58.9093 samples/sec | ETA 29:57:33\r\n",
      "2022-11-16 20:17:41 [INFO]\t[TRAIN] epoch: 60, iter: 242950/640000, loss: 0.5519, lr: 0.000039, batch_cost: 0.2723, reader_cost: 0.00013, ips: 58.7504 samples/sec | ETA 30:02:12\r\n",
      "2022-11-16 20:17:55 [INFO]\t[TRAIN] epoch: 60, iter: 243000/640000, loss: 0.5204, lr: 0.000039, batch_cost: 0.2728, reader_cost: 0.00014, ips: 58.6454 samples/sec | ETA 30:05:11\r\n",
      "2022-11-16 20:18:08 [INFO]\t[TRAIN] epoch: 60, iter: 243050/640000, loss: 0.4981, lr: 0.000039, batch_cost: 0.2703, reader_cost: 0.00013, ips: 59.1980 samples/sec | ETA 29:48:07\r\n",
      "2022-11-16 20:18:22 [INFO]\t[TRAIN] epoch: 60, iter: 243100/640000, loss: 0.5605, lr: 0.000039, batch_cost: 0.2708, reader_cost: 0.00013, ips: 59.0847 samples/sec | ETA 29:51:19\r\n",
      "2022-11-16 20:18:35 [INFO]\t[TRAIN] epoch: 60, iter: 243150/640000, loss: 0.5424, lr: 0.000039, batch_cost: 0.2713, reader_cost: 0.00013, ips: 58.9747 samples/sec | ETA 29:54:26\r\n",
      "2022-11-16 20:18:49 [INFO]\t[TRAIN] epoch: 60, iter: 243200/640000, loss: 0.5126, lr: 0.000039, batch_cost: 0.2727, reader_cost: 0.00014, ips: 58.6625 samples/sec | ETA 30:03:45\r\n",
      "2022-11-16 20:19:03 [INFO]\t[TRAIN] epoch: 61, iter: 243250/640000, loss: 0.5713, lr: 0.000039, batch_cost: 0.2727, reader_cost: 0.00377, ips: 58.6759 samples/sec | ETA 30:03:07\r\n",
      "2022-11-16 20:19:16 [INFO]\t[TRAIN] epoch: 61, iter: 243300/640000, loss: 0.5379, lr: 0.000039, batch_cost: 0.2705, reader_cost: 0.00013, ips: 59.1553 samples/sec | ETA 29:48:17\r\n",
      "2022-11-16 20:19:30 [INFO]\t[TRAIN] epoch: 61, iter: 243350/640000, loss: 0.5628, lr: 0.000039, batch_cost: 0.2688, reader_cost: 0.00012, ips: 59.5193 samples/sec | ETA 29:37:07\r\n",
      "2022-11-16 20:19:43 [INFO]\t[TRAIN] epoch: 61, iter: 243400/640000, loss: 0.5650, lr: 0.000039, batch_cost: 0.2727, reader_cost: 0.00014, ips: 58.6778 samples/sec | ETA 30:02:23\r\n",
      "2022-11-16 20:19:57 [INFO]\t[TRAIN] epoch: 61, iter: 243450/640000, loss: 0.5231, lr: 0.000039, batch_cost: 0.2719, reader_cost: 0.00013, ips: 58.8344 samples/sec | ETA 29:57:21\r\n",
      "2022-11-16 20:20:10 [INFO]\t[TRAIN] epoch: 61, iter: 243500/640000, loss: 0.5447, lr: 0.000039, batch_cost: 0.2706, reader_cost: 0.00013, ips: 59.1304 samples/sec | ETA 29:48:08\r\n",
      "2022-11-16 20:20:24 [INFO]\t[TRAIN] epoch: 61, iter: 243550/640000, loss: 0.5411, lr: 0.000039, batch_cost: 0.2732, reader_cost: 0.00013, ips: 58.5710 samples/sec | ETA 30:04:59\r\n",
      "2022-11-16 20:20:38 [INFO]\t[TRAIN] epoch: 61, iter: 243600/640000, loss: 0.5155, lr: 0.000039, batch_cost: 0.2733, reader_cost: 0.00013, ips: 58.5466 samples/sec | ETA 30:05:30\r\n",
      "2022-11-16 20:20:51 [INFO]\t[TRAIN] epoch: 61, iter: 243650/640000, loss: 0.4934, lr: 0.000039, batch_cost: 0.2747, reader_cost: 0.00015, ips: 58.2439 samples/sec | ETA 30:14:40\r\n",
      "2022-11-16 20:21:05 [INFO]\t[TRAIN] epoch: 61, iter: 243700/640000, loss: 0.5415, lr: 0.000039, batch_cost: 0.2701, reader_cost: 0.00013, ips: 59.2322 samples/sec | ETA 29:44:09\r\n",
      "2022-11-16 20:21:18 [INFO]\t[TRAIN] epoch: 61, iter: 243750/640000, loss: 0.5133, lr: 0.000039, batch_cost: 0.2700, reader_cost: 0.00013, ips: 59.2696 samples/sec | ETA 29:42:48\r\n",
      "2022-11-16 20:21:32 [INFO]\t[TRAIN] epoch: 61, iter: 243800/640000, loss: 0.5539, lr: 0.000039, batch_cost: 0.2737, reader_cost: 0.00014, ips: 58.4559 samples/sec | ETA 30:07:24\r\n",
      "2022-11-16 20:21:46 [INFO]\t[TRAIN] epoch: 61, iter: 243850/640000, loss: 0.5272, lr: 0.000039, batch_cost: 0.2707, reader_cost: 0.00013, ips: 59.1032 samples/sec | ETA 29:47:22\r\n",
      "2022-11-16 20:21:59 [INFO]\t[TRAIN] epoch: 61, iter: 243900/640000, loss: 0.5254, lr: 0.000039, batch_cost: 0.2716, reader_cost: 0.00012, ips: 58.9084 samples/sec | ETA 29:53:03\r\n",
      "2022-11-16 20:22:13 [INFO]\t[TRAIN] epoch: 61, iter: 243950/640000, loss: 0.5370, lr: 0.000039, batch_cost: 0.2709, reader_cost: 0.00012, ips: 59.0728 samples/sec | ETA 29:47:51\r\n",
      "2022-11-16 20:22:26 [INFO]\t[TRAIN] epoch: 61, iter: 244000/640000, loss: 0.4960, lr: 0.000039, batch_cost: 0.2714, reader_cost: 0.00012, ips: 58.9611 samples/sec | ETA 29:51:00\r\n",
      "2022-11-16 20:22:26 [INFO]\tStart evaluating (total_samples: 3094, total_iters: 3094)...\r\n",
      "3094/3094 [==============================] - 152s 49ms/step - batch_cost: 0.0489 - reader cost: 8.3319e-05\r\n",
      "2022-11-16 20:24:58 [INFO]\t[EVAL] #Images: 3094 mIoU: 0.6275 Acc: 0.7864 Kappa: 0.7048 Dice: 0.7668\r\n",
      "2022-11-16 20:24:58 [INFO]\t[EVAL] Class IoU: \r\n",
      "[0.6098 0.7742 0.6234 0.5027]\r\n",
      "2022-11-16 20:24:58 [INFO]\t[EVAL] Class Precision: \r\n",
      "[0.773  0.8652 0.7601 0.6679]\r\n",
      "2022-11-16 20:24:58 [INFO]\t[EVAL] Class Recall: \r\n",
      "[0.7428 0.8803 0.7761 0.6703]\r\n",
      "2022-11-16 20:24:59 [INFO]\t[EVAL] The model with the best validation mIoU (0.6279) was saved at iter 242000.\r\n",
      "2022-11-16 20:25:12 [INFO]\t[TRAIN] epoch: 61, iter: 244050/640000, loss: 0.5393, lr: 0.000039, batch_cost: 0.2721, reader_cost: 0.00013, ips: 58.8054 samples/sec | ETA 29:55:31\r\n",
      "2022-11-16 20:25:26 [INFO]\t[TRAIN] epoch: 61, iter: 244100/640000, loss: 0.5673, lr: 0.000039, batch_cost: 0.2758, reader_cost: 0.00014, ips: 58.0181 samples/sec | ETA 30:19:39\r\n",
      "2022-11-16 20:25:40 [INFO]\t[TRAIN] epoch: 61, iter: 244150/640000, loss: 0.6105, lr: 0.000039, batch_cost: 0.2746, reader_cost: 0.00015, ips: 58.2584 samples/sec | ETA 30:11:55\r\n",
      "2022-11-16 20:25:53 [INFO]\t[TRAIN] epoch: 61, iter: 244200/640000, loss: 0.5921, lr: 0.000039, batch_cost: 0.2747, reader_cost: 0.00014, ips: 58.2452 samples/sec | ETA 30:12:06\r\n",
      "2022-11-16 20:26:07 [INFO]\t[TRAIN] epoch: 61, iter: 244250/640000, loss: 0.4875, lr: 0.000039, batch_cost: 0.2732, reader_cost: 0.00014, ips: 58.5552 samples/sec | ETA 30:02:17\r\n",
      "2022-11-16 20:26:21 [INFO]\t[TRAIN] epoch: 61, iter: 244300/640000, loss: 0.5182, lr: 0.000039, batch_cost: 0.2716, reader_cost: 0.00013, ips: 58.9098 samples/sec | ETA 29:51:12\r\n",
      "2022-11-16 20:26:34 [INFO]\t[TRAIN] epoch: 61, iter: 244350/640000, loss: 0.5415, lr: 0.000039, batch_cost: 0.2707, reader_cost: 0.00013, ips: 59.1068 samples/sec | ETA 29:45:00\r\n",
      "2022-11-16 20:26:48 [INFO]\t[TRAIN] epoch: 61, iter: 244400/640000, loss: 0.5483, lr: 0.000039, batch_cost: 0.2709, reader_cost: 0.00013, ips: 59.0669 samples/sec | ETA 29:45:59\r\n",
      "2022-11-16 20:27:01 [INFO]\t[TRAIN] epoch: 61, iter: 244450/640000, loss: 0.5181, lr: 0.000039, batch_cost: 0.2722, reader_cost: 0.00013, ips: 58.7714 samples/sec | ETA 29:54:45\r\n",
      "2022-11-16 20:27:15 [INFO]\t[TRAIN] epoch: 61, iter: 244500/640000, loss: 0.5604, lr: 0.000039, batch_cost: 0.2721, reader_cost: 0.00013, ips: 58.7922 samples/sec | ETA 29:53:53\r\n",
      "2022-11-16 20:27:29 [INFO]\t[TRAIN] epoch: 61, iter: 244550/640000, loss: 0.5542, lr: 0.000039, batch_cost: 0.2712, reader_cost: 0.00013, ips: 58.9914 samples/sec | ETA 29:47:36\r\n",
      "2022-11-16 20:27:42 [INFO]\t[TRAIN] epoch: 61, iter: 244600/640000, loss: 0.5312, lr: 0.000039, batch_cost: 0.2710, reader_cost: 0.00013, ips: 59.0462 samples/sec | ETA 29:45:43\r\n",
      "2022-11-16 20:27:56 [INFO]\t[TRAIN] epoch: 61, iter: 244650/640000, loss: 0.4948, lr: 0.000039, batch_cost: 0.2703, reader_cost: 0.00013, ips: 59.1956 samples/sec | ETA 29:40:59\r\n",
      "2022-11-16 20:28:09 [INFO]\t[TRAIN] epoch: 61, iter: 244700/640000, loss: 0.5325, lr: 0.000039, batch_cost: 0.2706, reader_cost: 0.00013, ips: 59.1196 samples/sec | ETA 29:43:03\r\n",
      "2022-11-16 20:28:23 [INFO]\t[TRAIN] epoch: 61, iter: 244750/640000, loss: 0.5188, lr: 0.000039, batch_cost: 0.2709, reader_cost: 0.00013, ips: 59.0546 samples/sec | ETA 29:44:47\r\n",
      "2022-11-16 20:28:36 [INFO]\t[TRAIN] epoch: 61, iter: 244800/640000, loss: 0.5141, lr: 0.000039, batch_cost: 0.2704, reader_cost: 0.00013, ips: 59.1741 samples/sec | ETA 29:40:57\r\n",
      "2022-11-16 20:28:50 [INFO]\t[TRAIN] epoch: 61, iter: 244850/640000, loss: 0.5604, lr: 0.000039, batch_cost: 0.2722, reader_cost: 0.00013, ips: 58.7755 samples/sec | ETA 29:52:48\r\n",
      "2022-11-16 20:29:03 [INFO]\t[TRAIN] epoch: 61, iter: 244900/640000, loss: 0.5095, lr: 0.000039, batch_cost: 0.2713, reader_cost: 0.00013, ips: 58.9753 samples/sec | ETA 29:46:30\r\n",
      "2022-11-16 20:29:17 [INFO]\t[TRAIN] epoch: 61, iter: 244950/640000, loss: 0.4969, lr: 0.000039, batch_cost: 0.2726, reader_cost: 0.00013, ips: 58.6849 samples/sec | ETA 29:55:07\r\n",
      "2022-11-16 20:29:31 [INFO]\t[TRAIN] epoch: 61, iter: 245000/640000, loss: 0.5215, lr: 0.000039, batch_cost: 0.2704, reader_cost: 0.00013, ips: 59.1808 samples/sec | ETA 29:39:51\r\n",
      "2022-11-16 20:29:44 [INFO]\t[TRAIN] epoch: 61, iter: 245050/640000, loss: 0.5564, lr: 0.000039, batch_cost: 0.2717, reader_cost: 0.00013, ips: 58.8860 samples/sec | ETA 29:48:32\r\n",
      "2022-11-16 20:29:58 [INFO]\t[TRAIN] epoch: 61, iter: 245100/640000, loss: 0.5781, lr: 0.000039, batch_cost: 0.2742, reader_cost: 0.00014, ips: 58.3414 samples/sec | ETA 30:05:00\r\n",
      "2022-11-16 20:30:11 [INFO]\t[TRAIN] epoch: 61, iter: 245150/640000, loss: 0.5304, lr: 0.000039, batch_cost: 0.2701, reader_cost: 0.00013, ips: 59.2365 samples/sec | ETA 29:37:30\r\n",
      "2022-11-16 20:30:25 [INFO]\t[TRAIN] epoch: 61, iter: 245200/640000, loss: 0.5562, lr: 0.000039, batch_cost: 0.2725, reader_cost: 0.00013, ips: 58.7161 samples/sec | ETA 29:53:02\r\n",
      "2022-11-16 20:30:39 [INFO]\t[TRAIN] epoch: 61, iter: 245250/640000, loss: 0.5481, lr: 0.000039, batch_cost: 0.2716, reader_cost: 0.00013, ips: 58.9107 samples/sec | ETA 29:46:53\r\n",
      "2022-11-16 20:30:52 [INFO]\t[TRAIN] epoch: 61, iter: 245300/640000, loss: 0.5278, lr: 0.000039, batch_cost: 0.2758, reader_cost: 0.00013, ips: 58.0135 samples/sec | ETA 30:14:17\r\n",
      "2022-11-16 20:31:06 [INFO]\t[TRAIN] epoch: 61, iter: 245350/640000, loss: 0.4902, lr: 0.000039, batch_cost: 0.2732, reader_cost: 0.00014, ips: 58.5624 samples/sec | ETA 29:57:03\r\n",
      "2022-11-16 20:31:20 [INFO]\t[TRAIN] epoch: 61, iter: 245400/640000, loss: 0.5483, lr: 0.000039, batch_cost: 0.2707, reader_cost: 0.00013, ips: 59.1163 samples/sec | ETA 29:39:59\r\n",
      "2022-11-16 20:31:33 [INFO]\t[TRAIN] epoch: 61, iter: 245450/640000, loss: 0.5485, lr: 0.000039, batch_cost: 0.2718, reader_cost: 0.00013, ips: 58.8604 samples/sec | ETA 29:47:30\r\n",
      "2022-11-16 20:31:47 [INFO]\t[TRAIN] epoch: 61, iter: 245500/640000, loss: 0.5208, lr: 0.000039, batch_cost: 0.2718, reader_cost: 0.00013, ips: 58.8718 samples/sec | ETA 29:46:56\r\n",
      "2022-11-16 20:32:00 [INFO]\t[TRAIN] epoch: 61, iter: 245550/640000, loss: 0.5225, lr: 0.000039, batch_cost: 0.2696, reader_cost: 0.00013, ips: 59.3370 samples/sec | ETA 29:32:41\r\n",
      "2022-11-16 20:32:14 [INFO]\t[TRAIN] epoch: 61, iter: 245600/640000, loss: 0.4966, lr: 0.000039, batch_cost: 0.2705, reader_cost: 0.00014, ips: 59.1558 samples/sec | ETA 29:37:54\r\n",
      "2022-11-16 20:32:27 [INFO]\t[TRAIN] epoch: 61, iter: 245650/640000, loss: 0.5200, lr: 0.000039, batch_cost: 0.2720, reader_cost: 0.00013, ips: 58.8243 samples/sec | ETA 29:47:41\r\n",
      "2022-11-16 20:32:41 [INFO]\t[TRAIN] epoch: 61, iter: 245700/640000, loss: 0.5213, lr: 0.000039, batch_cost: 0.2699, reader_cost: 0.00013, ips: 59.2756 samples/sec | ETA 29:33:51\r\n",
      "2022-11-16 20:32:54 [INFO]\t[TRAIN] epoch: 61, iter: 245750/640000, loss: 0.5189, lr: 0.000039, batch_cost: 0.2721, reader_cost: 0.00013, ips: 58.8112 samples/sec | ETA 29:47:38\r\n",
      "2022-11-16 20:33:08 [INFO]\t[TRAIN] epoch: 61, iter: 245800/640000, loss: 0.5108, lr: 0.000039, batch_cost: 0.2725, reader_cost: 0.00014, ips: 58.7233 samples/sec | ETA 29:50:05\r\n",
      "2022-11-16 20:33:22 [INFO]\t[TRAIN] epoch: 61, iter: 245850/640000, loss: 0.5258, lr: 0.000039, batch_cost: 0.2733, reader_cost: 0.00014, ips: 58.5422 samples/sec | ETA 29:55:23\r\n",
      "2022-11-16 20:33:35 [INFO]\t[TRAIN] epoch: 61, iter: 245900/640000, loss: 0.4929, lr: 0.000039, batch_cost: 0.2732, reader_cost: 0.00014, ips: 58.5679 samples/sec | ETA 29:54:23\r\n",
      "2022-11-16 20:33:49 [INFO]\t[TRAIN] epoch: 61, iter: 245950/640000, loss: 0.4888, lr: 0.000039, batch_cost: 0.2723, reader_cost: 0.00015, ips: 58.7606 samples/sec | ETA 29:48:16\r\n",
      "2022-11-16 20:34:03 [INFO]\t[TRAIN] epoch: 61, iter: 246000/640000, loss: 0.4876, lr: 0.000039, batch_cost: 0.2725, reader_cost: 0.00013, ips: 58.7202 samples/sec | ETA 29:49:16\r\n",
      "2022-11-16 20:34:03 [INFO]\tStart evaluating (total_samples: 3094, total_iters: 3094)...\r\n",
      " 486/3094 [===>..........................] - ETA: 2:07 - batch_cost: 0.0487 - reader cost: 1.0027e-042022-11-16 21:30:03 [INFO]\t[TRAIN] epoch: 64, iter: 255450/640000, loss: 0.5367, lr: 0.000038, batch_cost: 0.2752, reader_cost: 0.00383, ips: 58.1370 samples/sec | ETA 29:23:52\r\n",
      "2022-11-16 21:30:17 [INFO]\t[TRAIN] epoch: 64, iter: 255500/640000, loss: 0.5202, lr: 0.000038, batch_cost: 0.2734, reader_cost: 0.00014, ips: 58.5165 samples/sec | ETA 29:12:12\r\n",
      "2022-11-16 21:30:31 [INFO]\t[TRAIN] epoch: 64, iter: 255550/640000, loss: 0.5004, lr: 0.000038, batch_cost: 0.2752, reader_cost: 0.00014, ips: 58.1373 samples/sec | ETA 29:23:24\r\n",
      "2022-11-16 21:30:44 [INFO]\t[TRAIN] epoch: 64, iter: 255600/640000, loss: 0.5223, lr: 0.000038, batch_cost: 0.2742, reader_cost: 0.00014, ips: 58.3455 samples/sec | ETA 29:16:53\r\n",
      "2022-11-16 21:30:58 [INFO]\t[TRAIN] epoch: 64, iter: 255650/640000, loss: 0.4878, lr: 0.000038, batch_cost: 0.2731, reader_cost: 0.00014, ips: 58.5866 samples/sec | ETA 29:09:26\r\n",
      "2022-11-16 21:31:12 [INFO]\t[TRAIN] epoch: 64, iter: 255700/640000, loss: 0.5235, lr: 0.000038, batch_cost: 0.2708, reader_cost: 0.00014, ips: 59.0795 samples/sec | ETA 28:54:36\r\n",
      "2022-11-16 21:31:25 [INFO]\t[TRAIN] epoch: 64, iter: 255750/640000, loss: 0.5647, lr: 0.000038, batch_cost: 0.2698, reader_cost: 0.00013, ips: 59.3129 samples/sec | ETA 28:47:33\r\n",
      "2022-11-16 21:31:39 [INFO]\t[TRAIN] epoch: 64, iter: 255800/640000, loss: 0.5199, lr: 0.000038, batch_cost: 0.2710, reader_cost: 0.00013, ips: 59.0400 samples/sec | ETA 28:55:19\r\n",
      "2022-11-16 21:31:52 [INFO]\t[TRAIN] epoch: 64, iter: 255850/640000, loss: 0.5284, lr: 0.000038, batch_cost: 0.2713, reader_cost: 0.00013, ips: 58.9768 samples/sec | ETA 28:56:57\r\n",
      "2022-11-16 21:32:06 [INFO]\t[TRAIN] epoch: 64, iter: 255900/640000, loss: 0.4887, lr: 0.000038, batch_cost: 0.2723, reader_cost: 0.00014, ips: 58.7612 samples/sec | ETA 29:03:05\r\n",
      "2022-11-16 21:32:20 [INFO]\t[TRAIN] epoch: 64, iter: 255950/640000, loss: 0.5615, lr: 0.000038, batch_cost: 0.2785, reader_cost: 0.00014, ips: 57.4484 samples/sec | ETA 29:42:42\r\n",
      "2022-11-16 21:32:34 [INFO]\t[TRAIN] epoch: 64, iter: 256000/640000, loss: 0.5655, lr: 0.000038, batch_cost: 0.2754, reader_cost: 0.00015, ips: 58.0922 samples/sec | ETA 29:22:42\r\n",
      "2022-11-16 21:32:34 [INFO]\tStart evaluating (total_samples: 3094, total_iters: 3094)...\r\n",
      "3094/3094 [==============================] - 155s 50ms/step - batch_cost: 0.0499 - reader cost: 9.2576e-05\r\n",
      "2022-11-16 21:35:08 [INFO]\t[EVAL] #Images: 3094 mIoU: 0.6253 Acc: 0.7862 Kappa: 0.7036 Dice: 0.7647\r\n",
      "2022-11-16 21:35:08 [INFO]\t[EVAL] Class IoU: \r\n",
      "[0.6114 0.7755 0.623  0.4912]\r\n",
      "2022-11-16 21:35:08 [INFO]\t[EVAL] Class Precision: \r\n",
      "[0.7691 0.8551 0.7667 0.677 ]\r\n",
      "2022-11-16 21:35:08 [INFO]\t[EVAL] Class Recall: \r\n",
      "[0.7488 0.8928 0.7687 0.6416]\r\n",
      "2022-11-16 21:35:09 [INFO]\t[EVAL] The model with the best validation mIoU (0.6279) was saved at iter 246000.\r\n",
      "2022-11-16 21:35:23 [INFO]\t[TRAIN] epoch: 64, iter: 256050/640000, loss: 0.5044, lr: 0.000038, batch_cost: 0.2740, reader_cost: 0.00013, ips: 58.3893 samples/sec | ETA 29:13:31\r\n",
      "2022-11-16 21:35:36 [INFO]\t[TRAIN] epoch: 64, iter: 256100/640000, loss: 0.4899, lr: 0.000038, batch_cost: 0.2724, reader_cost: 0.00014, ips: 58.7442 samples/sec | ETA 29:02:41\r\n",
      "2022-11-16 21:35:50 [INFO]\t[TRAIN] epoch: 64, iter: 256150/640000, loss: 0.5271, lr: 0.000038, batch_cost: 0.2725, reader_cost: 0.00014, ips: 58.7135 samples/sec | ETA 29:03:22\r\n",
      "2022-11-16 21:36:04 [INFO]\t[TRAIN] epoch: 64, iter: 256200/640000, loss: 0.5424, lr: 0.000038, batch_cost: 0.2720, reader_cost: 0.00014, ips: 58.8234 samples/sec | ETA 28:59:53\r\n",
      "2022-11-16 21:36:17 [INFO]\t[TRAIN] epoch: 64, iter: 256250/640000, loss: 0.5376, lr: 0.000038, batch_cost: 0.2738, reader_cost: 0.00015, ips: 58.4439 samples/sec | ETA 29:10:58\r\n",
      "2022-11-16 21:36:31 [INFO]\t[TRAIN] epoch: 64, iter: 256300/640000, loss: 0.4923, lr: 0.000038, batch_cost: 0.2739, reader_cost: 0.00014, ips: 58.4110 samples/sec | ETA 29:11:43\r\n",
      "2022-11-16 21:36:45 [INFO]\t[TRAIN] epoch: 64, iter: 256350/640000, loss: 0.5481, lr: 0.000038, batch_cost: 0.2750, reader_cost: 0.00015, ips: 58.1789 samples/sec | ETA 29:18:28\r\n",
      "2022-11-16 21:36:58 [INFO]\t[TRAIN] epoch: 64, iter: 256400/640000, loss: 0.5180, lr: 0.000038, batch_cost: 0.2735, reader_cost: 0.00015, ips: 58.5051 samples/sec | ETA 29:08:27\r\n",
      "2022-11-16 21:37:12 [INFO]\t[TRAIN] epoch: 64, iter: 256450/640000, loss: 0.5484, lr: 0.000038, batch_cost: 0.2735, reader_cost: 0.00015, ips: 58.5033 samples/sec | ETA 29:08:16\r\n",
      "2022-11-16 21:37:26 [INFO]\t[TRAIN] epoch: 64, iter: 256500/640000, loss: 0.5041, lr: 0.000038, batch_cost: 0.2734, reader_cost: 0.00015, ips: 58.5285 samples/sec | ETA 29:07:17\r\n",
      "2022-11-16 21:37:39 [INFO]\t[TRAIN] epoch: 64, iter: 256550/640000, loss: 0.5270, lr: 0.000038, batch_cost: 0.2747, reader_cost: 0.00015, ips: 58.2408 samples/sec | ETA 29:15:41\r\n",
      "2022-11-16 21:37:53 [INFO]\t[TRAIN] epoch: 64, iter: 256600/640000, loss: 0.5363, lr: 0.000038, batch_cost: 0.2726, reader_cost: 0.00014, ips: 58.6872 samples/sec | ETA 29:02:07\r\n",
      "2022-11-16 21:38:07 [INFO]\t[TRAIN] epoch: 64, iter: 256650/640000, loss: 0.5558, lr: 0.000038, batch_cost: 0.2707, reader_cost: 0.00014, ips: 59.1127 samples/sec | ETA 28:49:21\r\n",
      "2022-11-16 21:38:20 [INFO]\t[TRAIN] epoch: 64, iter: 256700/640000, loss: 0.5291, lr: 0.000038, batch_cost: 0.2734, reader_cost: 0.00014, ips: 58.5130 samples/sec | ETA 29:06:50\r\n",
      "2022-11-16 21:38:34 [INFO]\t[TRAIN] epoch: 64, iter: 256750/640000, loss: 0.5399, lr: 0.000038, batch_cost: 0.2736, reader_cost: 0.00013, ips: 58.4843 samples/sec | ETA 29:07:28\r\n",
      "2022-11-16 21:38:48 [INFO]\t[TRAIN] epoch: 64, iter: 256800/640000, loss: 0.5310, lr: 0.000038, batch_cost: 0.2714, reader_cost: 0.00013, ips: 58.9639 samples/sec | ETA 28:53:02\r\n",
      "2022-11-16 21:39:01 [INFO]\t[TRAIN] epoch: 64, iter: 256850/640000, loss: 0.5082, lr: 0.000038, batch_cost: 0.2716, reader_cost: 0.00014, ips: 58.9051 samples/sec | ETA 28:54:32\r\n",
      "2022-11-16 21:39:15 [INFO]\t[TRAIN] epoch: 64, iter: 256900/640000, loss: 0.5009, lr: 0.000038, batch_cost: 0.2716, reader_cost: 0.00014, ips: 58.9126 samples/sec | ETA 28:54:05\r\n",
      "2022-11-16 21:39:28 [INFO]\t[TRAIN] epoch: 64, iter: 256950/640000, loss: 0.4999, lr: 0.000038, batch_cost: 0.2755, reader_cost: 0.00013, ips: 58.0811 samples/sec | ETA 29:18:41\r\n",
      "2022-11-16 21:39:42 [INFO]\t[TRAIN] epoch: 64, iter: 257000/640000, loss: 0.5094, lr: 0.000038, batch_cost: 0.2714, reader_cost: 0.00014, ips: 58.9627 samples/sec | ETA 28:52:10\r\n",
      "2022-11-16 21:39:56 [INFO]\t[TRAIN] epoch: 64, iter: 257050/640000, loss: 0.5339, lr: 0.000038, batch_cost: 0.2739, reader_cost: 0.00015, ips: 58.4205 samples/sec | ETA 29:08:01\r\n",
      "2022-11-16 21:40:09 [INFO]\t[TRAIN] epoch: 64, iter: 257100/640000, loss: 0.5358, lr: 0.000038, batch_cost: 0.2748, reader_cost: 0.00015, ips: 58.2235 samples/sec | ETA 29:13:42\r\n",
      "2022-11-16 21:40:23 [INFO]\t[TRAIN] epoch: 64, iter: 257150/640000, loss: 0.5206, lr: 0.000038, batch_cost: 0.2722, reader_cost: 0.00014, ips: 58.7896 samples/sec | ETA 28:56:35\r\n",
      "2022-11-16 21:40:37 [INFO]\t[TRAIN] epoch: 64, iter: 257200/640000, loss: 0.5138, lr: 0.000038, batch_cost: 0.2738, reader_cost: 0.00014, ips: 58.4417 samples/sec | ETA 29:06:41\r\n",
      "2022-11-16 21:40:50 [INFO]\t[TRAIN] epoch: 64, iter: 257250/640000, loss: 0.5484, lr: 0.000038, batch_cost: 0.2747, reader_cost: 0.00014, ips: 58.2527 samples/sec | ETA 29:12:08\r\n",
      "2022-11-16 21:41:04 [INFO]\t[TRAIN] epoch: 64, iter: 257300/640000, loss: 0.5106, lr: 0.000038, batch_cost: 0.2733, reader_cost: 0.00014, ips: 58.5529 samples/sec | ETA 29:02:55\r\n",
      "2022-11-16 21:41:18 [INFO]\t[TRAIN] epoch: 64, iter: 257350/640000, loss: 0.5075, lr: 0.000038, batch_cost: 0.2753, reader_cost: 0.00014, ips: 58.1255 samples/sec | ETA 29:15:30\r\n",
      "2022-11-16 21:41:32 [INFO]\t[TRAIN] epoch: 64, iter: 257400/640000, loss: 0.4981, lr: 0.000038, batch_cost: 0.2723, reader_cost: 0.00014, ips: 58.7677 samples/sec | ETA 28:56:06\r\n",
      "2022-11-16 21:41:45 [INFO]\t[TRAIN] epoch: 64, iter: 257450/640000, loss: 0.5446, lr: 0.000038, batch_cost: 0.2720, reader_cost: 0.00014, ips: 58.8227 samples/sec | ETA 28:54:15\r\n",
      "2022-11-16 21:41:59 [INFO]\t[TRAIN] epoch: 64, iter: 257500/640000, loss: 0.4936, lr: 0.000038, batch_cost: 0.2777, reader_cost: 0.00015, ips: 57.6122 samples/sec | ETA 29:30:27\r\n",
      "2022-11-16 21:42:13 [INFO]\t[TRAIN] epoch: 64, iter: 257550/640000, loss: 0.5703, lr: 0.000038, batch_cost: 0.2727, reader_cost: 0.00014, ips: 58.6830 samples/sec | ETA 28:57:55\r\n",
      "2022-11-16 21:42:26 [INFO]\t[TRAIN] epoch: 64, iter: 257600/640000, loss: 0.5343, lr: 0.000038, batch_cost: 0.2712, reader_cost: 0.00014, ips: 59.0034 samples/sec | ETA 28:48:15\r\n",
      "2022-11-16 21:42:40 [INFO]\t[TRAIN] epoch: 64, iter: 257650/640000, loss: 0.5654, lr: 0.000038, batch_cost: 0.2716, reader_cost: 0.00013, ips: 58.9188 samples/sec | ETA 28:50:31\r\n",
      "2022-11-16 21:42:53 [INFO]\t[TRAIN] epoch: 64, iter: 257700/640000, loss: 0.5370, lr: 0.000038, batch_cost: 0.2724, reader_cost: 0.00014, ips: 58.7449 samples/sec | ETA 28:55:24\r\n",
      "2022-11-16 21:43:07 [INFO]\t[TRAIN] epoch: 64, iter: 257750/640000, loss: 0.5284, lr: 0.000038, batch_cost: 0.2745, reader_cost: 0.00013, ips: 58.2903 samples/sec | ETA 29:08:43\r\n",
      "2022-11-16 21:43:21 [INFO]\t[TRAIN] epoch: 64, iter: 257800/640000, loss: 0.5282, lr: 0.000038, batch_cost: 0.2694, reader_cost: 0.00013, ips: 59.3983 samples/sec | ETA 28:35:52\r\n",
      "2022-11-16 21:43:34 [INFO]\t[TRAIN] epoch: 64, iter: 257850/640000, loss: 0.4690, lr: 0.000038, batch_cost: 0.2724, reader_cost: 0.00013, ips: 58.7430 samples/sec | ETA 28:54:47\r\n",
      "2022-11-16 21:43:48 [INFO]\t[TRAIN] epoch: 64, iter: 257900/640000, loss: 0.5318, lr: 0.000038, batch_cost: 0.2728, reader_cost: 0.00014, ips: 58.6538 samples/sec | ETA 28:57:11\r\n",
      "2022-11-16 21:44:02 [INFO]\t[TRAIN] epoch: 64, iter: 257950/640000, loss: 0.4911, lr: 0.000038, batch_cost: 0.2737, reader_cost: 0.00014, ips: 58.4545 samples/sec | ETA 29:02:53\r\n",
      "2022-11-16 21:44:15 [INFO]\t[TRAIN] epoch: 64, iter: 258000/640000, loss: 0.5425, lr: 0.000038, batch_cost: 0.2718, reader_cost: 0.00014, ips: 58.8589 samples/sec | ETA 28:50:41\r\n",
      "2022-11-16 21:44:15 [INFO]\tStart evaluating (total_samples: 3094, total_iters: 3094)...\r\n",
      " 713/3094 [=====>........................] - ETA: 2:03 - batch_cost: 0.0516 - reader cost: 1.0625e-042022-11-16 21:47:17 [INFO]\t[TRAIN] epoch: 64, iter: 258100/640000, loss: 0.5189, lr: 0.000038, batch_cost: 0.2699, reader_cost: 0.00013, ips: 59.2895 samples/sec | ETA 28:37:40\r\n",
      "2022-11-16 21:47:31 [INFO]\t[TRAIN] epoch: 64, iter: 258150/640000, loss: 0.5243, lr: 0.000038, batch_cost: 0.2715, reader_cost: 0.00013, ips: 58.9364 samples/sec | ETA 28:47:44\r\n",
      "2022-11-16 21:47:44 [INFO]\t[TRAIN] epoch: 64, iter: 258200/640000, loss: 0.4797, lr: 0.000038, batch_cost: 0.2713, reader_cost: 0.00014, ips: 58.9732 samples/sec | ETA 28:46:26\r\n",
      "2022-11-16 21:47:58 [INFO]\t[TRAIN] epoch: 64, iter: 258250/640000, loss: 0.5594, lr: 0.000038, batch_cost: 0.2719, reader_cost: 0.00013, ips: 58.8402 samples/sec | ETA 28:50:06\r\n",
      "2022-11-16 21:48:12 [INFO]\t[TRAIN] epoch: 64, iter: 258300/640000, loss: 0.5050, lr: 0.000038, batch_cost: 0.2721, reader_cost: 0.00014, ips: 58.7947 samples/sec | ETA 28:51:13\r\n",
      "2022-11-16 21:48:25 [INFO]\t[TRAIN] epoch: 64, iter: 258350/640000, loss: 0.5091, lr: 0.000038, batch_cost: 0.2728, reader_cost: 0.00014, ips: 58.6495 samples/sec | ETA 28:55:16\r\n",
      "2022-11-16 21:48:39 [INFO]\t[TRAIN] epoch: 64, iter: 258400/640000, loss: 0.5116, lr: 0.000038, batch_cost: 0.2758, reader_cost: 0.00015, ips: 58.0192 samples/sec | ETA 29:13:54\r\n",
      "2022-11-16 21:48:53 [INFO]\t[TRAIN] epoch: 64, iter: 258450/640000, loss: 0.5060, lr: 0.000038, batch_cost: 0.2734, reader_cost: 0.00014, ips: 58.5288 samples/sec | ETA 28:58:24\r\n",
      "2022-11-16 21:49:06 [INFO]\t[TRAIN] epoch: 64, iter: 258500/640000, loss: 0.5399, lr: 0.000038, batch_cost: 0.2723, reader_cost: 0.00014, ips: 58.7513 samples/sec | ETA 28:51:35\r\n",
      "2022-11-16 21:49:20 [INFO]\t[TRAIN] epoch: 64, iter: 258550/640000, loss: 0.5244, lr: 0.000038, batch_cost: 0.2739, reader_cost: 0.00014, ips: 58.4067 samples/sec | ETA 29:01:34\r\n",
      "2022-11-16 21:49:34 [INFO]\t[TRAIN] epoch: 64, iter: 258600/640000, loss: 0.5931, lr: 0.000038, batch_cost: 0.2744, reader_cost: 0.00014, ips: 58.3069 samples/sec | ETA 29:04:20\r\n",
      "2022-11-16 21:49:47 [INFO]\t[TRAIN] epoch: 64, iter: 258650/640000, loss: 0.5366, lr: 0.000038, batch_cost: 0.2732, reader_cost: 0.00014, ips: 58.5649 samples/sec | ETA 28:56:25\r\n",
      "2022-11-16 21:50:01 [INFO]\t[TRAIN] epoch: 64, iter: 258700/640000, loss: 0.5585, lr: 0.000038, batch_cost: 0.2719, reader_cost: 0.00013, ips: 58.8475 samples/sec | ETA 28:47:51\r\n",
      "2022-11-16 21:50:14 [INFO]\t[TRAIN] epoch: 64, iter: 258750/640000, loss: 0.5423, lr: 0.000038, batch_cost: 0.2707, reader_cost: 0.00013, ips: 59.1015 samples/sec | ETA 28:40:12\r\n",
      "2022-11-16 21:50:28 [INFO]\t[TRAIN] epoch: 64, iter: 258800/640000, loss: 0.5185, lr: 0.000038, batch_cost: 0.2721, reader_cost: 0.00013, ips: 58.8098 samples/sec | ETA 28:48:30\r\n",
      "2022-11-16 21:50:42 [INFO]\t[TRAIN] epoch: 64, iter: 258850/640000, loss: 0.5453, lr: 0.000038, batch_cost: 0.2694, reader_cost: 0.00013, ips: 59.3895 samples/sec | ETA 28:31:24\r\n",
      "2022-11-16 21:50:55 [INFO]\t[TRAIN] epoch: 64, iter: 258900/640000, loss: 0.5762, lr: 0.000038, batch_cost: 0.2706, reader_cost: 0.00013, ips: 59.1325 samples/sec | ETA 28:38:37\r\n",
      "2022-11-16 21:51:09 [INFO]\t[TRAIN] epoch: 64, iter: 258950/640000, loss: 0.5692, lr: 0.000038, batch_cost: 0.2711, reader_cost: 0.00013, ips: 59.0211 samples/sec | ETA 28:41:38\r\n",
      "2022-11-16 21:51:22 [INFO]\t[TRAIN] epoch: 64, iter: 259000/640000, loss: 0.5399, lr: 0.000038, batch_cost: 0.2699, reader_cost: 0.00013, ips: 59.2770 samples/sec | ETA 28:33:59\r\n",
      "2022-11-16 21:51:36 [INFO]\t[TRAIN] epoch: 64, iter: 259050/640000, loss: 0.5008, lr: 0.000038, batch_cost: 0.2723, reader_cost: 0.00013, ips: 58.7690 samples/sec | ETA 28:48:34\r\n",
      "2022-11-16 21:51:50 [INFO]\t[TRAIN] epoch: 64, iter: 259100/640000, loss: 0.5752, lr: 0.000038, batch_cost: 0.2794, reader_cost: 0.00014, ips: 57.2600 samples/sec | ETA 29:33:53\r\n",
      "2022-11-16 21:52:03 [INFO]\t[TRAIN] epoch: 64, iter: 259150/640000, loss: 0.5016, lr: 0.000038, batch_cost: 0.2758, reader_cost: 0.00014, ips: 58.0131 samples/sec | ETA 29:10:38\r\n",
      "2022-11-16 21:52:17 [INFO]\t[TRAIN] epoch: 64, iter: 259200/640000, loss: 0.4965, lr: 0.000038, batch_cost: 0.2715, reader_cost: 0.00013, ips: 58.9367 samples/sec | ETA 28:42:58\r\n",
      "2022-11-16 21:52:31 [INFO]\t[TRAIN] epoch: 64, iter: 259250/640000, loss: 0.5285, lr: 0.000038, batch_cost: 0.2713, reader_cost: 0.00014, ips: 58.9832 samples/sec | ETA 28:41:23\r\n",
      "2022-11-16 21:52:44 [INFO]\t[TRAIN] epoch: 64, iter: 259300/640000, loss: 0.5156, lr: 0.000038, batch_cost: 0.2749, reader_cost: 0.00014, ips: 58.2039 samples/sec | ETA 29:04:12\r\n",
      "2022-11-16 21:52:58 [INFO]\t[TRAIN] epoch: 64, iter: 259350/640000, loss: 0.5079, lr: 0.000038, batch_cost: 0.2719, reader_cost: 0.00014, ips: 58.8464 samples/sec | ETA 28:44:56\r\n",
      "2022-11-16 21:53:12 [INFO]\t[TRAIN] epoch: 64, iter: 259400/640000, loss: 0.5636, lr: 0.000038, batch_cost: 0.2766, reader_cost: 0.00014, ips: 57.8476 samples/sec | ETA 29:14:29\r\n",
      "2022-11-16 21:53:26 [INFO]\t[TRAIN] epoch: 64, iter: 259450/640000, loss: 0.4986, lr: 0.000038, batch_cost: 0.2759, reader_cost: 0.00014, ips: 57.9911 samples/sec | ETA 29:09:55\r\n",
      "2022-11-16 21:53:39 [INFO]\t[TRAIN] epoch: 65, iter: 259500/640000, loss: 0.5203, lr: 0.000038, batch_cost: 0.2748, reader_cost: 0.00392, ips: 58.2215 samples/sec | ETA 29:02:46\r\n",
      "2022-11-16 21:53:53 [INFO]\t[TRAIN] epoch: 65, iter: 259550/640000, loss: 0.5090, lr: 0.000038, batch_cost: 0.2727, reader_cost: 0.00014, ips: 58.6692 samples/sec | ETA 28:49:14\r\n",
      "2022-11-16 21:54:07 [INFO]\t[TRAIN] epoch: 65, iter: 259600/640000, loss: 0.5129, lr: 0.000038, batch_cost: 0.2757, reader_cost: 0.00014, ips: 58.0253 samples/sec | ETA 29:08:12\r\n",
      "2022-11-16 21:54:21 [INFO]\t[TRAIN] epoch: 65, iter: 259650/640000, loss: 0.5597, lr: 0.000038, batch_cost: 0.2809, reader_cost: 0.00015, ips: 56.9619 samples/sec | ETA 29:40:36\r\n",
      "2022-11-16 21:54:35 [INFO]\t[TRAIN] epoch: 65, iter: 259700/640000, loss: 0.5284, lr: 0.000038, batch_cost: 0.2750, reader_cost: 0.00014, ips: 58.1763 samples/sec | ETA 29:03:12\r\n",
      "2022-11-16 21:54:48 [INFO]\t[TRAIN] epoch: 65, iter: 259750/640000, loss: 0.5451, lr: 0.000038, batch_cost: 0.2711, reader_cost: 0.00013, ips: 59.0237 samples/sec | ETA 28:37:57\r\n",
      "2022-11-16 21:55:02 [INFO]\t[TRAIN] epoch: 65, iter: 259800/640000, loss: 0.5351, lr: 0.000038, batch_cost: 0.2718, reader_cost: 0.00013, ips: 58.8570 samples/sec | ETA 28:42:35\r\n",
      "2022-11-16 21:55:15 [INFO]\t[TRAIN] epoch: 65, iter: 259850/640000, loss: 0.5020, lr: 0.000038, batch_cost: 0.2748, reader_cost: 0.00014, ips: 58.2321 samples/sec | ETA 29:00:51\r\n",
      "2022-11-16 21:55:29 [INFO]\t[TRAIN] epoch: 65, iter: 259900/640000, loss: 0.5560, lr: 0.000038, batch_cost: 0.2762, reader_cost: 0.00014, ips: 57.9344 samples/sec | ETA 29:09:33\r\n",
      "2022-11-16 21:55:43 [INFO]\t[TRAIN] epoch: 65, iter: 259950/640000, loss: 0.4961, lr: 0.000038, batch_cost: 0.2780, reader_cost: 0.00014, ips: 57.5590 samples/sec | ETA 29:20:44\r\n",
      "2022-11-16 21:55:57 [INFO]\t[TRAIN] epoch: 65, iter: 260000/640000, loss: 0.5167, lr: 0.000038, batch_cost: 0.2761, reader_cost: 0.00014, ips: 57.9501 samples/sec | ETA 29:08:37\r\n",
      "2022-11-16 21:55:57 [INFO]\tStart evaluating (total_samples: 3094, total_iters: 3094)...\r\n",
      "3094/3094 [==============================] - 157s 51ms/step - batch_cost: 0.0506 - reader cost: 9.5323e-05\r\n",
      "2022-11-16 21:58:34 [INFO]\t[EVAL] #Images: 3094 mIoU: 0.6247 Acc: 0.7848 Kappa: 0.7020 Dice: 0.7644\r\n",
      "2022-11-16 21:58:34 [INFO]\t[EVAL] Class IoU: \r\n",
      "[0.6127 0.7724 0.623  0.4908]\r\n",
      "2022-11-16 21:58:34 [INFO]\t[EVAL] Class Precision: \r\n",
      "[0.7454 0.867  0.7829 0.6741]\r\n",
      "2022-11-16 21:58:34 [INFO]\t[EVAL] Class Recall: \r\n",
      "[0.7748 0.8762 0.7532 0.6434]\r\n",
      "2022-11-16 21:58:35 [INFO]\t[EVAL] The model with the best validation mIoU (0.6279) was saved at iter 246000.\r\n",
      "2022-11-16 21:58:48 [INFO]\t[TRAIN] epoch: 65, iter: 260050/640000, loss: 0.5185, lr: 0.000038, batch_cost: 0.2723, reader_cost: 0.00014, ips: 58.7491 samples/sec | ETA 28:44:37\r\n",
      "2022-11-16 21:59:02 [INFO]\t[TRAIN] epoch: 65, iter: 260100/640000, loss: 0.5082, lr: 0.000038, batch_cost: 0.2698, reader_cost: 0.00013, ips: 59.3035 samples/sec | ETA 28:28:16\r\n",
      "2022-11-16 21:59:15 [INFO]\t[TRAIN] epoch: 65, iter: 260150/640000, loss: 0.4806, lr: 0.000038, batch_cost: 0.2712, reader_cost: 0.00013, ips: 58.9992 samples/sec | ETA 28:36:51\r\n",
      "2022-11-16 21:59:29 [INFO]\t[TRAIN] epoch: 65, iter: 260200/640000, loss: 0.5087, lr: 0.000038, batch_cost: 0.2702, reader_cost: 0.00013, ips: 59.2222 samples/sec | ETA 28:30:10\r\n",
      "2022-11-16 21:59:42 [INFO]\t[TRAIN] epoch: 65, iter: 260250/640000, loss: 0.5343, lr: 0.000038, batch_cost: 0.2722, reader_cost: 0.00013, ips: 58.7895 samples/sec | ETA 28:42:31\r\n",
      "2022-11-16 21:59:56 [INFO]\t[TRAIN] epoch: 65, iter: 260300/640000, loss: 0.5047, lr: 0.000038, batch_cost: 0.2706, reader_cost: 0.00012, ips: 59.1356 samples/sec | ETA 28:32:13\r\n",
      "2022-11-16 22:00:09 [INFO]\t[TRAIN] epoch: 65, iter: 260350/640000, loss: 0.5195, lr: 0.000038, batch_cost: 0.2721, reader_cost: 0.00013, ips: 58.8020 samples/sec | ETA 28:41:42\r\n",
      "2022-11-16 22:00:23 [INFO]\t[TRAIN] epoch: 65, iter: 260400/640000, loss: 0.5276, lr: 0.000037, batch_cost: 0.2735, reader_cost: 0.00014, ips: 58.5098 samples/sec | ETA 28:50:04\r\n",
      "2022-11-16 22:00:37 [INFO]\t[TRAIN] epoch: 65, iter: 260450/640000, loss: 0.5004, lr: 0.000037, batch_cost: 0.2800, reader_cost: 0.00014, ips: 57.1479 samples/sec | ETA 29:31:04\r\n",
      "2022-11-16 22:00:51 [INFO]\t[TRAIN] epoch: 65, iter: 260500/640000, loss: 0.5050, lr: 0.000037, batch_cost: 0.2774, reader_cost: 0.00014, ips: 57.6860 samples/sec | ETA 29:14:19\r\n",
      "2022-11-16 22:01:05 [INFO]\t[TRAIN] epoch: 65, iter: 260550/640000, loss: 0.5544, lr: 0.000037, batch_cost: 0.2723, reader_cost: 0.00014, ips: 58.7679 samples/sec | ETA 28:41:48\r\n",
      "2022-11-16 22:01:18 [INFO]\t[TRAIN] epoch: 65, iter: 260600/640000, loss: 0.5239, lr: 0.000037, batch_cost: 0.2736, reader_cost: 0.00014, ips: 58.4827 samples/sec | ETA 28:49:58\r\n",
      "2022-11-16 22:01:32 [INFO]\t[TRAIN] epoch: 65, iter: 260650/640000, loss: 0.5217, lr: 0.000037, batch_cost: 0.2718, reader_cost: 0.00014, ips: 58.8666 samples/sec | ETA 28:38:27\r\n",
      "2022-11-16 22:01:46 [INFO]\t[TRAIN] epoch: 65, iter: 260700/640000, loss: 0.5156, lr: 0.000037, batch_cost: 0.2730, reader_cost: 0.00014, ips: 58.6181 samples/sec | ETA 28:45:31\r\n",
      "2022-11-16 22:01:59 [INFO]\t[TRAIN] epoch: 65, iter: 260750/640000, loss: 0.4894, lr: 0.000037, batch_cost: 0.2730, reader_cost: 0.00014, ips: 58.6040 samples/sec | ETA 28:45:42\r\n",
      "2022-11-16 22:02:13 [INFO]\t[TRAIN] epoch: 65, iter: 260800/640000, loss: 0.4953, lr: 0.000037, batch_cost: 0.2706, reader_cost: 0.00016, ips: 59.1273 samples/sec | ETA 28:30:12\r\n",
      "2022-11-16 22:02:26 [INFO]\t[TRAIN] epoch: 65, iter: 260850/640000, loss: 0.5308, lr: 0.000037, batch_cost: 0.2720, reader_cost: 0.00013, ips: 58.8327 samples/sec | ETA 28:38:32\r\n",
      "2022-11-16 22:02:40 [INFO]\t[TRAIN] epoch: 65, iter: 260900/640000, loss: 0.5194, lr: 0.000037, batch_cost: 0.2718, reader_cost: 0.00014, ips: 58.8742 samples/sec | ETA 28:37:06\r\n",
      "2022-11-16 22:02:54 [INFO]\t[TRAIN] epoch: 65, iter: 260950/640000, loss: 0.5164, lr: 0.000037, batch_cost: 0.2726, reader_cost: 0.00014, ips: 58.6950 samples/sec | ETA 28:42:07\r\n",
      "2022-11-16 22:03:07 [INFO]\t[TRAIN] epoch: 65, iter: 261000/640000, loss: 0.5272, lr: 0.000037, batch_cost: 0.2706, reader_cost: 0.00013, ips: 59.1214 samples/sec | ETA 28:29:28\r\n",
      "2022-11-16 22:03:21 [INFO]\t[TRAIN] epoch: 65, iter: 261050/640000, loss: 0.5743, lr: 0.000037, batch_cost: 0.2728, reader_cost: 0.00015, ips: 58.6614 samples/sec | ETA 28:42:39\r\n",
      "2022-11-16 22:03:34 [INFO]\t[TRAIN] epoch: 65, iter: 261100/640000, loss: 0.5001, lr: 0.000037, batch_cost: 0.2712, reader_cost: 0.00014, ips: 58.9898 samples/sec | ETA 28:32:50\r\n",
      "2022-11-16 22:03:48 [INFO]\t[TRAIN] epoch: 65, iter: 261150/640000, loss: 0.5245, lr: 0.000037, batch_cost: 0.2756, reader_cost: 0.00013, ips: 58.0491 samples/sec | ETA 29:00:22\r\n",
      "2022-11-16 22:04:02 [INFO]\t[TRAIN] epoch: 65, iter: 261200/640000, loss: 0.5058, lr: 0.000037, batch_cost: 0.2710, reader_cost: 0.00013, ips: 59.0406 samples/sec | ETA 28:30:54\r\n",
      "2022-11-16 22:04:15 [INFO]\t[TRAIN] epoch: 65, iter: 261250/640000, loss: 0.5432, lr: 0.000037, batch_cost: 0.2732, reader_cost: 0.00013, ips: 58.5686 samples/sec | ETA 28:44:28\r\n",
      "2022-11-16 22:04:29 [INFO]\t[TRAIN] epoch: 65, iter: 261300/640000, loss: 0.5120, lr: 0.000037, batch_cost: 0.2711, reader_cost: 0.00013, ips: 59.0160 samples/sec | ETA 28:31:10\r\n",
      "2022-11-16 22:04:42 [INFO]\t[TRAIN] epoch: 65, iter: 261350/640000, loss: 0.5431, lr: 0.000037, batch_cost: 0.2722, reader_cost: 0.00013, ips: 58.7797 samples/sec | ETA 28:37:49\r\n",
      "2022-11-16 22:04:56 [INFO]\t[TRAIN] epoch: 65, iter: 261400/640000, loss: 0.5385, lr: 0.000037, batch_cost: 0.2741, reader_cost: 0.00014, ips: 58.3812 samples/sec | ETA 28:49:19\r\n",
      "2022-11-16 22:05:10 [INFO]\t[TRAIN] epoch: 65, iter: 261450/640000, loss: 0.5571, lr: 0.000037, batch_cost: 0.2734, reader_cost: 0.00014, ips: 58.5287 samples/sec | ETA 28:44:44\r\n",
      "2022-11-16 22:05:23 [INFO]\t[TRAIN] epoch: 65, iter: 261500/640000, loss: 0.5097, lr: 0.000037, batch_cost: 0.2718, reader_cost: 0.00014, ips: 58.8664 samples/sec | ETA 28:34:37\r\n",
      "2022-11-16 22:05:37 [INFO]\t[TRAIN] epoch: 65, iter: 261550/640000, loss: 0.5256, lr: 0.000037, batch_cost: 0.2782, reader_cost: 0.00015, ips: 57.5087 samples/sec | ETA 29:14:51\r\n",
      "2022-11-16 22:05:51 [INFO]\t[TRAIN] epoch: 65, iter: 261600/640000, loss: 0.5308, lr: 0.000037, batch_cost: 0.2769, reader_cost: 0.00015, ips: 57.7905 samples/sec | ETA 29:06:04\r\n",
      "2022-11-16 22:06:05 [INFO]\t[TRAIN] epoch: 65, iter: 261650/640000, loss: 0.5309, lr: 0.000037, batch_cost: 0.2736, reader_cost: 0.00014, ips: 58.4813 samples/sec | ETA 28:45:13\r\n",
      "2022-11-16 22:06:19 [INFO]\t[TRAIN] epoch: 65, iter: 261700/640000, loss: 0.5491, lr: 0.000037, batch_cost: 0.2734, reader_cost: 0.00014, ips: 58.5267 samples/sec | ETA 28:43:39\r\n",
      "2022-11-16 22:06:32 [INFO]\t[TRAIN] epoch: 65, iter: 261750/640000, loss: 0.4829, lr: 0.000037, batch_cost: 0.2724, reader_cost: 0.00014, ips: 58.7456 samples/sec | ETA 28:37:00\r\n",
      "2022-11-16 22:06:46 [INFO]\t[TRAIN] epoch: 65, iter: 261800/640000, loss: 0.5382, lr: 0.000037, batch_cost: 0.2725, reader_cost: 0.00014, ips: 58.7118 samples/sec | ETA 28:37:46\r\n",
      "2022-11-16 22:06:59 [INFO]\t[TRAIN] epoch: 65, iter: 261850/640000, loss: 0.5475, lr: 0.000037, batch_cost: 0.2721, reader_cost: 0.00014, ips: 58.8043 samples/sec | ETA 28:34:50\r\n",
      "2022-11-16 22:07:13 [INFO]\t[TRAIN] epoch: 65, iter: 261900/640000, loss: 0.5312, lr: 0.000037, batch_cost: 0.2727, reader_cost: 0.00014, ips: 58.6785 samples/sec | ETA 28:38:17\r\n",
      "2022-11-16 22:07:27 [INFO]\t[TRAIN] epoch: 65, iter: 261950/640000, loss: 0.5315, lr: 0.000037, batch_cost: 0.2735, reader_cost: 0.00014, ips: 58.5039 samples/sec | ETA 28:43:11\r\n",
      "2022-11-16 22:07:41 [INFO]\t[TRAIN] epoch: 65, iter: 262000/640000, loss: 0.4982, lr: 0.000037, batch_cost: 0.2767, reader_cost: 0.00015, ips: 57.8335 samples/sec | ETA 29:02:56\r\n",
      "2022-11-16 22:07:41 [INFO]\tStart evaluating (total_samples: 3094, total_iters: 3094)...\r\n",
      " 729/3094 [======>.......................] - ETA: 1:56 - batch_cost: 0.0493 - reader cost: 1.0340e-042022-11-16 22:24:40 [INFO]\t[TRAIN] epoch: 66, iter: 264600/640000, loss: 0.5212, lr: 0.000037, batch_cost: 0.2746, reader_cost: 0.00014, ips: 58.2756 samples/sec | ETA 28:37:48\r\n",
      "2022-11-16 22:24:53 [INFO]\t[TRAIN] epoch: 66, iter: 264650/640000, loss: 0.5177, lr: 0.000037, batch_cost: 0.2727, reader_cost: 0.00014, ips: 58.6650 samples/sec | ETA 28:26:11\r\n",
      "2022-11-16 22:25:07 [INFO]\t[TRAIN] epoch: 66, iter: 264700/640000, loss: 0.4557, lr: 0.000037, batch_cost: 0.2716, reader_cost: 0.00014, ips: 58.9162 samples/sec | ETA 28:18:41\r\n",
      "2022-11-16 22:25:20 [INFO]\t[TRAIN] epoch: 66, iter: 264750/640000, loss: 0.5609, lr: 0.000037, batch_cost: 0.2724, reader_cost: 0.00013, ips: 58.7347 samples/sec | ETA 28:23:42\r\n",
      "2022-11-16 22:25:34 [INFO]\t[TRAIN] epoch: 66, iter: 264800/640000, loss: 0.5338, lr: 0.000037, batch_cost: 0.2735, reader_cost: 0.00014, ips: 58.4948 samples/sec | ETA 28:30:27\r\n",
      "2022-11-16 22:25:48 [INFO]\t[TRAIN] epoch: 66, iter: 264850/640000, loss: 0.5187, lr: 0.000037, batch_cost: 0.2768, reader_cost: 0.00014, ips: 57.8099 samples/sec | ETA 28:50:30\r\n",
      "2022-11-16 22:26:02 [INFO]\t[TRAIN] epoch: 66, iter: 264900/640000, loss: 0.5611, lr: 0.000037, batch_cost: 0.2747, reader_cost: 0.00014, ips: 58.2515 samples/sec | ETA 28:37:09\r\n",
      "2022-11-16 22:26:15 [INFO]\t[TRAIN] epoch: 66, iter: 264950/640000, loss: 0.5421, lr: 0.000037, batch_cost: 0.2701, reader_cost: 0.00013, ips: 59.2359 samples/sec | ETA 28:08:23\r\n",
      "2022-11-16 22:26:29 [INFO]\t[TRAIN] epoch: 66, iter: 265000/640000, loss: 0.5131, lr: 0.000037, batch_cost: 0.2708, reader_cost: 0.00013, ips: 59.0796 samples/sec | ETA 28:12:37\r\n",
      "2022-11-16 22:26:42 [INFO]\t[TRAIN] epoch: 66, iter: 265050/640000, loss: 0.5417, lr: 0.000037, batch_cost: 0.2703, reader_cost: 0.00013, ips: 59.2007 samples/sec | ETA 28:08:56\r\n",
      "2022-11-16 22:26:56 [INFO]\t[TRAIN] epoch: 66, iter: 265100/640000, loss: 0.5744, lr: 0.000037, batch_cost: 0.2725, reader_cost: 0.00013, ips: 58.7216 samples/sec | ETA 28:22:29\r\n",
      "2022-11-16 22:27:09 [INFO]\t[TRAIN] epoch: 66, iter: 265150/640000, loss: 0.4919, lr: 0.000037, batch_cost: 0.2701, reader_cost: 0.00013, ips: 59.2273 samples/sec | ETA 28:07:44\r\n",
      "2022-11-16 22:27:23 [INFO]\t[TRAIN] epoch: 66, iter: 265200/640000, loss: 0.4810, lr: 0.000037, batch_cost: 0.2705, reader_cost: 0.00013, ips: 59.1583 samples/sec | ETA 28:09:28\r\n",
      "2022-11-16 22:27:36 [INFO]\t[TRAIN] epoch: 66, iter: 265250/640000, loss: 0.5073, lr: 0.000037, batch_cost: 0.2704, reader_cost: 0.00013, ips: 59.1686 samples/sec | ETA 28:08:57\r\n",
      "2022-11-16 22:27:50 [INFO]\t[TRAIN] epoch: 66, iter: 265300/640000, loss: 0.4907, lr: 0.000037, batch_cost: 0.2724, reader_cost: 0.00014, ips: 58.7434 samples/sec | ETA 28:20:57\r\n",
      "2022-11-16 22:28:04 [INFO]\t[TRAIN] epoch: 66, iter: 265350/640000, loss: 0.5246, lr: 0.000037, batch_cost: 0.2723, reader_cost: 0.00013, ips: 58.7501 samples/sec | ETA 28:20:32\r\n",
      "2022-11-16 22:28:17 [INFO]\t[TRAIN] epoch: 66, iter: 265400/640000, loss: 0.5158, lr: 0.000037, batch_cost: 0.2731, reader_cost: 0.00014, ips: 58.5965 samples/sec | ETA 28:24:45\r\n",
      "2022-11-16 22:28:31 [INFO]\t[TRAIN] epoch: 66, iter: 265450/640000, loss: 0.5115, lr: 0.000037, batch_cost: 0.2733, reader_cost: 0.00014, ips: 58.5347 samples/sec | ETA 28:26:20\r\n",
      "2022-11-16 22:28:45 [INFO]\t[TRAIN] epoch: 66, iter: 265500/640000, loss: 0.5598, lr: 0.000037, batch_cost: 0.2733, reader_cost: 0.00014, ips: 58.5333 samples/sec | ETA 28:26:09\r\n",
      "2022-11-16 22:28:59 [INFO]\t[TRAIN] epoch: 66, iter: 265550/640000, loss: 0.4809, lr: 0.000037, batch_cost: 0.2786, reader_cost: 0.00014, ips: 57.4322 samples/sec | ETA 28:58:37\r\n",
      "2022-11-16 22:29:12 [INFO]\t[TRAIN] epoch: 66, iter: 265600/640000, loss: 0.5323, lr: 0.000037, batch_cost: 0.2710, reader_cost: 0.00013, ips: 59.0409 samples/sec | ETA 28:11:01\r\n",
      "2022-11-16 22:29:26 [INFO]\t[TRAIN] epoch: 66, iter: 265650/640000, loss: 0.5539, lr: 0.000037, batch_cost: 0.2718, reader_cost: 0.00013, ips: 58.8691 samples/sec | ETA 28:15:44\r\n",
      "2022-11-16 22:29:39 [INFO]\t[TRAIN] epoch: 66, iter: 265700/640000, loss: 0.5173, lr: 0.000037, batch_cost: 0.2728, reader_cost: 0.00014, ips: 58.6527 samples/sec | ETA 28:21:46\r\n",
      "2022-11-16 22:29:53 [INFO]\t[TRAIN] epoch: 66, iter: 265750/640000, loss: 0.5216, lr: 0.000037, batch_cost: 0.2714, reader_cost: 0.00014, ips: 58.9525 samples/sec | ETA 28:12:53\r\n",
      "2022-11-16 22:30:07 [INFO]\t[TRAIN] epoch: 66, iter: 265800/640000, loss: 0.5313, lr: 0.000037, batch_cost: 0.2726, reader_cost: 0.00014, ips: 58.6932 samples/sec | ETA 28:20:08\r\n",
      "2022-11-16 22:30:20 [INFO]\t[TRAIN] epoch: 66, iter: 265850/640000, loss: 0.5168, lr: 0.000037, batch_cost: 0.2732, reader_cost: 0.00014, ips: 58.5705 samples/sec | ETA 28:23:28\r\n",
      "2022-11-16 22:30:34 [INFO]\t[TRAIN] epoch: 66, iter: 265900/640000, loss: 0.5017, lr: 0.000037, batch_cost: 0.2703, reader_cost: 0.00016, ips: 59.1903 samples/sec | ETA 28:05:24\r\n",
      "2022-11-16 22:30:47 [INFO]\t[TRAIN] epoch: 66, iter: 265950/640000, loss: 0.5345, lr: 0.000037, batch_cost: 0.2707, reader_cost: 0.00013, ips: 59.1098 samples/sec | ETA 28:07:28\r\n",
      "2022-11-16 22:31:01 [INFO]\t[TRAIN] epoch: 66, iter: 266000/640000, loss: 0.5215, lr: 0.000037, batch_cost: 0.2707, reader_cost: 0.00013, ips: 59.1086 samples/sec | ETA 28:07:17\r\n",
      "2022-11-16 22:31:01 [INFO]\tStart evaluating (total_samples: 3094, total_iters: 3094)...\r\n",
      "1900/3094 [=================>............] - ETA: 1:00 - batch_cost: 0.0509 - reader cost: 9.0120e-052022-11-16 22:38:53 [INFO]\t[TRAIN] epoch: 66, iter: 267150/640000, loss: 0.5073, lr: 0.000037, batch_cost: 0.2735, reader_cost: 0.00014, ips: 58.5039 samples/sec | ETA 28:19:29\r\n",
      "2022-11-16 22:39:07 [INFO]\t[TRAIN] epoch: 66, iter: 267200/640000, loss: 0.5494, lr: 0.000037, batch_cost: 0.2753, reader_cost: 0.00015, ips: 58.1204 samples/sec | ETA 28:30:28\r\n",
      "2022-11-16 22:39:21 [INFO]\t[TRAIN] epoch: 66, iter: 267250/640000, loss: 0.5057, lr: 0.000037, batch_cost: 0.2796, reader_cost: 0.00014, ips: 57.2166 samples/sec | ETA 28:57:15\r\n",
      "2022-11-16 22:39:35 [INFO]\t[TRAIN] epoch: 66, iter: 267300/640000, loss: 0.4871, lr: 0.000037, batch_cost: 0.2763, reader_cost: 0.00015, ips: 57.9021 samples/sec | ETA 28:36:27\r\n",
      "2022-11-16 22:39:49 [INFO]\t[TRAIN] epoch: 66, iter: 267350/640000, loss: 0.5050, lr: 0.000037, batch_cost: 0.2792, reader_cost: 0.00015, ips: 57.3131 samples/sec | ETA 28:53:52\r\n",
      "2022-11-16 22:40:03 [INFO]\t[TRAIN] epoch: 66, iter: 267400/640000, loss: 0.5826, lr: 0.000037, batch_cost: 0.2805, reader_cost: 0.00015, ips: 57.0481 samples/sec | ETA 29:01:41\r\n",
      "2022-11-16 22:40:17 [INFO]\t[TRAIN] epoch: 66, iter: 267450/640000, loss: 0.5328, lr: 0.000037, batch_cost: 0.2752, reader_cost: 0.00014, ips: 58.1307 samples/sec | ETA 28:29:01\r\n",
      "2022-11-16 22:40:31 [INFO]\t[TRAIN] epoch: 66, iter: 267500/640000, loss: 0.5451, lr: 0.000037, batch_cost: 0.2780, reader_cost: 0.00014, ips: 57.5444 samples/sec | ETA 28:46:12\r\n",
      "2022-11-16 22:40:44 [INFO]\t[TRAIN] epoch: 66, iter: 267550/640000, loss: 0.5248, lr: 0.000037, batch_cost: 0.2764, reader_cost: 0.00014, ips: 57.8783 samples/sec | ETA 28:36:00\r\n",
      "2022-11-16 22:40:58 [INFO]\t[TRAIN] epoch: 67, iter: 267600/640000, loss: 0.5221, lr: 0.000037, batch_cost: 0.2775, reader_cost: 0.00364, ips: 57.6620 samples/sec | ETA 28:42:13\r\n",
      "2022-11-16 22:41:12 [INFO]\t[TRAIN] epoch: 67, iter: 267650/640000, loss: 0.5058, lr: 0.000037, batch_cost: 0.2755, reader_cost: 0.00014, ips: 58.0661 samples/sec | ETA 28:30:00\r\n",
      "2022-11-16 22:41:26 [INFO]\t[TRAIN] epoch: 67, iter: 267700/640000, loss: 0.5598, lr: 0.000037, batch_cost: 0.2807, reader_cost: 0.00015, ips: 56.9942 samples/sec | ETA 29:01:55\r\n",
      "2022-11-16 22:41:40 [INFO]\t[TRAIN] epoch: 67, iter: 267750/640000, loss: 0.5467, lr: 0.000037, batch_cost: 0.2780, reader_cost: 0.00014, ips: 57.5515 samples/sec | ETA 28:44:49\r\n",
      "2022-11-16 22:41:54 [INFO]\t[TRAIN] epoch: 67, iter: 267800/640000, loss: 0.5259, lr: 0.000037, batch_cost: 0.2774, reader_cost: 0.00016, ips: 57.6844 samples/sec | ETA 28:40:37\r\n",
      "2022-11-16 22:42:08 [INFO]\t[TRAIN] epoch: 67, iter: 267850/640000, loss: 0.5199, lr: 0.000037, batch_cost: 0.2826, reader_cost: 0.00015, ips: 56.6134 samples/sec | ETA 29:12:56\r\n",
      "2022-11-16 22:42:22 [INFO]\t[TRAIN] epoch: 67, iter: 267900/640000, loss: 0.5144, lr: 0.000037, batch_cost: 0.2768, reader_cost: 0.00017, ips: 57.8071 samples/sec | ETA 28:36:30\r\n",
      "2022-11-16 22:42:36 [INFO]\t[TRAIN] epoch: 67, iter: 267950/640000, loss: 0.5008, lr: 0.000037, batch_cost: 0.2753, reader_cost: 0.00014, ips: 58.1219 samples/sec | ETA 28:26:59\r\n",
      "2022-11-16 22:42:49 [INFO]\t[TRAIN] epoch: 67, iter: 268000/640000, loss: 0.4883, lr: 0.000037, batch_cost: 0.2749, reader_cost: 0.00015, ips: 58.2120 samples/sec | ETA 28:24:06\r\n",
      "2022-11-16 22:42:49 [INFO]\tStart evaluating (total_samples: 3094, total_iters: 3094)...\r\n",
      "3094/3094 [==============================] - 158s 51ms/step - batch_cost: 0.0510 - reader cost: 9.9689e-05\r\n",
      "2022-11-16 22:45:28 [INFO]\t[EVAL] #Images: 3094 mIoU: 0.6268 Acc: 0.7870 Kappa: 0.7045 Dice: 0.7658\r\n",
      "2022-11-16 22:45:28 [INFO]\t[EVAL] Class IoU: \r\n",
      "[0.6152 0.7745 0.6278 0.4895]\r\n",
      "2022-11-16 22:45:28 [INFO]\t[EVAL] Class Precision: \r\n",
      "[0.7396 0.8657 0.7825 0.6943]\r\n",
      "2022-11-16 22:45:28 [INFO]\t[EVAL] Class Recall: \r\n",
      "[0.7853 0.8802 0.7605 0.624 ]\r\n",
      "2022-11-16 22:45:28 [INFO]\t[EVAL] The model with the best validation mIoU (0.6279) was saved at iter 246000.\r\n",
      "^C\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"train.py\", line 230, in <module>\r\n",
      "    main(args)\r\n",
      "  File \"train.py\", line 225, in main\r\n",
      "    to_static_training=cfg.to_static_training)\r\n",
      "  File \"/home/aistudio/PaddleSeg/paddleseg/core/train.py\", line 206, in train\r\n",
      "    logits_list = ddp_model(images) if nranks > 1 else model(images)\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\r\n",
      "    return self._dygraph_call_func(*inputs, **kwargs)\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\r\n",
      "    outputs = self.forward(*inputs, **kwargs)\r\n",
      "  File \"/home/aistudio/PaddleSeg/paddleseg/models/segformer.py\", line 83, in forward\r\n",
      "    feats = self.backbone(x)\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\r\n",
      "    return self._dygraph_call_func(*inputs, **kwargs)\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\r\n",
      "    outputs = self.forward(*inputs, **kwargs)\r\n",
      "  File \"/home/aistudio/PaddleSeg/paddleseg/models/backbones/mix_transformer.py\", line 472, in forward\r\n",
      "    x = self.forward_features(x)\r\n",
      "  File \"/home/aistudio/PaddleSeg/paddleseg/models/backbones/mix_transformer.py\", line 456, in forward_features\r\n",
      "    x = blk(x, H, W)\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\r\n",
      "    return self._dygraph_call_func(*inputs, **kwargs)\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\r\n",
      "    outputs = self.forward(*inputs, **kwargs)\r\n",
      "  File \"/home/aistudio/PaddleSeg/paddleseg/models/backbones/mix_transformer.py\", line 199, in forward\r\n",
      "    x = x + self.drop_path(self.attn(self.norm1(x), H, W))\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\r\n",
      "    return self._dygraph_call_func(*inputs, **kwargs)\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\r\n",
      "    outputs = self.forward(*inputs, **kwargs)\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py\", line 540, in forward\r\n",
      "    epsilon=self._epsilon)\r\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/functional/norm.py\", line 322, in layer_norm\r\n",
      "    'begin_norm_axis', begin_norm_axis)\r\n",
      "KeyboardInterrupt\r\n",
      "terminate called without an active exception\r\n"
     ]
    }
   ],
   "source": [
    "%cd ~/PaddleSeg\n",
    "! python train.py \\\n",
    "       --config configs/segformer/segformer_b2_cityscapes_1024x1024_160k.yml \\\n",
    "       --save_interval 2000 \\\n",
    "       --use_vdl \\\n",
    "       --log_iters 50 \\\n",
    "       --save_dir output/special \\\n",
    "       --do_eval \\\n",
    "#       --resume_model output/special/iter_10000 \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/13bf511388ef49a483c81b1bfd7377346765b873a93e462b99764b181553f893)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/78d828460d4c4871bdb542d950630af8b4d73e777fca4dcda4eedaf05d0e11d8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **逃离鞍点的方法**\n",
    "**测试出造成梯度爆炸最低学习率lr1（50iters内loss＞5），将模型学习率调整至0.8*lr1训练直到loss大于原先loss的2倍后恢复正常训练。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6、模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-11-16T14:46:45.889894Z",
     "iopub.status.busy": "2022-11-16T14:46:45.889134Z",
     "iopub.status.idle": "2022-11-16T14:49:26.199141Z",
     "shell.execute_reply": "2022-11-16T14:49:26.198201Z",
     "shell.execute_reply.started": "2022-11-16T14:46:45.889862Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/PaddleSeg\r\n",
      "2022-11-16 22:46:48 [INFO]\t\r\n",
      "---------------Config Information---------------\r\n",
      "batch_size: 16\r\n",
      "iters: 640000\r\n",
      "loss:\r\n",
      "  coef:\r\n",
      "  - 1\r\n",
      "  types:\r\n",
      "  - coef:\r\n",
      "    - 0.8\r\n",
      "    - 0.2\r\n",
      "    losses:\r\n",
      "    - type: CrossEntropyLoss\r\n",
      "    - type: LovaszSoftmaxLoss\r\n",
      "    type: MixedLoss\r\n",
      "lr_scheduler:\r\n",
      "  end_lr: 0\r\n",
      "  learning_rate: 6.0e-05\r\n",
      "  power: 0.9\r\n",
      "  type: PolynomialDecay\r\n",
      "model:\r\n",
      "  num_classes: 4\r\n",
      "  pretrained: https://bj.bcebos.com/paddleseg/dygraph/mix_vision_transformer_b2.tar.gz\r\n",
      "  type: SegFormer_B2\r\n",
      "optimizer:\r\n",
      "  momentum: 0.9\r\n",
      "  type: sgd\r\n",
      "  weight_decay: 4.0e-05\r\n",
      "train_dataset:\r\n",
      "  dataset_root: datasets\r\n",
      "  mode: train\r\n",
      "  num_classes: 4\r\n",
      "  train_path: datasets/train_list.txt\r\n",
      "  transforms:\r\n",
      "  - max_scale_factor: 1.25\r\n",
      "    min_scale_factor: 0.75\r\n",
      "    scale_step_size: 0.25\r\n",
      "    type: ResizeStepScaling\r\n",
      "  - prob: 0.075\r\n",
      "    type: RandomBlur\r\n",
      "  - crop_size:\r\n",
      "    - 256\r\n",
      "    - 256\r\n",
      "    type: RandomPaddingCrop\r\n",
      "  - type: RandomHorizontalFlip\r\n",
      "  - type: RandomVerticalFlip\r\n",
      "  - brightness_range: 0.4\r\n",
      "    contrast_range: 0.4\r\n",
      "    saturation_range: 0.4\r\n",
      "    type: RandomDistort\r\n",
      "  - type: Normalize\r\n",
      "  type: Dataset\r\n",
      "val_dataset:\r\n",
      "  dataset_root: datasets\r\n",
      "  mode: val\r\n",
      "  num_classes: 4\r\n",
      "  transforms:\r\n",
      "  - crop_size:\r\n",
      "    - 256\r\n",
      "    - 256\r\n",
      "    type: RandomPaddingCrop\r\n",
      "  - type: Normalize\r\n",
      "  type: Dataset\r\n",
      "  val_path: datasets/val_list.txt\r\n",
      "------------------------------------------------\r\n",
      "W1116 22:46:48.079411 19509 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2\r\n",
      "W1116 22:46:48.079445 19509 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.\r\n",
      "2022-11-16 22:46:49 [INFO]\tLoading pretrained model from https://bj.bcebos.com/paddleseg/dygraph/mix_vision_transformer_b2.tar.gz\r\n",
      "2022-11-16 22:46:49 [WARNING]\tlinear_c4.proj.weight is not in pretrained model\r\n",
      "2022-11-16 22:46:49 [WARNING]\tlinear_c4.proj.bias is not in pretrained model\r\n",
      "2022-11-16 22:46:49 [WARNING]\tlinear_c3.proj.weight is not in pretrained model\r\n",
      "2022-11-16 22:46:49 [WARNING]\tlinear_c3.proj.bias is not in pretrained model\r\n",
      "2022-11-16 22:46:49 [WARNING]\tlinear_c2.proj.weight is not in pretrained model\r\n",
      "2022-11-16 22:46:49 [WARNING]\tlinear_c2.proj.bias is not in pretrained model\r\n",
      "2022-11-16 22:46:49 [WARNING]\tlinear_c1.proj.weight is not in pretrained model\r\n",
      "2022-11-16 22:46:49 [WARNING]\tlinear_c1.proj.bias is not in pretrained model\r\n",
      "2022-11-16 22:46:49 [WARNING]\tlinear_fuse._conv.weight is not in pretrained model\r\n",
      "2022-11-16 22:46:49 [WARNING]\tlinear_fuse._batch_norm.weight is not in pretrained model\r\n",
      "2022-11-16 22:46:49 [WARNING]\tlinear_fuse._batch_norm.bias is not in pretrained model\r\n",
      "2022-11-16 22:46:49 [WARNING]\tlinear_fuse._batch_norm._mean is not in pretrained model\r\n",
      "2022-11-16 22:46:49 [WARNING]\tlinear_fuse._batch_norm._variance is not in pretrained model\r\n",
      "2022-11-16 22:46:49 [WARNING]\tlinear_pred.weight is not in pretrained model\r\n",
      "2022-11-16 22:46:49 [WARNING]\tlinear_pred.bias is not in pretrained model\r\n",
      "2022-11-16 22:46:49 [INFO]\tThere are 332/347 variables loaded into SegFormer.\r\n",
      "2022-11-16 22:46:49 [INFO]\tLoading pretrained model from output/special/iter_268000/model.pdparams\r\n",
      "2022-11-16 22:46:49 [INFO]\tThere are 347/347 variables loaded into SegFormer.\r\n",
      "2022-11-16 22:46:49 [INFO]\tLoaded trained params of model successfully\r\n",
      "2022-11-16 22:46:50 [INFO]\tStart evaluating (total_samples: 3094, total_iters: 3094)...\r\n",
      "3094/3094 [==============================] - 155s 50ms/step - batch_cost: 0.0499 - reader cost: 2.3209e-04\r\n",
      "2022-11-16 22:49:24 [INFO]\t[EVAL] #Images: 3094 mIoU: 0.6268 Acc: 0.7870 Kappa: 0.7045 Dice: 0.7658\r\n",
      "2022-11-16 22:49:24 [INFO]\t[EVAL] Class IoU: \r\n",
      "[0.6152 0.7745 0.6278 0.4895]\r\n",
      "2022-11-16 22:49:24 [INFO]\t[EVAL] Class Precision: \r\n",
      "[0.7396 0.8657 0.7825 0.6943]\r\n",
      "2022-11-16 22:49:24 [INFO]\t[EVAL] Class Recall: \r\n",
      "[0.7853 0.8802 0.7605 0.624 ]\r\n"
     ]
    }
   ],
   "source": [
    "# 模型评估\n",
    "%cd ~/PaddleSeg\n",
    "! python val.py \\\n",
    "       --config configs/segformer/segformer_b2_cityscapes_1024x1024_160k.yml \\\n",
    "       --model_path output/special/iter_268000/model.pdparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/5691eeaecda0442ea37c877469ab242e10d3fe7974ce45ffaa5794afced523f6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7、测试结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-11-16T14:50:14.817347Z",
     "iopub.status.busy": "2022-11-16T14:50:14.816404Z",
     "iopub.status.idle": "2022-11-16T14:54:38.383296Z",
     "shell.execute_reply": "2022-11-16T14:54:38.382194Z",
     "shell.execute_reply.started": "2022-11-16T14:50:14.817308Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/PaddleSeg\r\n",
      "2022-11-16 22:50:16 [INFO]\t\r\n",
      "---------------Config Information---------------\r\n",
      "batch_size: 16\r\n",
      "iters: 640000\r\n",
      "loss:\r\n",
      "  coef:\r\n",
      "  - 1\r\n",
      "  types:\r\n",
      "  - coef:\r\n",
      "    - 0.8\r\n",
      "    - 0.2\r\n",
      "    losses:\r\n",
      "    - type: CrossEntropyLoss\r\n",
      "    - type: LovaszSoftmaxLoss\r\n",
      "    type: MixedLoss\r\n",
      "lr_scheduler:\r\n",
      "  end_lr: 0\r\n",
      "  learning_rate: 6.0e-05\r\n",
      "  power: 0.9\r\n",
      "  type: PolynomialDecay\r\n",
      "model:\r\n",
      "  num_classes: 4\r\n",
      "  pretrained: https://bj.bcebos.com/paddleseg/dygraph/mix_vision_transformer_b2.tar.gz\r\n",
      "  type: SegFormer_B2\r\n",
      "optimizer:\r\n",
      "  momentum: 0.9\r\n",
      "  type: sgd\r\n",
      "  weight_decay: 4.0e-05\r\n",
      "train_dataset:\r\n",
      "  dataset_root: datasets\r\n",
      "  mode: train\r\n",
      "  num_classes: 4\r\n",
      "  train_path: datasets/train_list.txt\r\n",
      "  transforms:\r\n",
      "  - max_scale_factor: 1.25\r\n",
      "    min_scale_factor: 0.75\r\n",
      "    scale_step_size: 0.25\r\n",
      "    type: ResizeStepScaling\r\n",
      "  - prob: 0.075\r\n",
      "    type: RandomBlur\r\n",
      "  - crop_size:\r\n",
      "    - 256\r\n",
      "    - 256\r\n",
      "    type: RandomPaddingCrop\r\n",
      "  - type: RandomHorizontalFlip\r\n",
      "  - type: RandomVerticalFlip\r\n",
      "  - brightness_range: 0.4\r\n",
      "    contrast_range: 0.4\r\n",
      "    saturation_range: 0.4\r\n",
      "    type: RandomDistort\r\n",
      "  - type: Normalize\r\n",
      "  type: Dataset\r\n",
      "val_dataset:\r\n",
      "  dataset_root: datasets\r\n",
      "  mode: val\r\n",
      "  num_classes: 4\r\n",
      "  transforms:\r\n",
      "  - crop_size:\r\n",
      "    - 256\r\n",
      "    - 256\r\n",
      "    type: RandomPaddingCrop\r\n",
      "  - type: Normalize\r\n",
      "  type: Dataset\r\n",
      "  val_path: datasets/val_list.txt\r\n",
      "------------------------------------------------\r\n",
      "W1116 22:50:17.001202 19983 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2\r\n",
      "W1116 22:50:17.001245 19983 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.\r\n",
      "2022-11-16 22:50:18 [INFO]\tLoading pretrained model from https://bj.bcebos.com/paddleseg/dygraph/mix_vision_transformer_b2.tar.gz\r\n",
      "2022-11-16 22:50:18 [WARNING]\tlinear_c4.proj.weight is not in pretrained model\r\n",
      "2022-11-16 22:50:18 [WARNING]\tlinear_c4.proj.bias is not in pretrained model\r\n",
      "2022-11-16 22:50:18 [WARNING]\tlinear_c3.proj.weight is not in pretrained model\r\n",
      "2022-11-16 22:50:18 [WARNING]\tlinear_c3.proj.bias is not in pretrained model\r\n",
      "2022-11-16 22:50:18 [WARNING]\tlinear_c2.proj.weight is not in pretrained model\r\n",
      "2022-11-16 22:50:18 [WARNING]\tlinear_c2.proj.bias is not in pretrained model\r\n",
      "2022-11-16 22:50:18 [WARNING]\tlinear_c1.proj.weight is not in pretrained model\r\n",
      "2022-11-16 22:50:18 [WARNING]\tlinear_c1.proj.bias is not in pretrained model\r\n",
      "2022-11-16 22:50:18 [WARNING]\tlinear_fuse._conv.weight is not in pretrained model\r\n",
      "2022-11-16 22:50:18 [WARNING]\tlinear_fuse._batch_norm.weight is not in pretrained model\r\n",
      "2022-11-16 22:50:18 [WARNING]\tlinear_fuse._batch_norm.bias is not in pretrained model\r\n",
      "2022-11-16 22:50:18 [WARNING]\tlinear_fuse._batch_norm._mean is not in pretrained model\r\n",
      "2022-11-16 22:50:18 [WARNING]\tlinear_fuse._batch_norm._variance is not in pretrained model\r\n",
      "2022-11-16 22:50:18 [WARNING]\tlinear_pred.weight is not in pretrained model\r\n",
      "2022-11-16 22:50:18 [WARNING]\tlinear_pred.bias is not in pretrained model\r\n",
      "2022-11-16 22:50:18 [INFO]\tThere are 332/347 variables loaded into SegFormer.\r\n",
      "2022-11-16 22:50:18 [INFO]\tNumber of predict images = 4608\r\n",
      "2022-11-16 22:50:18 [INFO]\tLoading pretrained model from output/special/iter_268000/model.pdparams\r\n",
      "2022-11-16 22:50:18 [INFO]\tThere are 347/347 variables loaded into SegFormer.\r\n",
      "2022-11-16 22:50:18 [INFO]\tStart to predict...\r\n",
      "4608/4608 [==============================] - 258s 56ms/step\r\n"
     ]
    }
   ],
   "source": [
    "# 测试集预测\n",
    "%cd ~/PaddleSeg\n",
    "!python predict.py \\\n",
    "       --config configs/segformer/segformer_b2_cityscapes_1024x1024_160k.yml \\\n",
    "       --model_path output/special/iter_268000/model.pdparams \\\n",
    "       --image_path datasets/img_testA \\\n",
    "       --save_dir result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-11-16T14:54:48.639477Z",
     "iopub.status.busy": "2022-11-16T14:54:48.638705Z",
     "iopub.status.idle": "2022-11-16T14:54:51.870859Z",
     "shell.execute_reply": "2022-11-16T14:54:51.869950Z",
     "shell.execute_reply.started": "2022-11-16T14:54:48.639444Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: result/added_prediction/919.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/7649.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/9624.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1288.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2786.jpg (deflated 1%)\r\n",
      "  adding: result/added_prediction/9598.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/855.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6984.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5199.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/825.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/3849.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8097.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7961.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/170.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7328.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7870.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2279.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9158.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9574.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/3869.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3896.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/8424.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/5391.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/4227.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9879.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/997.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/2264.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/308.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6803.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1892.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/3569.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/480.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9381.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9256.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/5666.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8647.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/621.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/5518.jpg (deflated 1%)\r\n",
      "  adding: result/added_prediction/6308.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3439.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6629.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6285.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/7597.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/970.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/3867.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5040.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5104.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9073.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2380.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/214.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1475.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3172.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5061.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5588.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/7602.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2148.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3983.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9690.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/5223.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2984.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7933.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/1276.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9729.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9432.jpg (deflated 1%)\r\n",
      "  adding: result/added_prediction/2091.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9857.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2317.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5615.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/6907.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2557.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2436.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/6959.jpg (deflated 5%)\r\n",
      "  adding: result/added_prediction/9903.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1090.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/80.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/8218.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/3578.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/5535.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/4343.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2458.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3980.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1440.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5915.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2042.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4699.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/3976.jpg (deflated 11%)\r\n",
      "  adding: result/added_prediction/8782.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1292.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6203.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1898.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4601.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1947.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/1104.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/8685.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/7070.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/9351.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4942.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/4818.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7492.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/4320.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/3330.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/754.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/6245.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4243.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/8061.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4868.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7026.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6488.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9649.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/471.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1907.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/6265.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/4873.jpg (deflated 5%)\r\n",
      "  adding: result/added_prediction/4686.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1865.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/401.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1667.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5555.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2826.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7653.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/8855.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/5243.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5625.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4334.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6956.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/879.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/8851.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/946.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/3322.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/3015.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6796.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/3574.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/4247.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3475.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9297.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/902.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/8171.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9907.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1426.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/5267.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/5716.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5791.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1612.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3673.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8672.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7325.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/262.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2614.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/4126.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5757.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2349.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/8183.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/4511.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/7112.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/6303.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/7729.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2687.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/6071.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/6378.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7641.jpg (deflated 7%)\r\n",
      "  adding: result/added_prediction/7417.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1687.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/294.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/5221.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3101.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6337.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1264.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/7877.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/6377.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/3564.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/8104.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4723.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/7532.jpg (deflated 1%)\r\n",
      "  adding: result/added_prediction/4478.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/7408.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/5169.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/4480.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/7678.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8028.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9014.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/8415.jpg (deflated 5%)\r\n",
      "  adding: result/added_prediction/2377.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/3576.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1760.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1084.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/7533.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1018.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2081.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9406.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/2763.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5833.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3491.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/4.jpg (deflated 5%)\r\n",
      "  adding: result/added_prediction/9475.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9786.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/4860.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/3577.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/9219.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/40.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/2530.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4416.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/5899.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/417.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5373.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6189.jpg (deflated 1%)\r\n",
      "  adding: result/added_prediction/8231.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9850.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/536.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6595.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9528.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1111.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/3672.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/1178.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2573.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/3958.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/3950.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2967.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9811.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/2456.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4931.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8845.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1784.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8762.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/5384.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7230.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6126.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9514.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/5102.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9631.jpg (deflated 5%)\r\n",
      "  adding: result/added_prediction/7047.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/304.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/196.jpg (deflated 5%)\r\n",
      "  adding: result/added_prediction/5510.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8805.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1388.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/4998.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/4634.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/46.jpg (deflated 5%)\r\n",
      "  adding: result/added_prediction/405.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7480.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3895.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7543.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9883.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6841.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3117.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/5022.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8831.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/590.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7896.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/5156.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/7847.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2732.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/3089.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1482.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2347.jpg (deflated 1%)\r\n",
      "  adding: result/added_prediction/5591.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/767.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9689.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/6622.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7475.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2656.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/14.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5759.jpg (deflated 16%)\r\n",
      "  adding: result/added_prediction/2444.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/6582.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/7761.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2466.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7645.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/445.jpg (deflated 15%)\r\n",
      "  adding: result/added_prediction/7522.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1567.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/6196.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2780.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2459.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4333.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9512.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/3406.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9756.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/5416.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/4507.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/7749.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1754.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/4386.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/6153.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9195.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/3975.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/8575.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/5642.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9273.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/4468.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/550.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1822.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/963.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/2699.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/3018.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/8356.jpg (deflated 8%)\r\n",
      "  adding: result/added_prediction/3240.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9071.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/137.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1869.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6794.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/6404.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1341.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2976.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/5435.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/318.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3319.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3845.jpg (deflated 1%)\r\n",
      "  adding: result/added_prediction/6177.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9455.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/6557.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/9206.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4886.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8081.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/9516.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3694.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7752.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/6468.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/4674.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/706.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1124.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2122.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4313.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/8998.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2150.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/7647.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/9420.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4345.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/6650.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/3607.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/6957.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/692.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6853.jpg (deflated 5%)\r\n",
      "  adding: result/added_prediction/8369.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5683.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9610.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/8705.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/840.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4452.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2693.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3413.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/5653.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/3278.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2451.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9639.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7081.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1765.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2871.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8653.jpg (deflated 5%)\r\n",
      "  adding: result/added_prediction/200.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2616.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6999.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4788.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/8854.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5508.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9075.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/305.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1235.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/987.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/4725.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1031.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1384.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2419.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2040.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/3336.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9744.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/4908.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2570.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8630.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5178.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2902.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7370.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7043.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7508.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/6787.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6630.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/5511.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7088.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4068.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2073.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/3714.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/7817.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2781.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/8100.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5133.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/2918.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/358.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9156.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9626.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/4151.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3450.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/450.jpg (deflated 1%)\r\n",
      "  adding: result/added_prediction/2973.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4078.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1210.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/589.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9184.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8807.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3888.jpg (deflated 6%)\r\n",
      "  adding: result/added_prediction/374.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/5724.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/8648.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9250.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/5953.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/4070.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6424.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/5839.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/8563.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/8876.jpg (deflated 5%)\r\n",
      "  adding: result/added_prediction/1302.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7016.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/678.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/5207.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6669.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/4576.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3837.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3879.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/4470.jpg (deflated 5%)\r\n",
      "  adding: result/added_prediction/1906.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8498.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/7006.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4400.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9895.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1969.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/6880.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/5913.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2839.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7856.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/4184.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9023.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7907.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9913.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/8583.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7317.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/4859.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/7313.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8568.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/8151.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2779.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/8174.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8516.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8219.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/7534.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9439.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/3072.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3056.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/3704.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/1042.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4489.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1786.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1252.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/6953.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8595.jpg (deflated 5%)\r\n",
      "  adding: result/added_prediction/5741.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/5089.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7617.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/892.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9985.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9802.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1323.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9742.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/4954.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9188.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/7452.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9677.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2143.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1502.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/1234.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1596.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/8111.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/5609.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/6137.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/224.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/4056.jpg (deflated 9%)\r\n",
      "  adding: result/added_prediction/2731.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/7472.jpg (deflated 1%)\r\n",
      "  adding: result/added_prediction/3892.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2914.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7426.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9517.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/5987.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9515.jpg (deflated 5%)\r\n",
      "  adding: result/added_prediction/8501.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3291.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1437.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3846.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4092.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5355.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/610.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6484.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/263.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7409.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3959.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2725.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/180.jpg (deflated 5%)\r\n",
      "  adding: result/added_prediction/6777.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2846.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/6169.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1753.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/2200.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4813.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6345.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/2550.jpg (deflated 8%)\r\n",
      "  adding: result/added_prediction/6998.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1826.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/8296.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/7128.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9522.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7412.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1936.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1336.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8803.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1056.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/181.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3807.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/1581.jpg (deflated 8%)\r\n",
      "  adding: result/added_prediction/7372.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/4993.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6382.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/806.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2684.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/5817.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7623.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2428.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/5256.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/27.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/3646.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/7142.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8160.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/5397.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/8004.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2741.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/436.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/7149.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1795.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9755.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/6948.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/638.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6336.jpg (deflated 19%)\r\n",
      "  adding: result/added_prediction/5100.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6360.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/7232.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5158.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9211.jpg (deflated 17%)\r\n",
      "  adding: result/added_prediction/1579.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9034.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4009.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/8789.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9035.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/6639.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/4522.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6505.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/3536.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6275.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2943.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5226.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/7677.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4403.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/5789.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/886.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4392.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8535.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9497.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/1740.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/4191.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/783.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5784.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2612.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/3409.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/6768.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1633.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4081.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2074.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1487.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2776.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4995.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5646.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7675.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1855.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5320.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7712.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/35.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6980.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/7777.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8211.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5690.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8350.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2034.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9334.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3815.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/7368.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9770.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7387.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2424.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3684.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/8707.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/3817.jpg (deflated 19%)\r\n",
      "  adding: result/added_prediction/4039.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/683.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6771.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1291.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4915.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3123.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/6190.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/796.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8643.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/4237.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5048.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7467.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8590.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2666.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4735.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6635.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/4148.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/7667.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/1987.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/3448.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/685.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/8084.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/7842.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1699.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6866.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6780.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8449.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/8834.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/9691.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5354.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4535.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/4377.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/9028.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6645.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3742.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/3221.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9936.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/4115.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3720.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4866.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/300.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1887.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2038.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/8067.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/42.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8385.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8573.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2961.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1930.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/7580.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1856.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3454.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/5580.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/3157.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/8612.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7064.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9965.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/3875.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2112.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2432.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/3003.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5777.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1733.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2167.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/1638.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5616.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3978.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/3550.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/8676.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/597.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/8303.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5637.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/7790.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/4134.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/3264.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/5144.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1192.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/3471.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8014.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/6070.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/815.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9711.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/8646.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6497.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/530.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/6664.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3818.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/889.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1184.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5105.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/5509.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/6992.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4346.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/61.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/732.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9080.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/7795.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/3507.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1823.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/2339.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9507.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5959.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2060.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/7684.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1349.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/4356.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1821.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9358.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/6833.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/4380.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4903.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/5851.jpg (deflated 6%)\r\n",
      "  adding: result/added_prediction/8838.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/983.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/3286.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2791.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8540.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/5923.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/5489.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1499.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9580.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/6353.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/3168.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9021.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4717.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/7044.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4105.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/4449.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1883.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2047.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/455.jpg (deflated 1%)\r\n",
      "  adding: result/added_prediction/9384.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/8746.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/7485.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/5301.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3155.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6981.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/2089.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8269.jpg (deflated 9%)\r\n",
      "  adding: result/added_prediction/6784.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/574.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5550.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7235.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/8906.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9200.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9394.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5076.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9472.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/1435.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2868.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/984.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/337.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/6323.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3551.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1244.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2889.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1835.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/6558.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/6971.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/285.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/4047.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/6628.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/709.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6854.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2007.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1911.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5593.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/5762.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9765.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/8148.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/6614.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/7418.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/8322.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/1398.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/8451.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3659.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9867.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/408.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/7808.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/2854.jpg (deflated 5%)\r\n",
      "  adding: result/added_prediction/8832.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6573.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/9462.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/7208.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3539.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3092.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/6098.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/6618.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4819.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2395.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2423.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1578.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/4194.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8464.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1674.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/5769.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/6993.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/8755.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/2689.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/2147.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8069.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4705.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/5281.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4087.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/5786.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6464.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/8982.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1697.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/4665.jpg (deflated 1%)\r\n",
      "  adding: result/added_prediction/952.jpg (deflated 1%)\r\n",
      "  adding: result/added_prediction/7977.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9135.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9745.jpg (deflated 1%)\r\n",
      "  adding: result/added_prediction/5991.jpg (deflated 5%)\r\n",
      "  adding: result/added_prediction/1021.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9029.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/6517.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/8548.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3523.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6288.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/4992.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/3527.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8659.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7097.jpg (deflated 5%)\r\n",
      "  adding: result/added_prediction/835.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9214.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/4879.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8315.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9706.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4317.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2919.jpg (deflated 5%)\r\n",
      "  adding: result/added_prediction/5322.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/3418.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1296.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/7572.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/6175.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/926.jpg (deflated 5%)\r\n",
      "  adding: result/added_prediction/4929.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/9989.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5262.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/5302.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9820.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4830.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9752.jpg (deflated 1%)\r\n",
      "  adding: result/added_prediction/4026.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4299.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9274.jpg (deflated 1%)\r\n",
      "  adding: result/added_prediction/9838.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5451.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9433.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7598.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/4547.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/4301.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/8554.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1651.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8368.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6588.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5792.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1026.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/7245.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2061.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7399.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1233.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/6218.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6366.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1648.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6158.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2502.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/177.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9203.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/4475.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1307.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/3593.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1387.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/168.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3359.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/8049.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1329.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/917.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/7320.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/5350.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1076.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9064.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5711.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6805.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6661.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3165.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6844.jpg (deflated 1%)\r\n",
      "  adding: result/added_prediction/8536.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5118.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4457.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9117.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/321.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/1840.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/7498.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1867.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1804.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6086.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4035.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9526.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/5212.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9204.jpg (deflated 5%)\r\n",
      "  adding: result/added_prediction/7113.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/8980.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1523.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/3216.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/4211.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/8094.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5857.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/9613.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/8459.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/8966.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2020.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/6643.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/585.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/415.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9948.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/4218.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9409.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/1397.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9131.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/8651.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2119.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/8023.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/7834.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3422.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/4802.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/698.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/7461.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3472.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/5725.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2290.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/237.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/6616.jpg (deflated 5%)\r\n",
      "  adding: result/added_prediction/3516.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5680.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/5970.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1986.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/4352.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/8379.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/4054.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/3207.jpg (deflated 5%)\r\n",
      "  adding: result/added_prediction/6198.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9760.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/5674.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9484.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/3598.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/6077.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2859.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3041.jpg (deflated 5%)\r\n",
      "  adding: result/added_prediction/4185.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/4702.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/5749.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/665.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/8409.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/9286.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8763.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1717.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2257.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9953.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1951.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/672.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2925.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/4632.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9367.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/256.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/9720.jpg (deflated 1%)\r\n",
      "  adding: result/added_prediction/4500.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/875.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/9208.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2438.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/658.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/2163.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/3718.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/6945.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/6894.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/9890.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/7680.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/2603.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/677.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1189.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/5057.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/5231.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/9773.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/9521.jpg (deflated 1%)\r\n",
      "  adding: result/added_prediction/6121.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/2460.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/7741.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/6411.jpg (deflated 5%)\r\n",
      "  adding: result/added_prediction/3246.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/8628.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/7181.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/8140.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/476.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/1020.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/47.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/5288.jpg (deflated 3%)\r\n",
      "  adding: result/added_prediction/250.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/8433.jpg (deflated 4%)\r\n",
      "  adding: result/added_prediction/9887.jpg (deflated 2%)\r\n",
      "  adding: result/added_prediction/1145.jpg (deflated 3%)\r\n"
     ]
    }
   ],
   "source": [
    "# 由预测结果生成提交文件\n",
    "%cd ~/PaddleSeg\n",
    "!zip -r result.zip result/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/5bc884da0d514ec3902c21a4dfebffb8d581edd09ceb42219ec5c8ea6f4e04f0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8、基于结果的多模型融合（目前仍存bug）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **result评分时异常，但可能会涨点**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir ~/work/results/merge_result\n",
    "!mkdir ~/work/results/merge_result/pseudo_color_prediction\n",
    "!mkdir ~/work/results/merge_result/added_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "os.chdir('/home/aistudio/work/results/')\n",
    "\n",
    "p = 0.1\n",
    "index = 0\n",
    "\n",
    "for f in os.listdir(\"result-segformerb2-65.09/added_prediction\"):\n",
    "\n",
    "    # time_start = time.clock()\n",
    "    \n",
    "    if index % 10 == 0:\n",
    "        print(\"当前已读取\"+str(index)+\"个样本，进度为 \"+str(100*index/len(os.listdir(\"result-segformerb2-65.09/added_prediction\")))+\"%\")\n",
    "    file_name = f.split(\".\")[0]\n",
    "    color_map1 = cv2.imread(\"result-segformerb2-65.09/pseudo_color_prediction/{}.png\".format(file_name), cv2.IMREAD_COLOR)\n",
    "    color_map2 = cv2.imread(\"result-segformerb2-66.24/pseudo_color_prediction/{}.png\".format(file_name), cv2.IMREAD_COLOR)\n",
    "    color_map3 = cv2.imread(\"result-segformerb3/pseudo_color_prediction/{}.png\".format(file_name), cv2.IMREAD_COLOR)\n",
    "    add1 = cv2.imread(\"result-segformerb2-65.09/added_prediction/{}.jpg\".format(file_name), cv2.IMREAD_COLOR)\n",
    "    add2 = cv2.imread(\"result-segformerb2-66.24/added_prediction/{}.jpg\".format(file_name), cv2.IMREAD_COLOR)\n",
    "    add3 = cv2.imread(\"result-segformerb3/added_prediction/{}.jpg\".format(file_name), cv2.IMREAD_COLOR)\n",
    "\n",
    "    for i in range(256):\n",
    "        for j in range(256):\n",
    "            if (color_map2[i][j] == color_map3[i][j]).all():\n",
    "                color_map1[i][j] = color_map2[i][j]\n",
    "                add1[i][j] = add2[i][j]\n",
    "\n",
    "    cv2.imwrite(\"merge_result/pseudo_color_prediction/{}.png\".format(file_name).format(\"RE\"+str(index)), color_map1)\n",
    "    cv2.imwrite(\"merge_result/added_prediction/{}.jpg\".format(file_name), add1)\n",
    "\n",
    "    index += 1\n",
    "\n",
    "    # time_end = time.clock()\n",
    "    # tim = time_end - time_start\n",
    "    # minute = tim % 60\n",
    "    # sec = tim - 60*minute\n",
    "    # print(\"ETA: {}:{}\".format(minute, sec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9、总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/29b829a18a524f288d960b99b87fe027112ebafd530945d3bc5b3346a1cd2ff5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考项目\n",
    "https://aistudio.baidu.com/aistudio/projectdetail/4556036"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
